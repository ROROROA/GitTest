{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import gc\n",
    "mode = 'online' # offline/online: offline validation or online submission\n",
    "now_phase = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from deepctr.models import DeepFM\n",
    "from deepctr.models.din import DIN\n",
    "from deepctr.inputs import SparseFeat, DenseFeat, get_feature_names, VarLenSparseFeat\n",
    "from sklearn.metrics import log_loss, roc_auc_score\n",
    "from tensorflow.python.keras.models import Model, load_model, save_model\n",
    "from deepctr.layers import custom_objects\n",
    "import tensorflow as tf\n",
    "tf.random.set_seed(1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "offline_answer_path = 'offline_underexpose_answer_2'\n",
    "offline_test_path = 'offline_underexpose_test_2' \n",
    "offline_train_path = 'offline_underexpose_train_2'\n",
    "\n",
    "train_path = 'underexpose_train' if mode == 'online' else offline_train_path\n",
    "test_path = 'underexpose_test' if mode == 'online' else offline_test_path\n",
    "\n",
    "output_path = 'sub_{}'.format(mode)\n",
    "if not os.path.exists(output_path): os.mkdir(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "drive_path  = 'debiasing'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create offline val data\n",
    "import pandas as pd  \n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "sample_user_num = 1600\n",
    "if not os.path.exists(offline_answer_path): os.mkdir(offline_answer_path)\n",
    "if not os.path.exists(offline_test_path): os.mkdir(offline_test_path)\n",
    "if not os.path.exists(offline_train_path): os.mkdir(offline_train_path)\n",
    "np.random.seed(1234)\n",
    "\n",
    "for phase in range(now_phase+1):\n",
    "    click_train = pd.read_csv('underexpose_train/underexpose_train_click-{}.csv'.format(phase), header=None,\n",
    "                            names=['user_id', 'item_id', 'time'])\n",
    "    all_user_ids = click_train['user_id'].unique()\n",
    "  \n",
    "    sample_user_ids = np.random.choice(all_user_ids, size=1600, replace=False)\n",
    "\n",
    "    click_test = click_train[click_train['user_id'].isin(sample_user_ids)]\n",
    "    click_train = click_train[~click_train['user_id'].isin(sample_user_ids)]\n",
    "\n",
    "    click_test = click_test.sort_values(by=['user_id', 'time'])\n",
    "    click_answer = click_test.groupby('user_id').tail(1)\n",
    "    click_test = click_test.groupby('user_id').apply(lambda x:x[:-1]).reset_index(drop=True)\n",
    "    click_answer = click_answer[click_answer['user_id'].isin(click_test['user_id'].unique())] # 防止有些用户只有1个点击数据，去掉\n",
    "    click_test = click_test[click_test['user_id'].isin(click_answer['user_id'].unique())]\n",
    "    click_qtime = click_answer[['user_id', 'time']]\n",
    "\n",
    "    click_train.to_csv(offline_train_path + '/underexpose_train_click-{}.csv'.format(phase), index=False, header=None)\n",
    "    click_answer.to_csv(offline_answer_path + '/underexpose_test_qtime_with_answer-{}.csv'.format(phase), index=False, header=None)\n",
    "    click_test.to_csv(offline_test_path + '/underexpose_test_click-{}.csv'.format(phase), index=False, header=None)\n",
    "    click_qtime.to_csv(offline_test_path + '/underexpose_test_qtime-{}.csv'.format(phase), index=False, header=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Common"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd  \n",
    "from tqdm import tqdm  \n",
    "from collections import defaultdict  \n",
    "import math  \n",
    "import numpy as np\n",
    "# click_train = pd.read_csv(train_path + '/underexpose_train_click-{}.csv'.format(0), header=None,\n",
    "                                  # names=['user_id', 'item_id', 'time'])\n",
    "# click_train = click_train.sort_values(by=['user_id', 'time'])\n",
    "# 6789\n",
    "user_feat_df = pd.read_csv('underexpose_train/underexpose_user_feat.csv',header=None, names=['user_id','age_level','gender','city_level'])\n",
    "user_feat_df = user_feat_df.drop_duplicates('user_id')\n",
    "user_feat_df['age_level'].fillna(\"-1\", inplace=True) # user_feat_df['age_level'].value_counts().index[0]\n",
    "user_feat_df['gender'].fillna(\"-1\", inplace=True) # user_feat_df['gender'].value_counts().index[0]\n",
    "user_feat_df['city_level'].fillna(\"-1\", inplace=True) # user_feat_df['city_level'].value_counts().index[0]\n",
    "\n",
    "\n",
    "item_feat_cols = ['item_id',] + ['txt_embed_'+ str(i) for i in range(128)] + ['img_embed_'+ str(i) for i in range(128)]\n",
    "item_feat_df = pd.read_csv('underexpose_train/underexpose_item_feat.csv',header=None, names=item_feat_cols)\n",
    "item_feat_df['txt_embed_0'] = item_feat_df['txt_embed_0'].apply(lambda x:float(x[1:]))\n",
    "item_feat_df['txt_embed_127'] = item_feat_df['txt_embed_127'].apply(lambda x:float(x[:-1]))\n",
    "item_feat_df['img_embed_0'] = item_feat_df['img_embed_0'].apply(lambda x:float(x[1:]))\n",
    "item_feat_df['img_embed_127'] = item_feat_df['img_embed_127'].apply(lambda x:float(x[:-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "phase: 0\n",
      "phase: 1\n",
      "phase: 2\n",
      "phase: 3\n",
      "phase: 4\n",
      "phase: 5\n"
     ]
    }
   ],
   "source": [
    "online_total_click = pd.DataFrame()\n",
    "for c in range(now_phase + 1):\n",
    "    print('phase:', c)\n",
    "    click_train = pd.read_csv('underexpose_train/underexpose_train_click-{}.csv'.format(c), header=None,\n",
    "                              names=['user_id', 'item_id', 'time'])\n",
    "    click_test = pd.read_csv('underexpose_test/underexpose_test_click-{}.csv'.format(c), header=None,\n",
    "                              names=['user_id', 'item_id', 'time'])\n",
    "\n",
    "    all_click = click_train.append(click_test)\n",
    "    all_click['phase'] = c\n",
    "    online_total_click = online_total_click.append(all_click)\n",
    "    \n",
    "online_top50_click_np = online_total_click['item_id'].value_counts().index[:50].values\n",
    "online_top50_click = ','.join([str(i) for i in online_top50_click_np])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "phase: 0\n",
      "phase: 1\n",
      "phase: 2\n",
      "phase: 3\n",
      "phase: 4\n",
      "phase: 5\n"
     ]
    }
   ],
   "source": [
    "total_click = pd.DataFrame()\n",
    "for c in range(now_phase + 1):\n",
    "    print('phase:', c)\n",
    "    click_train = pd.read_csv(train_path + '/underexpose_train_click-{}.csv'.format(c), header=None,\n",
    "                              names=['user_id', 'item_id', 'time'])\n",
    "    click_test = pd.read_csv(test_path + '/underexpose_test_click-{}.csv'.format(c), header=None,\n",
    "                              names=['user_id', 'item_id', 'time'])\n",
    "\n",
    "    all_click = click_train.append(click_test)\n",
    "    all_click['phase'] = c\n",
    "    total_click = total_click.append(all_click)\n",
    "offline_top50_click_np = total_click['item_id'].value_counts().index[:50].values\n",
    "offline_top50_click = ','.join([str(i) for i in offline_top50_click_np])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill user to 50 items  \n",
    "def get_predict(df, pred_col, top_fill):\n",
    "    top_fill = [int(t) for t in top_fill.split(',')]\n",
    "    scores = [-1 * i for i in range(1, len(top_fill) + 1)]\n",
    "    ids = list(df['user_id'].unique())\n",
    "    fill_df = pd.DataFrame(ids * len(top_fill), columns=['user_id'])\n",
    "    fill_df.sort_values('user_id', inplace=True)\n",
    "    fill_df['item_id'] = top_fill * len(ids)\n",
    "    fill_df[pred_col] = scores * len(ids)\n",
    "    print(len(fill_df))\n",
    "    df = df.append(fill_df)\n",
    "    df.sort_values(pred_col, ascending=False, inplace=True)\n",
    "    df = df.drop_duplicates(subset=['user_id', 'item_id'], keep='first')\n",
    "    df['rank'] = df.groupby('user_id')[pred_col].rank(method='first', ascending=False)\n",
    "    df = df[df['rank'] <= 50]\n",
    "    df = df.groupby('user_id')['item_id'].apply(lambda x: ','.join([str(i) for i in x])).str.split(',',\n",
    "                                                                                                   expand=True).reset_index()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feat_topk_click_df(whole_click, user_feat_df, feat_cols=['gender','age_level']):\n",
    "   whole_click_user_feat_df = pd.merge(user_feat_df, whole_click, how='inner', on='user_id')\n",
    "   whole_click_feat_topk_df = whole_click_user_feat_df.groupby(feat_cols+ ['item_id']).size().reset_index().rename(columns={0:'click_num'})\n",
    "   whole_click_feat_topk_df['rank'] = whole_click_feat_topk_df.groupby(feat_cols)['click_num'].rank(method='first', ascending=False)\n",
    "   whole_click_feat_topk_df = whole_click_feat_topk_df[whole_click_feat_topk_df['rank'] <= 50]\n",
    "   whole_click_feat_topk_df = whole_click_feat_topk_df.sort_values(by=feat_cols+['rank',])\n",
    "   whole_click_feat_topk_df['sim'] = whole_click_feat_topk_df['rank'].apply(lambda x: -x)\n",
    "   return whole_click_feat_topk_df\n",
    "\n",
    "def get_reco_df_fill_topk(recom_df, user_feat_df, whole_click_user_feat_topk_df, global_top_click_items, feat_cols=['gender','age_level']):\n",
    "   # rec_users in the user_feat_df\n",
    "   existing_users = set(recom_df['user_id']) & set(user_feat_df['user_id'])\n",
    "   recommend_fill_df = pd.merge(user_feat_df[user_feat_df['user_id'].isin(existing_users)], whole_click_user_feat_topk_df, \n",
    "                                on=feat_cols, how='inner')[['user_id', 'item_id', 'sim']]\n",
    "   existing_users = set(recommend_fill_df['user_id'])\n",
    "   print(len(existing_users), len(existing_users)*50, len(recommend_fill_df))\n",
    "\n",
    "   # rec_users not in user_feat_df\n",
    "   all_users = set(recom_df['user_id'])\n",
    "   top_fill = [int(t) for t in global_top_click_items.split(',')]\n",
    "   scores = [-1 * i for i in range(51, len(top_fill) + 51)]\n",
    "   ids = list(all_users)\n",
    "   all_fill_df = pd.DataFrame(ids * len(top_fill), columns=['user_id'])\n",
    "   all_fill_df.sort_values('user_id', inplace=True)\n",
    "   all_fill_df['item_id'] = top_fill * len(ids)\n",
    "   all_fill_df['sim'] = scores * len(ids)\n",
    "   print(len(all_users), len(all_users)*50, len(all_fill_df))\n",
    "\n",
    "   recommend_fill_df = recommend_fill_df.append(all_fill_df)\n",
    "   print(len(recommend_fill_df))\n",
    "   return recommend_fill_df\n",
    "\n",
    "\n",
    "def get_feat_predict(rec_df, whole_click_df, user_feat_df, global_top_click_items, feat_cols=['gender','age_level']):\n",
    "    whole_click_feat_topk_df = get_feat_topk_click_df(whole_click_df, user_feat_df, feat_cols)\n",
    "    recommend_fill_df = get_reco_df_fill_topk(rec_df, user_feat_df, whole_click_feat_topk_df, global_top_click_items, feat_cols)\n",
    "    \n",
    "    df = rec_df.append(recommend_fill_df)\n",
    "    df.sort_values('sim', ascending=False, inplace=True)\n",
    "    df = df.drop_duplicates(subset=['user_id', 'item_id'], keep='first')\n",
    "    df['rank'] = df.groupby('user_id')['sim'].rank(method='first', ascending=False)\n",
    "    df = df[df['rank'] <= 50]\n",
    "    df = df.groupby('user_id')['item_id'].apply(lambda x: ','.join([str(i) for i in x])).str.split(',',\n",
    "                                                                                             expand=True).reset_index()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def make_user_time_tuple(group_df, user_col='user_id', item_col='item_id', time_col='time'):\n",
    "    user_time_tuples = list(zip(group_df[user_col], group_df[time_col]))\n",
    "    return user_time_tuples\n",
    "\n",
    "def make_item_time_tuple(group_df, user_col='user_id', item_col='item_id', time_col='time'):\n",
    "  # group_df = group_df.drop_duplicates(subset=[user_col, item_col], keep='last')\n",
    "  item_time_tuples = list(zip(group_df[item_col], group_df[time_col]))\n",
    "  return item_time_tuples\n",
    "\n",
    "def get_user_item_time_dict(df, user_col='user_id', item_col='item_id', time_col='time'):\n",
    "    user_item_ = df.sort_values(by=[user_col, time_col])\n",
    "    user_item_ = user_item_.groupby(user_col).apply(lambda group: make_item_time_tuple(group, user_col, item_col, time_col)).reset_index().rename(columns={0: 'item_id_time_list'})\n",
    "    user_item_time_dict = dict(zip(user_item_[user_col], user_item_['item_id_time_list']))\n",
    "    return user_item_time_dict\n",
    "\n",
    "def get_item_user_time_dict(df, user_col='user_id', item_col='item_id', time_col='time'):\n",
    "    item_user_df = df.sort_values(by=[item_col, time_col])\n",
    "    item_user_df = item_user_df.groupby(item_col).apply(\n",
    "        lambda group: make_user_time_tuple(group, user_col, item_col, time_col)).reset_index().rename(\n",
    "        columns={0: 'user_id_time_list'})\n",
    "    item_user_time_dict = dict(zip(item_user_df[item_col], item_user_df['user_id_time_list']))\n",
    "    return item_user_time_dict\n",
    "\n",
    "def get_user_min_time_dict(df,  user_col='user_id', item_col='item_id', time_col='time'):\n",
    "    df = df.sort_values(by=[user_col, time_col])\n",
    "    df = df.groupby(user_col).head(1)\n",
    "    user_min_time_dict = dict(zip(df[user_col], df[time_col]))\n",
    "    return user_min_time_dict\n",
    "\n",
    "\n",
    "def item_based_recommend(sim_item_corr, user_item_time_dict, user_id, top_k, item_num, alpha=15000):\n",
    "    rank = {}\n",
    "    if user_id not in user_item_time_dict:\n",
    "      return []\n",
    "    interacted_item_times = user_item_time_dict[user_id]\n",
    "    min_time = min([time for item, time in interacted_item_times])\n",
    "    interacted_items = set([item for item, time in interacted_item_times])\n",
    "    \n",
    "    miss_item_num = 0\n",
    "    for loc, (i, time) in enumerate(interacted_item_times):\n",
    "        if i not in sim_item_corr:\n",
    "          miss_item_num += 1\n",
    "          continue\n",
    "        for j, wij in sorted(sim_item_corr[i].items(), key=lambda x: x[1], reverse=True)[0:top_k]:\n",
    "            if j not in interacted_items:\n",
    "                rank.setdefault(j, 0)\n",
    "\n",
    "                content_weight = 1.0\n",
    "                if item_content_sim_dict.get(i, {}).get(j, None) is not None:\n",
    "                  content_weight += item_content_sim_dict[i][j]\n",
    "                if item_content_sim_dict.get(j, {}).get(i, None) is not None:\n",
    "                  content_weight += item_content_sim_dict[j][i]\n",
    "\n",
    "                time_weight = np.exp(alpha*(time - min_time))\n",
    "                loc_weight = (0.9**(len(interacted_item_times)-loc)) \n",
    "                rank[j] += loc_weight * time_weight * content_weight * wij \n",
    "    if miss_item_num > 10:     \n",
    "        print('user_id={}, miss_item_num={}'.format(user_id, miss_item_num))\n",
    "    sorted_rank_items = sorted(rank.items(), key=lambda d: d[1], reverse=True)[:item_num]\n",
    "    \n",
    "    return sorted_rank_items\n",
    "\n",
    "\n",
    "def user_based_recommend(sim_user_corr, user_item_time_dict, user_id, top_k, item_num, alpha=15000):\n",
    "    rank = {}\n",
    "    interacted_items = set([i for i, t in user_item_time_dict[user_id]]) \n",
    "    interacted_item_time_list = user_item_time_dict[user_id]\n",
    "    interacted_num = len(interacted_items)\n",
    "\n",
    "    min_time = min([t for i,t in interacted_item_time_list])\n",
    "    time_weight_dict = {i: np.exp(alpha*(t-min_time)) for i,t in interacted_item_time_list}\n",
    "    loc_weight_dict = {i: 0.9**(interacted_num-loc) for loc, (i,t) in enumerate(interacted_item_time_list)}\n",
    "\n",
    "    for sim_v, wuv in sorted(sim_user_corr[user_id].items(), key=lambda x:x[1], reverse=True)[0:top_k]:\n",
    "      for j, j_time in user_item_time_dict[sim_v]:\n",
    "        if j not in interacted_items:\n",
    "          rank.setdefault(j, 0)\n",
    "\n",
    "          content_weight = 1.0\n",
    "          for loc, (i, t) in enumerate(interacted_item_time_list):\n",
    "              loc_weight = loc_weight_dict[i]\n",
    "              time_weight = time_weight_dict[i]\n",
    "              if item_content_sim_dict.get(i, {}).get(j, None) is not None:\n",
    "                content_weight += time_weight*loc_weight*item_content_sim_dict[i][j]\n",
    "\n",
    "          # weight = np.exp(-15000*abs(j_time-q_time))\n",
    "          rank[j] += content_weight * wuv \n",
    "\n",
    "    return sorted(rank.items(), key=lambda d: d[1], reverse=True)[:item_num]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import pickle\n",
    "import os\n",
    "def get_content_sim_item(item_feat_df, topk=100):\n",
    "   sim_path = os.path.join(drive_path, 'item_content_sim_dict.pkl')\n",
    "   if os.path.exists(sim_path):\n",
    "      with open(sim_path, 'rb') as f:\n",
    "        return pickle.load(f)\n",
    "\n",
    "   item_idx_2_rawid_dict = dict(zip(item_feat_df.index, item_feat_df['item_id']))\n",
    "   txt_item_feat_df = item_feat_df.filter(regex=\"txt*\")\n",
    "   img_item_feat_df = item_feat_df.filter(regex=\"img*\") \n",
    "\n",
    "   txt_item_feat_np = np.ascontiguousarray(txt_item_feat_df.values, dtype=np.float32)\n",
    "   img_item_feat_np = np.ascontiguousarray(img_item_feat_df.values, dtype=np.float32)\n",
    "   \n",
    "   # norm\n",
    "   txt_item_feat_np = txt_item_feat_np / np.linalg.norm(txt_item_feat_np, axis=1, keepdims=True)\n",
    "   img_item_feat_np = img_item_feat_np / np.linalg.norm(img_item_feat_np, axis=1, keepdims=True)\n",
    "\n",
    "   import faiss    \n",
    "   txt_index = faiss.IndexFlatIP(128)\n",
    "   txt_index.add(txt_item_feat_np)\n",
    "\n",
    "   img_index = faiss.IndexFlatIP(128)\n",
    "   img_index.add(img_item_feat_np)\n",
    "\n",
    "   item_sim_dict = collections.defaultdict(dict)\n",
    "\n",
    "   def search(feat_index, feat_np):\n",
    "      sim, idx = feat_index.search(feat_np, topk)\n",
    "      for target_idx, sim_value_list, rele_idx_list in zip(range(len(feat_np)), sim, idx):\n",
    "          target_raw_id = item_idx_2_rawid_dict[target_idx]\n",
    "          for rele_idx, sim_value in zip(rele_idx_list[1:], sim_value_list[1: ]):\n",
    "            rele_raw_id = item_idx_2_rawid_dict[rele_idx]\n",
    "            item_sim_dict[target_raw_id][rele_raw_id] = item_sim_dict.get(target_raw_id, {}).get(rele_raw_id, 0) + sim_value\n",
    "   \n",
    "   search(txt_index, txt_item_feat_np)\n",
    "   search(img_index, img_item_feat_np)\n",
    "\n",
    "   with open(sim_path, 'wb') as f:\n",
    "    pickle.dump(item_sim_dict, f)\n",
    "\n",
    "   return item_sim_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## swing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def swing(df, user_col='user_id', item_col='item_id', time_col='time'):\n",
    "    # 1. item, (u1,t1), (u2, t2).....\n",
    "    item_user_df = df.sort_values(by=[item_col, time_col])\n",
    "    item_user_df = item_user_df.groupby(item_col).apply(\n",
    "        lambda group: make_user_time_tuple(group, user_col, item_col, time_col)).reset_index().rename(\n",
    "        columns={0: 'user_id_time_list'})\n",
    "    item_user_time_dict = dict(zip(item_user_df[item_col], item_user_df['user_id_time_list']))\n",
    "\n",
    "    user_item_time_dict = defaultdict(list)\n",
    "    # 2. ((u1, u2), i1, d12)\n",
    "    u_u_cnt = defaultdict(list)\n",
    "    item_cnt = defaultdict(int)\n",
    "    for item, user_time_list in tqdm(item_user_time_dict.items()):\n",
    "        for u, u_time in user_time_list:\n",
    "            # just record\n",
    "            item_cnt[item] += 1\n",
    "            user_item_time_dict[u].append((item, u_time))\n",
    "\n",
    "            for relate_u, relate_u_time in user_time_list:\n",
    "                if relate_u == u:\n",
    "                    continue\n",
    "               \n",
    "                key = (u, relate_u)  if u <= relate_u else (relate_u, u)\n",
    "                u_u_cnt[key].append((item, np.abs(u_time - relate_u_time)))\n",
    "\n",
    "\n",
    "    # 3. (i1,i2), sim\n",
    "    sim_item = {}\n",
    "    alpha = 5.0\n",
    "    for u_u, co_item_times in u_u_cnt.items():\n",
    "        num_co_items = len(co_item_times)\n",
    "        for i, i_time_diff in co_item_times:\n",
    "            sim_item.setdefault(i, {})\n",
    "            for j, j_time_diff in co_item_times:\n",
    "              if j == i:\n",
    "                continue\n",
    "              weight = 1.0 # np.exp(-15000*(i_time_diff + j_time_diff))\n",
    "              sim_item[i][j] = sim_item[i].setdefault(j, 0.) + weight / (alpha + num_co_items)\n",
    "    # 4. norm by item count\n",
    "    sim_item_corr = sim_item.copy()\n",
    "    for i, related_items in sim_item.items():\n",
    "        for j, cij in related_items.items():\n",
    "            sim_item_corr[i][j] = cij / math.sqrt(item_cnt[i] * item_cnt[j])\n",
    "       \n",
    "    return sim_item_corr, user_item_time_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## time-dir-aware itemcf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_time_dir_aware_sim_item(df, user_col='user_id', item_col='item_id', time_col='time'):\n",
    "    user_item_time_dict = get_user_item_time_dict(df, user_col, item_col, time_col)\n",
    "\n",
    "    sim_item = {}\n",
    "    item_cnt = defaultdict(int)\n",
    "    for user, item_time_list in tqdm(user_item_time_dict.items()):\n",
    "        for loc_1, (i, i_time) in enumerate(item_time_list):\n",
    "            item_cnt[i] += 1\n",
    "            sim_item.setdefault(i, {})\n",
    "            for loc_2, (relate_item, related_time) in enumerate(item_time_list):\n",
    "                if i == relate_item:\n",
    "                    continue\n",
    "                loc_alpha = 1.0 if loc_2 > loc_1 else 0.7\n",
    "                loc_weight = loc_alpha * (0.8**(np.abs(loc_2-loc_1)-1)) \n",
    "                time_weight = np.exp(-15000*np.abs(i_time-related_time))\n",
    "\n",
    "                sim_item[i].setdefault(relate_item, 0)\n",
    "                sim_item[i][relate_item] += loc_weight * time_weight / math.log(1 + len(item_time_list))\n",
    "                \n",
    "    sim_item_corr = sim_item.copy()\n",
    "    for i, related_items in tqdm(sim_item.items()):\n",
    "        for j, cij in related_items.items():\n",
    "            sim_item_corr[i][j] = cij / math.sqrt(item_cnt[i] * item_cnt[j])\n",
    "            # sim_item_corr[i][j] = cij / math.sqrt(item_cnt[i]*item_cnt[j])+cij/min(item_cnt[i], item_cnt[j])+0.5*cij/(item_cnt[i]+item_cnt[j])\n",
    "\n",
    "    return sim_item_corr, user_item_time_dict\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## bi-graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bi_sim_item(df, user_col='user_id', item_col='item_id', time_col='time'):\n",
    "    item_user_time_dict = get_item_user_time_dict(df, user_col, item_col, time_col)\n",
    "    user_item_time_dict = get_user_item_time_dict(df, user_col, item_col, time_col)\n",
    "\n",
    "    item_cnt = defaultdict(int)  \n",
    "    for user, item_times in tqdm(user_item_time_dict.items()):  \n",
    "        for i,t in item_times:  \n",
    "            item_cnt[i] += 1  \n",
    "\n",
    "    sim_item = {}\n",
    "    \n",
    "    for item, user_time_lists in tqdm(item_user_time_dict.items()):\n",
    "    \n",
    "        sim_item.setdefault(item, {}) \n",
    "    \n",
    "        for u, item_time in user_time_lists:\n",
    "        \n",
    "            tmp_len = len(user_item_time_dict[u])\n",
    "        \n",
    "            for relate_item, related_time in user_item_time_dict[u]:\n",
    "                sim_item[item].setdefault(relate_item, 0)\n",
    "                weight = np.exp(-15000*np.abs(related_time - item_time))\n",
    "                sim_item[item][relate_item] += weight / (math.log(len(user_time_lists)+1) * math.log(tmp_len+1))\n",
    "       \n",
    "    return sim_item, user_item_time_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## user-cf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# user-cf\n",
    "def get_sim_user(df, user_col='user_id', item_col='item_id', time_col='time'):\n",
    "    # user_min_time_dict = get_user_min_time_dict(df, user_col, item_col, time_col) # user first time \n",
    "    # history\n",
    "    user_item_time_dict = get_user_item_time_dict(df)\n",
    "    # item, [u1, u2, ...,]\n",
    "    item_user_time_dict = get_item_user_time_dict(df)\n",
    "\n",
    "    sim_user = {}\n",
    "    user_cnt = defaultdict(int)\n",
    "    for item, user_time_list in tqdm(item_user_time_dict.items()):\n",
    "        num_users = len(user_time_list)\n",
    "        for u, t in user_time_list:\n",
    "            user_cnt[u] += 1\n",
    "            sim_user.setdefault(u, {})\n",
    "            for relate_user, relate_t in user_time_list:\n",
    "                # time_diff_relate_u = 1.0/(1.0+10000*abs(relate_t-t))\n",
    "                if u == relate_user:\n",
    "                    continue\n",
    "                sim_user[u].setdefault(relate_user, 0)\n",
    "                weight = 1.0\n",
    "                sim_user[u][relate_user] += weight / math.log(1 + num_users) # 流行度高的衰减\n",
    "\n",
    "    sim_user_corr = sim_user.copy()\n",
    "    for u, related_users in tqdm(sim_user.items()):\n",
    "        for v, cuv in related_users.items():\n",
    "            sim_user_corr[u][v] = cuv / math.sqrt(user_cnt[u] * user_cnt[v])\n",
    "\n",
    "    return sim_user_corr, user_item_time_dict\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## recall process\n",
    "\n",
    "1. 划分history和last\n",
    "2. history计算相似性\n",
    "3. 召回"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "topk_num = 200\n",
    "recommend_num = 800"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### recall one source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 基于计算的相似性汇总\n",
    "def norm_recall_item_score_list(sorted_recall_item_list):\n",
    "    if len(sorted_recall_item_list) == 0: return sorted_recall_item_list\n",
    "    \n",
    "    assert sorted_recall_item_list[0][1] >= sorted_recall_item_list[-1][1] # 稍微check下是否排序的\n",
    "    max_sim = sorted_recall_item_list[0][1]\n",
    "    min_sim = sorted_recall_item_list[-1][1]\n",
    "    \n",
    "    norm_sorted_recall_item_list = []\n",
    "    for item, score in sorted_recall_item_list:\n",
    "        if max_sim > 0:\n",
    "            norm_score = 1.0 * (score - min_sim) / (max_sim - min_sim) if max_sim > min_sim else 1.0\n",
    "        else:\n",
    "            norm_score = 0.0 # topk-fill set to 0.0\n",
    "        norm_sorted_recall_item_list.append((item, norm_score))\n",
    "    return norm_sorted_recall_item_list\n",
    "\n",
    "\n",
    "def norm_user_recall_item_dict(recall_item_dict):\n",
    "    norm_recall_item_dict = {}\n",
    "    for u, sorted_recall_item_list in recall_item_dict.items():\n",
    "        norm_recall_item_dict[u] = norm_recall_item_score_list(sorted_recall_item_list)\n",
    "    return norm_recall_item_dict\n",
    "\n",
    "\n",
    "def get_recall_results(item_sim_dict, user_item_dict, target_user_ids=None, item_based=True):\n",
    "    if target_user_ids is None:\n",
    "        target_user_ids = user_item_dict.keys()\n",
    "    recall_item_dict = {}\n",
    "    \n",
    "    top50_click_np = offline_top50_click_np if mode == 'offline' else online_top50_click_np\n",
    "    for u in tqdm(target_user_ids):\n",
    "        if item_based:\n",
    "            recall_items = item_based_recommend(item_sim_dict, user_item_dict, u, recommend_num, topk_num)\n",
    "        else:\n",
    "            recall_items = user_based_recommend(item_sim_dict, user_item_dict, u, recommend_num, topk_num)\n",
    "        \n",
    "        if len(recall_items) == 0: \n",
    "            recall_items = [(top50_click_np[0], 0.0)] # 防止该用户丢失\n",
    "        \n",
    "        recall_item_dict[u] = recall_items\n",
    "        \n",
    "    return recall_item_dict\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### aggregate multi-recall sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# item-cf\n",
    "# bi-graph\n",
    "# user-cf\n",
    "# item-cf\n",
    "def agg_recall_results(recall_item_dict_list, is_norm=True, ret_type='tuple'):\n",
    "    print('aggregate recall results begin....')\n",
    "    agg_recall_item_dict = {}\n",
    "    for recall_item_dict in recall_item_dict_list:\n",
    "        if is_norm:\n",
    "            recall_item_dict = norm_user_recall_item_dict(recall_item_dict)\n",
    "        for u, recall_items in recall_item_dict.items():\n",
    "            agg_recall_item_dict.setdefault(u, {})\n",
    "            for i, score in recall_items:\n",
    "                agg_recall_item_dict[u].setdefault(i, 0.0)\n",
    "                agg_recall_item_dict[u][i] += score # 累加\n",
    "                \n",
    "    if ret_type == 'tuple':\n",
    "        agg_recall_item_tuple_dict = {}\n",
    "        for u, recall_item_dict in agg_recall_item_dict.items():\n",
    "            sorted_recall_item_tuples = sorted(recall_item_dict.items(), key=lambda x:x[1], reverse=True)\n",
    "            agg_recall_item_tuple_dict[u] = sorted_recall_item_tuples\n",
    "        return agg_recall_item_tuple_dict\n",
    "    \n",
    "    if ret_type == 'df':\n",
    "        recall_u_i_score_pair_list = []\n",
    "        for u, recall_item_dict in agg_recall_item_dict.items():\n",
    "            for i, score in recall_item_dict.items():\n",
    "                recall_u_i_score_pair_list.append((u, i, score))\n",
    "        recall_df = pd.DataFrame.from_records(recall_u_i_score_pair_list, columns=['user_id', 'item_id', 'sim'])\n",
    "        return recall_df\n",
    "    \n",
    "    return agg_recall_item_dict\n",
    "\n",
    "\n",
    "def get_multi_source_sim_dict_results(history_df, recall_methods={'item-cf', 'bi-graph', 'user-cf', 'swing'}):\n",
    "    recall_sim_pair_dict = {}\n",
    "    if 'item-cf' in recall_methods: \n",
    "        print('item-cf item-sim begin')\n",
    "        item_sim_dict, _ = get_time_dir_aware_sim_item(history_df)\n",
    "        recall_sim_pair_dict['item-cf'] = item_sim_dict\n",
    "        print('item-cf item-sim-pair done, pair_num={}'.format(len(item_sim_dict)))\n",
    "        \n",
    "    if  'bi-graph' in recall_methods:\n",
    "        print('bi-graph item-sim begin')\n",
    "        item_sim_dict, _ =  get_bi_sim_item(history_df)\n",
    "        recall_sim_pair_dict['bi-graph'] =item_sim_dict\n",
    "        print('bi-graph item-sim-pair done, pair_num={}'.format(len(item_sim_dict)))\n",
    "        \n",
    "    if 'swing' in recall_methods:\n",
    "        print('swing item-sim begin')\n",
    "        item_sim_dict, _ =  swing(history_df)\n",
    "        recall_sim_pair_dict['swing'] = item_sim_dict\n",
    "        print('swing item-sim-pair done, pair_num={}'.format(len(item_sim_dict)))\n",
    "        \n",
    "    if 'user-cf' in recall_methods:\n",
    "        print('user-cf user-sim begin')\n",
    "        user_sim_dict, _ =  get_sim_user(history_df)\n",
    "        recall_sim_pair_dict['user-cf'] = user_sim_dict\n",
    "        print('user-cf user-sim-pair done, pair_num={}'.format(len(user_sim_dict)))\n",
    "        \n",
    "    return recall_sim_pair_dict\n",
    "        \n",
    "        \n",
    "\n",
    "def do_multi_recall_results(recall_sim_pair_dict, user_item_time_dict, target_user_ids=None, ret_type='df'):\n",
    "    if target_user_ids is None:\n",
    "        target_user_ids = user_item_time_dict.keys()\n",
    "    \n",
    "    recall_item_dict_list = []\n",
    "    for name, sim_dict in recall_sim_pair_dict.items():\n",
    "        # item-based\n",
    "        if name in {'item-cf', 'bi-graph', 'swing'}:\n",
    "            recall_item_dict = get_recall_results(sim_dict, user_item_time_dict, target_user_ids, item_based=True)\n",
    "        else:\n",
    "            recall_item_dict = get_recall_results(sim_dict, user_item_time_dict, target_user_ids, item_based=False)\n",
    "        \n",
    "        print('{} recall done, recall_user_num={}.'.format(name, len(recall_item_dict)))\n",
    "        recall_item_dict_list.append(recall_item_dict)\n",
    "        \n",
    "    return agg_recall_results(recall_item_dict_list, is_norm=True, ret_type=ret_type)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# item-cf\n",
    "# bi-graph\n",
    "# user-cf\n",
    "# item-cf\n",
    "def agg_recall_results(recall_item_dict_list, is_norm=True, ret_type='tuple'):\n",
    "    print('aggregate recall results begin....')\n",
    "    agg_recall_item_dict = {}\n",
    "    for recall_item_dict in recall_item_dict_list:\n",
    "        if is_norm:\n",
    "            recall_item_dict = norm_user_recall_item_dict(recall_item_dict)\n",
    "        for u, recall_items in recall_item_dict.items():\n",
    "            agg_recall_item_dict.setdefault(u, {})\n",
    "            for i, score in recall_items:\n",
    "                agg_recall_item_dict[u].setdefault(i, 0.0)\n",
    "                agg_recall_item_dict[u][i] += score # 累加\n",
    "                \n",
    "    if ret_type == 'tuple':\n",
    "        agg_recall_item_tuple_dict = {}\n",
    "        for u, recall_item_dict in agg_recall_item_dict.items():\n",
    "            sorted_recall_item_tuples = sorted(recall_item_dict.items(), key=lambda x:x[1], reverse=True)\n",
    "            agg_recall_item_tuple_dict[u] = sorted_recall_item_tuples\n",
    "        return agg_recall_item_tuple_dict\n",
    "    \n",
    "    if ret_type == 'df':\n",
    "        recall_u_i_score_pair_list = []\n",
    "        for u, recall_item_dict in agg_recall_item_dict.items():\n",
    "            for i, score in recall_item_dict.items():\n",
    "                recall_u_i_score_pair_list.append((u, i, score))\n",
    "        recall_df = pd.DataFrame.from_records(recall_u_i_score_pair_list, columns=['user_id', 'item_id', 'sim'])\n",
    "        return recall_df\n",
    "    \n",
    "    return agg_recall_item_dict\n",
    "\n",
    "\n",
    "def get_multi_source_sim_dict_results(history_df, recall_methods={'item-cf', 'bi-graph', 'user-cf', 'swing'}):\n",
    "    recall_sim_pair_dict = {}\n",
    "    if 'item-cf' in recall_methods: \n",
    "        print('item-cf item-sim begin')\n",
    "        item_sim_dict, _ = get_time_dir_aware_sim_item(history_df)\n",
    "        recall_sim_pair_dict['item-cf'] = item_sim_dict\n",
    "        print('item-cf item-sim-pair done, pair_num={}'.format(len(item_sim_dict)))\n",
    "        \n",
    "    if  'bi-graph' in recall_methods:\n",
    "        print('bi-graph item-sim begin')\n",
    "        item_sim_dict, _ =  get_bi_sim_item(history_df)\n",
    "        recall_sim_pair_dict['bi-graph'] =item_sim_dict\n",
    "        print('bi-graph item-sim-pair done, pair_num={}'.format(len(item_sim_dict)))\n",
    "        \n",
    "    if 'swing' in recall_methods:\n",
    "        print('swing item-sim begin')\n",
    "        item_sim_dict, _ =  swing(history_df)\n",
    "        recall_sim_pair_dict['swing'] = item_sim_dict\n",
    "        print('swing item-sim-pair done, pair_num={}'.format(len(item_sim_dict)))\n",
    "        \n",
    "    if 'user-cf' in recall_methods:\n",
    "        print('user-cf user-sim begin')\n",
    "        user_sim_dict, _ =  get_sim_user(history_df)\n",
    "        recall_sim_pair_dict['user-cf'] = user_sim_dict\n",
    "        print('user-cf user-sim-pair done, pair_num={}'.format(len(user_sim_dict)))\n",
    "        \n",
    "    return recall_sim_pair_dict\n",
    "        \n",
    "def do_multi_recall_results(recall_sim_pair_dict, user_item_time_dict, target_user_ids=None, ret_type='df'):\n",
    "    if target_user_ids is None:\n",
    "        target_user_ids = user_item_time_dict.keys()\n",
    "    \n",
    "    recall_item_dict_list = []\n",
    "    for name, sim_dict in recall_sim_pair_dict.items():\n",
    "        # item-based\n",
    "        if name in {'item-cf', 'bi-graph', 'swing'}:\n",
    "            recall_item_dict = get_recall_results(sim_dict, user_item_time_dict, target_user_ids, item_based=True)\n",
    "        else:\n",
    "            recall_item_dict = get_recall_results(sim_dict, user_item_time_dict, target_user_ids, item_based=False)\n",
    "        \n",
    "        print('{} recall done, recall_user_num={}.'.format(name, len(recall_item_dict)))\n",
    "        recall_item_dict_list.append(recall_item_dict)\n",
    "        \n",
    "    return agg_recall_results(recall_item_dict_list, is_norm=True, ret_type=ret_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### multi-processing recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_multi_source_sim_dict_results_multi_processing(history_df, recall_methods={'item-cf', 'bi-graph', 'user-cf', 'swing'}, thread_num=4):\n",
    "    def convert(history_df, input_q, result_q):\n",
    "        while True:\n",
    "            name = input_q.get()\n",
    "            if 'item-cf' == name: \n",
    "                print('item-cf item-sim begin')\n",
    "                item_sim_dict, _ = get_time_dir_aware_sim_item(history_df)\n",
    "                result_q.put((name, item_sim_dict))\n",
    "                print('item-cf item-sim-pair done, pair_num={}'.format(len(item_sim_dict)))\n",
    "\n",
    "            elif  'bi-graph' == name:\n",
    "                print('bi-graph item-sim begin')\n",
    "                item_sim_dict, _ =  get_bi_sim_item(history_df)\n",
    "                result_q.put((name, item_sim_dict))\n",
    "                print('bi-graph item-sim-pair done, pair_num={}'.format(len(item_sim_dict)))\n",
    "\n",
    "            elif 'swing' == name:\n",
    "                print('swing item-sim begin')\n",
    "                item_sim_dict, _ =  swing(history_df)\n",
    "                result_q.put((name, item_sim_dict))\n",
    "                print('swing item-sim-pair done, pair_num={}'.format(len(item_sim_dict)))\n",
    "\n",
    "            elif 'user-cf' == name:\n",
    "                print('user-cf user-sim begin')\n",
    "                user_sim_dict, _ =  get_sim_user(history_df)\n",
    "                result_q.put((name, user_sim_dict))\n",
    "                print('user-cf user-sim-pair done, pair_num={}'.format(len(user_sim_dict)))\n",
    "            input_q.task_done()\n",
    "        \n",
    "    from multiprocessing import Process, JoinableQueue, Queue   \n",
    "    input_q = JoinableQueue()\n",
    "    result_q = Queue()\n",
    "        \n",
    "    processes = []\n",
    "    for name in recall_methods:\n",
    "        input_q.put(name)\n",
    "        processes.append(Process(target=convert, args=(history_df, input_q, result_q)))\n",
    "        processes[-1].daemon = True\n",
    "        processes[-1].start()\n",
    "        \n",
    "    input_q.join()\n",
    "  \n",
    "    recall_sim_pair_dict = {}\n",
    "    while len(recall_sim_pair_dict) != len(recall_methods):\n",
    "        name, sim_pair_dict = result_q.get()\n",
    "        recall_sim_pair_dict[name] = sim_pair_dict  \n",
    "    for p in processes:\n",
    "        p.terminate()\n",
    "        p.join()\n",
    "        \n",
    "    assert len(recall_sim_pair_dict) == len(recall_methods)\n",
    "    return recall_sim_pair_dict\n",
    "\n",
    "def do_multi_recall_results_multi_processing(recall_sim_pair_dict, user_item_time_dict, target_user_ids=None, \n",
    "                                                                ret_type='df', thread_num=4):\n",
    "    from multiprocessing import Process, JoinableQueue, Queue\n",
    "    def convert(user_item_time_dict, target_user_ids, item_based, input_q, result_q):\n",
    "        while True:\n",
    "            name, sim_dict = input_q.get()\n",
    "            print('do recall for {}'.format(name))\n",
    "            recall_item_dict = get_recall_results(sim_dict, user_item_time_dict, target_user_ids, item_based=item_based)\n",
    "            result_q.put(recall_item_dict)\n",
    "            print('{} recall done, recall_user_num={}.'.format(name, len(recall_item_dict)))\n",
    "            input_q.task_done()\n",
    "            \n",
    "    input_q = JoinableQueue()\n",
    "    result_q = Queue()\n",
    "    \n",
    "    if target_user_ids is None:\n",
    "        target_user_ids = user_item_time_dict.keys()\n",
    "        \n",
    "    processes = []\n",
    "    for name, sim_dict in recall_sim_pair_dict.items():\n",
    "        item_based = True if name in {'item-cf', 'bi-graph', 'swing'} else False\n",
    "        input_q.put((name, sim_dict))\n",
    "        processes.append(Process(target=convert, args=(user_item_time_dict, target_user_ids, item_based, input_q, result_q)))\n",
    "        processes[-1].daemon = True\n",
    "        processes[-1].start()\n",
    "        \n",
    "    input_q.join()\n",
    "  \n",
    "    recall_item_dict_list = []\n",
    "    while  len(recall_item_dict_list) != len(recall_sim_pair_dict):\n",
    "        recall_item_dict = result_q.get()\n",
    "        recall_item_dict_list.append(recall_item_dict)\n",
    "        \n",
    "    for p in processes:\n",
    "        p.terminate()\n",
    "        p.join()\n",
    "        \n",
    "    print(len(recall_item_dict_list))\n",
    "    \n",
    "    assert len(recall_item_dict_list) == len(recall_sim_pair_dict)\n",
    "    return agg_recall_results(recall_item_dict_list, is_norm=True, ret_type=ret_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_item_sim_tuple(group_df):\n",
    "    group_df = group_df.sort_values(by=['sim'], ascending=False)\n",
    "    item_score_tuples = list(zip(group_df['item_id'], group_df['sim']))\n",
    "    return item_score_tuples\n",
    "\n",
    "def save_recall_df_as_user_tuples_dict(total_recom_df):\n",
    "    \n",
    "    save_path = os.path.join(drive_path, 'recall', 'online')\n",
    "    !mkdir -p {save_path}\n",
    "    \n",
    "    for phase in range(now_phase+1):\n",
    "        phase_df = total_recom_df[total_recom_df['phase'] == phase]\n",
    "        phase_df = phase_df.groupby('user_id').apply(make_item_sim_tuple).reset_index().rename(columns={0: 'item_score_list'})\n",
    "        phase_user_item_score_dict = dict(zip(phase_df['user_id'], phase_df['item_score_list']))\n",
    "        pickle.dump(phase_user_item_score_dict, open(os.path.join(save_path, 'phase_{}.pkl'.format(phase)), 'wb'))\n",
    "    \n",
    "    pickle.dump(total_recom_df, open(os.path.join(save_path, 'total_recall_df.pkl'), 'wb'))\n",
    "    \n",
    "def read_recall_df():\n",
    "    save_path = os.path.join(drive_path, 'recall', 'online')\n",
    "    \n",
    "    all_phase_user_item_score_dict = {}\n",
    "    \n",
    "    for phase in range(now_phase+1):\n",
    "        phase_save_path = os.path.join(save_path, 'phase_{}.pkl'.format(phase))\n",
    "        phase_user_item_score_dict = pickle.load(open(phase_save_path, 'rb'))\n",
    "        all_phase_user_item_score_dict[phase] = phase_user_item_score_dict\n",
    "\n",
    "    return all_phase_user_item_score_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### construct recall-training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_history_and_last_click_df(click_df):\n",
    "    click_df = click_df.sort_values(by=['user_id', 'time'])\n",
    "    click_last_df = click_df.groupby('user_id').tail(1)\n",
    "\n",
    "    # 用户只有1个点击时，history为空了，导致训练的时候这个用户不可见, 此时默认一下该用户泄露\n",
    "    def hist_func(user_df):\n",
    "        num = len(user_df)\n",
    "        if num == 1:\n",
    "            return user_df\n",
    "        else:\n",
    "            return user_df[:-1]\n",
    "\n",
    "    click_history_df = click_df.groupby('user_id').apply(hist_func).reset_index(drop=True)\n",
    "  \n",
    "    return click_history_df, click_last_df\n",
    "\n",
    "def sliding_obtain_training_df(c, is_silding_compute_sim=False, recall_methods={'item-cf', 'bi-graph', 'user-cf', 'swing'}):\n",
    "    print('train_path={}, test_path={}'.format(train_path, test_path))\n",
    "    \n",
    "    click_train = pd.read_csv(train_path + '/underexpose_train_click-{}.csv'.format(c), header=None,\n",
    "                          names=['user_id', 'item_id', 'time'])\n",
    "    click_test = pd.read_csv(test_path + '/underexpose_test_click-{}.csv'.format(c), header=None,\n",
    "                          names=['user_id', 'item_id', 'time'])\n",
    "    all_click = click_train.append(click_test)\n",
    "\n",
    "    click_history_df = all_click  # init\n",
    "    total_step = 10\n",
    "    step = 0\n",
    "    \n",
    "    # for validation\n",
    "    compute_mode = 'once' if not is_silding_compute_sim else 'multi'\n",
    "    \n",
    "    save_training_path = os.path.join('training', mode, compute_mode, str(c))\n",
    "    !mkdir -p {save_training_path}\n",
    "    \n",
    "    full_sim_pair_dict = get_multi_source_sim_dict_results_multi_processing(click_history_df, recall_methods=recall_methods) \n",
    "    pickle.dump(full_sim_pair_dict, open(os.path.join(save_training_path, 'full_sim_pair_dict.pkl'), 'wb'))\n",
    "    \n",
    "    step_user_recall_item_dict = {}\n",
    "    step_strategy_sim_pair_dict = {}\n",
    "#     step_user_hist_item_time_dict = {}\n",
    "    \n",
    "    while step < total_step:\n",
    "        print('step={}'.format(step))\n",
    "        click_history_df, click_last_df = get_history_and_last_click_df(click_history_df)  # override click_history_df\n",
    "        user_item_time_dict = get_user_item_time_dict(click_history_df)\n",
    "        \n",
    "        if is_silding_compute_sim:\n",
    "            sim_pair_dict = get_multi_source_sim_dict_results_multi_processing(click_history_df, recall_methods=recall_methods) # re-compute\n",
    "        else:\n",
    "            sim_pair_dict = full_sim_pair_dict\n",
    "            \n",
    "        user_recall_item_dict = do_multi_recall_results_multi_processing(sim_pair_dict, user_item_time_dict, ret_type='tuple')\n",
    "        \n",
    "        step_user_recall_item_dict[step] =  user_recall_item_dict\n",
    "        if  is_silding_compute_sim:\n",
    "            step_strategy_sim_pair_dict[step] = sim_pair_dict\n",
    "         # step_user_hist_item_time_dict[step] = user_item_time_dict\n",
    "        step += 1\n",
    "    \n",
    "    pickle.dump(step_user_recall_item_dict, open(os.path.join(save_training_path, 'step_user_recall_item_dict.pkl'), 'wb'))\n",
    "    \n",
    "    if  is_silding_compute_sim:\n",
    "        pickle.dump(step_strategy_sim_pair_dict, open(os.path.join(save_training_path, 'step_strategy_sim_pair_dict.pkl'), 'wb'))\n",
    "    \n",
    "    # validation/test recall results based on full_sim_pair_dict\n",
    "    # user-cf depend on sim-user history, so use all-click; test user history will not occur in train, so it's ok\n",
    "    print('obtain validate/test recall data')\n",
    "    all_user_item_dict = get_user_item_time_dict(all_click) \n",
    "    val_user_recall_item_dict = do_multi_recall_results_multi_processing(full_sim_pair_dict, \n",
    "                                                                    all_user_item_dict, \n",
    "                                                                    target_user_ids=click_test['user_id'].unique(), ret_type='tuple')\n",
    "    \n",
    "    pickle.dump(val_user_recall_item_dict, open(os.path.join(save_training_path, 'val_user_recall_item_dict.pkl'), 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## recall-submit running"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_content_sim_dict = get_content_sim_item(item_feat_df, topk=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_path=underexpose_train, test_path=underexpose_test\n",
      "phase: 0\n",
      "bi-graph item-sim begin\n",
      "user-cf user-sim begin\n",
      "swing item-sim begin\n",
      "item-cf item-sim begin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18505/18505 [00:00<00:00, 272387.03it/s]\n",
      "100%|██████████| 40776/40776 [00:02<00:00, 20174.64it/s]\n",
      "100%|██████████| 18505/18505 [00:00<00:00, 22298.53it/s]\n",
      " 12%|█▏        | 2233/18505 [00:05<00:40, 401.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user-cf user-sim-pair done, pair_num=18505\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40776/40776 [00:05<00:00, 6820.10it/s] \n",
      " 34%|███▍      | 13997/40776 [00:08<00:14, 1903.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "swing item-sim-pair done, pair_num=40770\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40776/40776 [00:23<00:00, 1704.39it/s]\n",
      " 52%|█████▏    | 9661/18505 [00:26<00:31, 283.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bi-graph item-sim-pair done, pair_num=40776\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18505/18505 [00:47<00:00, 389.96it/s]\n",
      "100%|██████████| 40776/40776 [00:02<00:00, 14901.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "item-cf item-sim-pair done, pair_num=40776\n",
      "do recall for user-cf\n",
      "do recall for swing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1663/1663 [00:01<00:00, 1150.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "swing recall done, recall_user_num=1663.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████     | 851/1663 [00:21<00:26, 30.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "do recall for bi-graph\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1663/1663 [00:17<00:00, 95.65it/s] \n",
      " 95%|█████████▌| 1584/1663 [00:39<00:01, 47.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bi-graph recall done, recall_user_num=1663.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 1596/1663 [00:39<00:01, 53.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "do recall for item-cf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1663/1663 [00:41<00:00, 39.75it/s]\n",
      " 12%|█▏        | 200/1663 [00:02<00:22, 66.36it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user-cf recall done, recall_user_num=1663.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1663/1663 [00:17<00:00, 95.43it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "item-cf recall done, recall_user_num=1663.\n",
      "4\n",
      "aggregate recall results begin....\n",
      "phase: 1\n",
      "bi-graph item-sim begin\n",
      "user-cf user-sim begin\n",
      "swing item-sim begin\n",
      "item-cf item-sim begin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18672/18672 [00:00<00:00, 275088.50it/s]\n",
      "100%|██████████| 41409/41409 [00:02<00:00, 20633.95it/s]\n",
      "100%|██████████| 18672/18672 [00:00<00:00, 21818.79it/s]\n",
      " 59%|█████▊    | 24263/41409 [00:04<00:01, 10799.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user-cf user-sim-pair done, pair_num=18672\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 41409/41409 [00:05<00:00, 6989.71it/s] \n",
      " 32%|███▏      | 13193/41409 [00:07<00:15, 1765.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "swing item-sim-pair done, pair_num=41401\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 41409/41409 [00:24<00:00, 1704.22it/s]\n",
      " 90%|█████████ | 16881/18672 [00:45<00:03, 455.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bi-graph item-sim-pair done, pair_num=41409\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18672/18672 [00:49<00:00, 377.27it/s]\n",
      "100%|██████████| 41409/41409 [00:02<00:00, 14489.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "item-cf item-sim-pair done, pair_num=41409\n",
      "do recall for user-cf\n",
      "do recall for swing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1726/1726 [00:01<00:00, 969.36it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "swing recall done, recall_user_num=1726.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 635/1726 [00:21<00:45, 23.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "do recall for bi-graph\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 1165/1726 [00:41<00:25, 22.33it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "do recall for item-cf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1726/1726 [00:21<00:00, 78.97it/s] \n",
      " 15%|█▌        | 260/1726 [00:03<00:25, 57.87it/s]]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bi-graph recall done, recall_user_num=1726.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1726/1726 [00:55<00:00, 30.85it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user-cf recall done, recall_user_num=1726.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1726/1726 [00:22<00:00, 76.98it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "item-cf recall done, recall_user_num=1726.\n",
      "4\n",
      "aggregate recall results begin....\n",
      "phase: 2\n",
      "bi-graph item-sim begin\n",
      "user-cf user-sim begin\n",
      "swing item-sim begin\n",
      "item-cf item-sim begin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18398/18398 [00:00<00:00, 256224.26it/s]\n",
      "100%|██████████| 41031/41031 [00:02<00:00, 19313.00it/s]\n",
      "100%|██████████| 18398/18398 [00:00<00:00, 20772.11it/s]\n",
      " 13%|█▎        | 5196/41031 [00:03<00:23, 1522.08it/s]]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user-cf user-sim-pair done, pair_num=18398\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 41031/41031 [00:06<00:00, 6645.07it/s] \n",
      " 32%|███▏      | 13017/41031 [00:08<00:16, 1723.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "swing item-sim-pair done, pair_num=41026\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 41031/41031 [00:25<00:00, 1627.22it/s]\n",
      " 90%|█████████ | 16638/18398 [00:46<00:04, 438.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bi-graph item-sim-pair done, pair_num=41031\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18398/18398 [00:51<00:00, 360.58it/s]\n",
      "100%|██████████| 41031/41031 [00:03<00:00, 12541.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "item-cf item-sim-pair done, pair_num=41031\n",
      "do recall for user-cf\n",
      "do recall for swing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1690/1690 [00:01<00:00, 905.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "swing recall done, recall_user_num=1690.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 712/1690 [00:21<00:24, 39.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "do recall for bi-graph\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 1592/1690 [00:19<00:01, 96.79it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "do recall for item-cf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1690/1690 [00:20<00:00, 81.07it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bi-graph recall done, recall_user_num=1690.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1690/1690 [00:54<00:00, 31.13it/s]\n",
      " 51%|█████     | 858/1690 [00:12<00:11, 70.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user-cf recall done, recall_user_num=1690.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1690/1690 [00:22<00:00, 74.74it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "item-cf recall done, recall_user_num=1690.\n",
      "4\n",
      "aggregate recall results begin....\n",
      "phase: 3\n",
      "bi-graph item-sim begin\n",
      "user-cf user-sim begin\n",
      "swing item-sim begin\n",
      "item-cf item-sim begin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18821/18821 [00:00<00:00, 269889.28it/s]\n",
      "100%|██████████| 42815/42815 [00:02<00:00, 15773.58it/s]\n",
      "100%|██████████| 18821/18821 [00:01<00:00, 17368.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user-cf user-sim-pair done, pair_num=18821\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 42815/42815 [00:07<00:00, 5624.50it/s] \n",
      " 36%|███▌      | 15297/42815 [00:10<00:17, 1586.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "swing item-sim-pair done, pair_num=42809\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 42815/42815 [00:29<00:00, 1434.81it/s]\n",
      " 92%|█████████▏| 17353/18821 [00:55<00:03, 401.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bi-graph item-sim-pair done, pair_num=42815\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18821/18821 [00:59<00:00, 315.54it/s]\n",
      "100%|██████████| 42815/42815 [00:03<00:00, 11157.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "item-cf item-sim-pair done, pair_num=42815\n",
      "do recall for swing\n",
      "do recall for user-cf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1675/1675 [00:02<00:00, 612.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "swing recall done, recall_user_num=1675.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 534/1675 [00:25<01:06, 17.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "do recall for bi-graph\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 1538/1675 [00:23<00:01, 68.99it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "do recall for item-cf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1675/1675 [00:25<00:00, 66.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bi-graph recall done, recall_user_num=1675.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1675/1675 [01:09<00:00, 24.07it/s]\n",
      " 76%|███████▋  | 1279/1675 [00:20<00:04, 85.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user-cf recall done, recall_user_num=1675.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1675/1675 [00:25<00:00, 65.21it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "item-cf recall done, recall_user_num=1675.\n",
      "4\n",
      "aggregate recall results begin....\n",
      "phase: 4\n",
      "bi-graph item-sim begin\n",
      "user-cf user-sim begin\n",
      "swing item-sim begin\n",
      "item-cf item-sim begin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18618/18618 [00:00<00:00, 262362.42it/s]\n",
      "100%|██████████| 42840/42840 [00:02<00:00, 15458.48it/s]\n",
      "100%|██████████| 18618/18618 [00:01<00:00, 16644.63it/s]\n",
      " 12%|█▏        | 5332/42840 [00:04<00:31, 1182.19it/s]]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user-cf user-sim-pair done, pair_num=18618\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 42840/42840 [00:07<00:00, 5491.56it/s] \n",
      " 23%|██▎       | 4345/18618 [00:14<00:49, 288.44it/s]s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "swing item-sim-pair done, pair_num=42835\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 42840/42840 [00:31<00:00, 1370.38it/s]\n",
      " 91%|█████████ | 16972/18618 [00:58<00:05, 284.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bi-graph item-sim-pair done, pair_num=42840\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18618/18618 [01:03<00:00, 293.33it/s]\n",
      "100%|██████████| 42840/42840 [00:03<00:00, 11716.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "item-cf item-sim-pair done, pair_num=42840\n",
      "do recall for swing\n",
      "do recall for user-cf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1708/1708 [00:03<00:00, 509.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "swing recall done, recall_user_num=1708.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 563/1708 [00:28<01:29, 12.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "do recall for bi-graph\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 977/1708 [00:53<01:06, 10.94it/s]]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "do recall for item-cf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1708/1708 [00:29<00:00, 57.78it/s]\n",
      " 64%|██████▎   | 1085/1708 [00:59<00:43, 14.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bi-graph recall done, recall_user_num=1708.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1708/1708 [00:29<00:00, 57.73it/s]\n",
      " 91%|█████████ | 1551/1708 [01:23<00:16,  9.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "item-cf recall done, recall_user_num=1708.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1708/1708 [01:28<00:00, 19.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user-cf recall done, recall_user_num=1708.\n",
      "4\n",
      "aggregate recall results begin....\n",
      "phase: 5\n",
      "bi-graph item-sim begin\n",
      "user-cf user-sim begin\n",
      "swing item-sim begin\n",
      "item-cf item-sim begin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19459/19459 [00:00<00:00, 238160.71it/s]\n",
      "100%|██████████| 45630/45630 [00:03<00:00, 15133.25it/s]\n",
      "100%|██████████| 19459/19459 [00:01<00:00, 15625.82it/s]\n",
      " 13%|█▎        | 5830/45630 [00:05<00:34, 1165.71it/s]]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user-cf user-sim-pair done, pair_num=19459\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 45630/45630 [00:08<00:00, 5567.36it/s]\n",
      " 22%|██▏       | 4227/19459 [00:14<00:57, 267.17it/s]s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "swing item-sim-pair done, pair_num=45621\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 45630/45630 [00:34<00:00, 1326.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bi-graph item-sim-pair done, pair_num=45630\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19459/19459 [01:09<00:00, 280.70it/s]\n",
      "100%|██████████| 45630/45630 [00:03<00:00, 11695.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "item-cf item-sim-pair done, pair_num=45630\n",
      "do recall for swing\n",
      "do recall for user-cf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1798/1798 [00:03<00:00, 513.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "swing recall done, recall_user_num=1798.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 574/1798 [00:31<01:01, 19.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "do recall for bi-graph\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 1514/1798 [00:27<00:05, 48.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "do recall for item-cf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1798/1798 [00:31<00:00, 57.44it/s]\n",
      " 14%|█▍        | 255/1798 [00:05<00:31, 49.18it/s]]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bi-graph recall done, recall_user_num=1798.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1798/1798 [00:30<00:00, 58.07it/s]\n",
      " 93%|█████████▎| 1679/1798 [01:29<00:15,  7.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "item-cf recall done, recall_user_num=1798.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1798/1798 [01:33<00:00, 19.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user-cf recall done, recall_user_num=1798.\n",
      "4\n",
      "aggregate recall results begin....\n",
      "513000\n"
     ]
    }
   ],
   "source": [
    "# time-aware-direction item-cf\n",
    "recom_item = []\n",
    "print(\"train_path={}, test_path={}\".format(train_path, test_path))\n",
    "whole_click = pd.DataFrame()\n",
    "\n",
    "total_recom_df = pd.DataFrame()\n",
    "for c in range(now_phase + 1):\n",
    "    print('phase:', c)\n",
    "    click_train = pd.read_csv(train_path + '/underexpose_train_click-{}.csv'.format(c), header=None,\n",
    "                              names=['user_id', 'item_id', 'time'])\n",
    "    click_test = pd.read_csv(test_path + '/underexpose_test_click-{}.csv'.format(c), header=None,\n",
    "                              names=['user_id', 'item_id', 'time'])\n",
    "    click_q_time = pd.read_csv(test_path + '/underexpose_test_qtime-{}.csv'.format(c), header=None,\n",
    "                              names=['user_id', 'time'])\n",
    "\n",
    "    all_click = click_train.append(click_test)\n",
    "    whole_click = whole_click.append(all_click)\n",
    "    \n",
    "    recall_sim_pair_dict = get_multi_source_sim_dict_results_multi_processing(all_click, recall_methods={'item-cf', 'bi-graph', 'user-cf', 'swing'}) \n",
    "    user_item_time_dict = get_user_item_time_dict(all_click)\n",
    "    \n",
    "    recom_df = do_multi_recall_results_multi_processing(recall_sim_pair_dict, user_item_time_dict, target_user_ids=click_q_time['user_id'].unique(), ret_type='df')\n",
    "    recom_df['phase'] = c\n",
    "    total_recom_df = total_recom_df.append(recom_df)\n",
    "            \n",
    "save_recall_df_as_user_tuples_dict(total_recom_df)\n",
    "\n",
    "# find most popular items  \n",
    "top50_click = whole_click['item_id'].value_counts().index[:50].values\n",
    "top50_click = ','.join([str(i) for i in top50_click])\n",
    "result = get_predict(total_recom_df, 'sim', top50_click)\n",
    "result.to_csv(output_path + '/baseline_cf_v4.csv', index=False, header=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sliding construct training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_path=underexpose_train, test_path=underexpose_test\n",
      "swing item-sim begin\n",
      "bi-graph item-sim begin\n",
      "user-cf user-sim begin\n",
      "item-cf item-sim begin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18618/18618 [00:00<00:00, 179937.72it/s]\n",
      "100%|██████████| 42840/42840 [00:03<00:00, 10914.30it/s]\n",
      "100%|██████████| 18618/18618 [00:01<00:00, 14138.33it/s]\n",
      " 10%|▉         | 4142/42840 [00:08<00:34, 1109.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user-cf user-sim-pair done, pair_num=18618\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 27444/42840 [00:38<00:26, 586.62it/s] "
     ]
    }
   ],
   "source": [
    "for i in range(4, now_phase+1):\n",
    "    sliding_obtain_training_df(i, is_silding_compute_sim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_click"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for phase in range(now_phase+1):\n",
    "    sliding_obtain_training_df(phase, is_compute_sim_once=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "full_sim_pair_dict.pkl\tstep_user_recall_item_dict.pkl\r\n"
     ]
    }
   ],
   "source": [
    "!ls training/online/once/0/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coding=utf-8\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import datetime\n",
    "import json\n",
    "import sys\n",
    "import time\n",
    "from collections import defaultdict\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# the higher scores, the better performance\n",
    "def evaluate_each_phase(predictions, answers):\n",
    "    list_item_degress = []\n",
    "    for user_id in answers:\n",
    "        item_id, item_degree = answers[user_id]\n",
    "        list_item_degress.append(item_degree)\n",
    "    list_item_degress.sort()\n",
    "    median_item_degree = list_item_degress[len(list_item_degress) // 2]\n",
    "\n",
    "    num_cases_full = 0.0\n",
    "    ndcg_50_full = 0.0\n",
    "    ndcg_50_half = 0.0\n",
    "    num_cases_half = 0.0\n",
    "    hitrate_50_full = 0.0\n",
    "    hitrate_50_half = 0.0\n",
    "    for user_id in answers:\n",
    "        item_id, item_degree = answers[user_id]\n",
    "        rank = 0\n",
    "        while rank < 50 and predictions[user_id][rank] != item_id:\n",
    "            rank += 1\n",
    "        num_cases_full += 1.0\n",
    "        if rank < 50:\n",
    "            ndcg_50_full += 1.0 / np.log2(rank + 2.0)\n",
    "            hitrate_50_full += 1.0\n",
    "        if item_degree <= median_item_degree:\n",
    "            num_cases_half += 1.0\n",
    "            if rank < 50:\n",
    "                ndcg_50_half += 1.0 / np.log2(rank + 2.0)\n",
    "                hitrate_50_half += 1.0\n",
    "    ndcg_50_full /= num_cases_full\n",
    "    hitrate_50_full /= num_cases_full\n",
    "    ndcg_50_half /= num_cases_half\n",
    "    hitrate_50_half /= num_cases_half\n",
    "    return np.array([ndcg_50_full, ndcg_50_half,\n",
    "                     hitrate_50_full, hitrate_50_half], dtype=np.float32)\n",
    "\n",
    "# submit_fname is the path to the file submitted by the participants.\n",
    "# debias_track_answer.csv is the standard answer, which is not released.\n",
    "def evaluate(submit_fname,\n",
    "             answer_fname='debias_track_answer.csv', current_time=None):\n",
    "    schedule_in_unix_time = [\n",
    "        0,  # ........ 1970-01-01 08:00:00 (T=0)\n",
    "        1586534399,  # 2020-04-10 23:59:59 (T=1)\n",
    "        1587139199,  # 2020-04-17 23:59:59 (T=2)\n",
    "        1587743999,  # 2020-04-24 23:59:59 (T=3)\n",
    "        1588348799,  # 2020-05-01 23:59:59 (T=4)\n",
    "        1588953599,  # 2020-05-08 23:59:59 (T=5)\n",
    "        1589558399,  # 2020-05-15 23:59:59 (T=6)\n",
    "        1590163199,  # 2020-05-22 23:59:59 (T=7)\n",
    "        1590767999,  # 2020-05-29 23:59:59 (T=8)\n",
    "        1591372799  # .2020-06-05 23:59:59 (T=9)\n",
    "    ]\n",
    "    assert len(schedule_in_unix_time) == 10\n",
    "    for i in range(1, len(schedule_in_unix_time) - 1):\n",
    "        # 604800 == one week\n",
    "        assert schedule_in_unix_time[i] + 604800 == schedule_in_unix_time[i + 1]\n",
    "\n",
    "    if current_time is None:\n",
    "        current_time = int(time.time())\n",
    "    print('current_time:', current_time)\n",
    "    print('date_time:', datetime.datetime.fromtimestamp(current_time))\n",
    "    current_phase = 0\n",
    "    while (current_phase < 9) and (\n",
    "            current_time > schedule_in_unix_time[current_phase + 1]):\n",
    "        current_phase += 1\n",
    "    print('current_phase:', current_phase)\n",
    "  \n",
    "    try:\n",
    "        answers = [{} for _ in range(10)]\n",
    "        with open(answer_fname, 'r') as fin:\n",
    "            for line in fin:\n",
    "                line = [int(x) for x in line.split(',')]\n",
    "                phase_id, user_id, item_id, item_degree = line\n",
    "                if mode == 'online':\n",
    "                  assert user_id % 11 == phase_id\n",
    "                # exactly one test case for each user_id\n",
    "                answers[phase_id][user_id] = (item_id, item_degree)\n",
    "    except Exception as e:\n",
    "        return print('server-side error: answer file incorrect', e)\n",
    "\n",
    "    try:\n",
    "        predictions = {}\n",
    "        with open(submit_fname, 'r') as fin:\n",
    "            for line in fin:\n",
    "                line = line.strip()\n",
    "                if line == '':\n",
    "                    continue\n",
    "                line = line.split(',')\n",
    "                user_id = int(line[0])\n",
    "                if user_id in predictions:\n",
    "                    return print('submitted duplicate user_ids')\n",
    "                item_ids = [int(i) for i in line[1:]]\n",
    "                if len(item_ids) != 50:\n",
    "                    return print('each row need have 50 items')\n",
    "                if len(set(item_ids)) != 50:\n",
    "                    return print('each row need have 50 DISTINCT items')\n",
    "                predictions[user_id] = item_ids\n",
    "    except Exception as e:\n",
    "        return print('submission not in correct format,e={}'.format(e))\n",
    "\n",
    "    scores = np.zeros(4, dtype=np.float32)\n",
    "\n",
    "    # The final winning teams will be decided based on phase T=7,8,9 only.\n",
    "    # We thus fix the scores to 1.0 for phase 0,1,2,...,6 at the final stage.\n",
    "    if current_phase >= 7:  # if at the final stage, i.e., T=7,8,9\n",
    "        scores += 7.0  # then fix the scores to 1.0 for phase 0,1,2,...,6\n",
    "    phase_beg = (7 if (current_phase >= 7) else 0)\n",
    "    phase_end = current_phase + 1\n",
    "    for phase_id in range(phase_beg, phase_end):\n",
    "        for user_id in answers[phase_id]:\n",
    "            if user_id not in predictions:\n",
    "                return print('user_id %d of phase %d not in submission' % (\n",
    "                        user_id, phase_id))\n",
    "        try:\n",
    "            # We sum the scores from all the phases, instead of averaging them.\n",
    "            phase_score = evaluate_each_phase(predictions, answers[phase_id])\n",
    "            print('phase_id={}, score={}'.format(phase_id, phase_score))\n",
    "            scores += phase_score\n",
    "        except Exception as e:\n",
    "            return print('error occurred during evaluation, e={}'.format(e))\n",
    "    \n",
    "    print(\"score={},\\nhitrate_50_full={},\\nndcg_50_full={},\\nhitrate_50_half={}, \\nndcg_50_half={}\".format(\n",
    "        float(scores[0]), float(scores[2]), float(scores[0]), float(scores[3]), float(scores[1])\n",
    "    ))\n",
    "    return scores[0]\n",
    "    # return report_score(\n",
    "    #     stdout, score=float(scores[0]),\n",
    "    #     ndcg_50_full=float(scores[0]), ndcg_50_half=float(scores[1]),\n",
    "    #     hitrate_50_full=float(scores[2]), hitrate_50_half=float(scores[3]))\n",
    "\n",
    "# FYI. You can create a fake answer file for validation based on this. For example,\n",
    "# you can mask the latest ONE click made by each user in underexpose_test_click-T.csv,\n",
    "# and use those masked clicks to create your own validation set, i.e.,\n",
    "# a fake underexpose_test_qtime_with_answer-T.csv for validation.\n",
    "def _create_answer_file_for_evaluation(output_answer_fname='debias_track_answer.csv'):\n",
    "    train = train_path + '/underexpose_train_click-%d.csv'\n",
    "    test = test_path + '/underexpose_test_click-%d.csv'\n",
    "\n",
    "    # underexpose_test_qtime-T.csv contains only <user_id, time>\n",
    "    # underexpose_test_qtime_with_answer-T.csv contains <user_id, item_id, time>\n",
    "    answer = offline_answer_path + '/underexpose_test_qtime_with_answer-%d.csv'  # not released\n",
    "\n",
    "    item_deg = defaultdict(lambda: 0)\n",
    "    with open(output_answer_fname, 'w') as fout:\n",
    "        for phase_id in range(now_phase+1):\n",
    "            with open(train % phase_id) as fin:\n",
    "                for line in fin:\n",
    "                    user_id, item_id, timestamp = line.split(',')\n",
    "                    user_id, item_id, timestamp = (\n",
    "                        int(user_id), int(item_id), float(timestamp))\n",
    "                    item_deg[item_id] += 1\n",
    "            with open(test % phase_id) as fin:\n",
    "                for line in fin:\n",
    "                    user_id, item_id, timestamp = line.split(',')\n",
    "                    user_id, item_id, timestamp = (\n",
    "                        int(user_id), int(item_id), float(timestamp))\n",
    "                    item_deg[item_id] += 1\n",
    "            with open(answer % phase_id) as fin:\n",
    "                for line in fin:\n",
    "                    user_id, item_id, timestamp = line.split(',')\n",
    "                    user_id, item_id, timestamp = (\n",
    "                        int(user_id), int(item_id), float(timestamp))\n",
    "                    if mode == 'online':\n",
    "                       assert user_id % 11 == phase_id\n",
    "                    print(phase_id, user_id, item_id, item_deg[item_id],\n",
    "                          sep=',', file=fout)\n",
    "                    \n",
    "\n",
    "# submit_fname is the path to the file submitted by the participants.\n",
    "# debias_track_answer.csv is the standard answer, which is not released.\n",
    "def evaluate_target_phase(submit_fname, target_phase, \n",
    "             answer_fname='debias_track_answer.csv', current_time=None):\n",
    "    schedule_in_unix_time = [\n",
    "        0,  # ........ 1970-01-01 08:00:00 (T=0)\n",
    "        1586534399,  # 2020-04-10 23:59:59 (T=1)\n",
    "        1587139199,  # 2020-04-17 23:59:59 (T=2)\n",
    "        1587743999,  # 2020-04-24 23:59:59 (T=3)\n",
    "        1588348799,  # 2020-05-01 23:59:59 (T=4)\n",
    "        1588953599,  # 2020-05-08 23:59:59 (T=5)\n",
    "        1589558399,  # 2020-05-15 23:59:59 (T=6)\n",
    "        1590163199,  # 2020-05-22 23:59:59 (T=7)\n",
    "        1590767999,  # 2020-05-29 23:59:59 (T=8)\n",
    "        1591372799  # .2020-06-05 23:59:59 (T=9)\n",
    "    ]\n",
    "    assert len(schedule_in_unix_time) == 10\n",
    "    for i in range(1, len(schedule_in_unix_time) - 1):\n",
    "        # 604800 == one week\n",
    "        assert schedule_in_unix_time[i] + 604800 == schedule_in_unix_time[i + 1]\n",
    "\n",
    "    if current_time is None:\n",
    "        current_time = int(time.time())\n",
    "    print('current_time:', current_time)\n",
    "    print('date_time:', datetime.datetime.fromtimestamp(current_time))\n",
    "    current_phase = 0\n",
    "    while (current_phase < 9) and (\n",
    "            current_time > schedule_in_unix_time[current_phase + 1]):\n",
    "        current_phase += 1\n",
    "    print('current_phase:', current_phase)\n",
    "  \n",
    "    try:\n",
    "        answers = [{} for _ in range(10)]\n",
    "        with open(answer_fname, 'r') as fin:\n",
    "            for line in fin:\n",
    "                line = [int(x) for x in line.split(',')]\n",
    "                phase_id, user_id, item_id, item_degree = line\n",
    "                # assert user_id % 11 == phase_id\n",
    "                # exactly one test case for each user_id\n",
    "                answers[phase_id][user_id] = (item_id, item_degree)\n",
    "    except Exception as e:\n",
    "        return print('server-side error: answer file incorrect', e)\n",
    "\n",
    "    try:\n",
    "        predictions = {}\n",
    "        with open(submit_fname, 'r') as fin:\n",
    "            for line in fin:\n",
    "                line = line.strip()\n",
    "                if line == '':\n",
    "                    continue\n",
    "                line = line.split(',')\n",
    "                user_id = int(line[0])\n",
    "                if user_id in predictions:\n",
    "                    return print('submitted duplicate user_ids')\n",
    "                item_ids = [int(i) for i in line[1:]]\n",
    "                if len(item_ids) != 50:\n",
    "                    return print('each row need have 50 items')\n",
    "                if len(set(item_ids)) != 50:\n",
    "                    return print('each row need have 50 DISTINCT items')\n",
    "                predictions[user_id] = item_ids\n",
    "    except Exception as e:\n",
    "        return print('submission not in correct format,e={}'.format(e))\n",
    "\n",
    "    scores = np.zeros(4, dtype=np.float32)\n",
    "\n",
    "    # The final winning teams will be decided based on phase T=7,8,9 only.\n",
    "    # We thus fix the scores to 1.0 for phase 0,1,2,...,6 at the final stage.\n",
    "    if current_phase >= 7:  # if at the final stage, i.e., T=7,8,9\n",
    "        scores += 7.0  # then fix the scores to 1.0 for phase 0,1,2,...,6\n",
    "    phase_beg = (7 if (current_phase >= 7) else 0)\n",
    "    phase_end = current_phase + 1\n",
    "    for phase_id in [target_phase]:\n",
    "        for user_id in answers[phase_id]:\n",
    "            if user_id not in predictions:\n",
    "                return print('user_id %d of phase %d not in submission' % (\n",
    "                        user_id, phase_id))\n",
    "        try:\n",
    "            # We sum the scores from all the phases, instead of averaging them.\n",
    "            phase_score = evaluate_each_phase(predictions, answers[phase_id])\n",
    "            print('phase_id={}, score={}'.format(phase_id, phase_score))\n",
    "            scores += phase_score\n",
    "        except Exception as e:\n",
    "            return print('error occurred during evaluation e={}'.format(e))\n",
    "    \n",
    "    print(\"score={},\\nhitrate_50_full={},\\nndcg_50_full={},\\nhitrate_50_half={}, \\nndcg_50_half={}\".format(\n",
    "        float(scores[0]), float(scores[2]), float(scores[0]), float(scores[3]), float(scores[1])\n",
    "    ))\n",
    "    return scores[0]\n",
    "    # return report_score(\n",
    "    #     stdout, score=float(scores[0]),\n",
    "    #     ndcg_50_full=float(scores[0]), ndcg_50_half=float(scores[1]),\n",
    "    #     hitrate_50_full=float(scores[2]), hitrate_50_half=float(scores[3]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read answers(val data) in offline_answer_path, and output to output_answer_fname\n",
    "_create_answer_file_for_evaluation(output_answer_fname=output_path +'/debias_track_answer.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_time: 1589113093\n",
      "date_time: 2020-05-10 12:18:13\n",
      "current_phase: 5\n",
      "phase_id=0, score=[0.05561217 0.03750644 0.124375   0.08455115]\n",
      "phase_id=1, score=[0.06618372 0.03779866 0.141875   0.08430913]\n",
      "phase_id=2, score=[0.0620118  0.04202654 0.155625   0.10571081]\n",
      "phase_id=3, score=[0.05628263 0.03226046 0.14       0.09307876]\n",
      "phase_id=4, score=[0.06485526 0.05119485 0.15       0.10974106]\n",
      "phase_id=5, score=[0.06123232 0.03808351 0.14125    0.08991495]\n",
      "score=0.36617788672447205,\n",
      "hitrate_50_full=0.8531249761581421,\n",
      "ndcg_50_full=0.36617788672447205,\n",
      "hitrate_50_half=0.567305862903595, \n",
      "ndcg_50_half=0.23887042701244354\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.3661779"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(submit_fname=output_path + \"/baseline_cf_v4.csv\", \n",
    "         answer_fname=output_path +'/debias_track_answer.csv') # topk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_time: 1589169665\n",
      "date_time: 2020-05-11 04:01:05\n",
      "current_phase: 5\n",
      "phase_id=0, score=[0.05550259 0.03771673 0.12375    0.08559499]\n",
      "phase_id=1, score=[0.06563789 0.03697544 0.1425     0.08430913]\n",
      "phase_id=2, score=[0.0617016  0.0421126  0.153125   0.10571081]\n",
      "phase_id=3, score=[0.0563484  0.03240005 0.139375   0.09307876]\n",
      "phase_id=4, score=[0.06493273 0.05105051 0.150625   0.10974106]\n",
      "phase_id=5, score=[0.06160757 0.03814993 0.143125   0.09113001]\n",
      "score=0.36573076248168945,\n",
      "hitrate_50_full=0.8525000214576721,\n",
      "ndcg_50_full=0.36573076248168945,\n",
      "hitrate_50_half=0.5695647597312927, \n",
      "ndcg_50_half=0.2384052723646164\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.36573076"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(submit_fname=output_path + \"/baseline_cf_v4.csv\", \n",
    "         answer_fname=output_path +'/debias_track_answer.csv') # topk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "upload: sub_online/baseline_cf_v4.csv to s3://mx-machine-learning/xuetaofeng/kdd/phase/5/baseline_cf_v4.csv\n",
      "upload: sub_online/baseline_cf_v4.csv to s3://mx-machine-learning/xuetaofeng/kdd/phase/5/baseline_cf_v4.csv\n",
      "upload: sub_online/baseline_cf_v4.csv to s3://mx-machine-learning/xuetaofeng/kdd/phase/5/baseline_cf_v4.csv\n",
      "upload: sub_online/baseline_cf_v4.csv to s3://mx-machine-learning/xuetaofeng/kdd/phase/5/baseline_cf_v4.csv\n"
     ]
    }
   ],
   "source": [
    "!aws s3 cp sub_online/baseline_cf_v4.csv s3://mx-machine-learning/xuetaofeng/kdd/phase/5/baseline_cf_v4.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read answers(val data) in offline_answer_path, and output to output_answer_fname\n",
    "_create_answer_file_for_evaluation(output_answer_fname=output_path +'/debias_track_answer.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_time: 1589362639\n",
      "date_time: 2020-05-13 09:37:19\n",
      "current_phase: 5\n",
      "phase_id=5, score=[0.06493513 0.03897732 0.14625    0.08991495]\n",
      "score=0.0649351254105568,\n",
      "hitrate_50_full=0.14624999463558197,\n",
      "ndcg_50_full=0.0649351254105568,\n",
      "hitrate_50_half=0.0899149477481842, \n",
      "ndcg_50_half=0.03897732496261597\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.064935125"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_target_phase(output_path + \"/baseline_recall_v1_phase_5.csv\", 5, \n",
    "         answer_fname=output_path +'/debias_track_answer.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_time: 1589367947\n",
      "date_time: 2020-05-13 11:05:47\n",
      "current_phase: 5\n",
      "phase_id=0, score=[0.05982477 0.04083483 0.133125   0.09290188]\n",
      "score=0.05982477217912674,\n",
      "hitrate_50_full=0.13312500715255737,\n",
      "ndcg_50_full=0.05982477217912674,\n",
      "hitrate_50_half=0.09290187805891037, \n",
      "ndcg_50_half=0.040834832936525345\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.059824772"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_target_phase(output_path + \"/baseline_recall_v1_phase_0.csv\", 0, \n",
    "         answer_fname=output_path +'/debias_track_answer.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_time: 1589367953\n",
      "date_time: 2020-05-13 11:05:53\n",
      "current_phase: 5\n",
      "phase_id=0, score=[0.06224673 0.04148717 0.14625    0.09812108]\n",
      "score=0.06224673241376877,\n",
      "hitrate_50_full=0.14624999463558197,\n",
      "ndcg_50_full=0.06224673241376877,\n",
      "hitrate_50_half=0.09812108427286148, \n",
      "ndcg_50_half=0.04148716852068901\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.062246732"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_target_phase(output_path + \"/baseline_ranking_v1_phase_0_offline.csv\", 0, \n",
    "         answer_fname=output_path +'/debias_track_answer.csv') # online_total_click gbdt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_time: 1589211630\n",
      "date_time: 2020-05-11 15:40:30\n",
      "current_phase: 5\n",
      "phase_id=0, score=[0.06415642 0.03102796 0.14375    0.07724426]\n",
      "score=0.0641564205288887,\n",
      "hitrate_50_full=0.14374999701976776,\n",
      "ndcg_50_full=0.0641564205288887,\n",
      "hitrate_50_half=0.07724425941705704, \n",
      "ndcg_50_half=0.031027959659695625\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.06415642"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_target_phase(output_path + \"/baseline_ranking_v1_phase_0_offline.csv\", 0, \n",
    "         answer_fname=output_path +'/debias_track_answer.csv') # gbdt+sliding, offline_total_click"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_time: 1589348256\n",
      "date_time: 2020-05-13 05:37:36\n",
      "current_phase: 5\n",
      "phase_id=5, score=[0.06714715 0.04146599 0.151875   0.09356014]\n",
      "score=0.0671471506357193,\n",
      "hitrate_50_full=0.15187500417232513,\n",
      "ndcg_50_full=0.0671471506357193,\n",
      "hitrate_50_half=0.09356014430522919, \n",
      "ndcg_50_half=0.041465990245342255\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.06714715"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_target_phase(output_path + \"/baseline_ranking_v1_phase_5_offline.csv\", 5, \n",
    "         answer_fname=output_path +'/debias_track_answer.csv') # gbdt + sliding + （no item statistic feat）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_time: 1589352800\n",
      "date_time: 2020-05-13 06:53:20\n",
      "current_phase: 5\n",
      "phase_id=5, score=[0.06716888 0.04090553 0.151875   0.09234508]\n",
      "score=0.06716888397932053,\n",
      "hitrate_50_full=0.15187500417232513,\n",
      "ndcg_50_full=0.06716888397932053,\n",
      "hitrate_50_half=0.09234508126974106, \n",
      "ndcg_50_half=0.040905531495809555\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.067168884"
      ]
     },
     "execution_count": 327,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_target_phase(output_path + \"/baseline_ranking_v1_phase_5_offline.csv\", 5, \n",
    "         answer_fname=output_path +'/debias_track_answer.csv') # gbdt + sliding + fix interest degree bug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_time: 1589365750\n",
      "date_time: 2020-05-13 10:29:10\n",
      "current_phase: 5\n",
      "phase_id=5, score=[0.07039623 0.04510698 0.161875   0.10085054]\n",
      "score=0.07039622962474823,\n",
      "hitrate_50_full=0.16187499463558197,\n",
      "ndcg_50_full=0.07039622962474823,\n",
      "hitrate_50_half=0.10085054486989975, \n",
      "ndcg_50_half=0.04510698467493057\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.07039623"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_target_phase(output_path + \"/baseline_ranking_v1_phase_5_offline.csv\", 5, \n",
    "         answer_fname=output_path +'/debias_track_answer.csv') # din + sliding + hist-feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_time: 1589366433\n",
      "date_time: 2020-05-13 10:40:33\n",
      "current_phase: 5\n",
      "phase_id=5, score=[0.07039623 0.04510698 0.161875   0.10085054]\n",
      "score=0.07039622962474823,\n",
      "hitrate_50_full=0.16187499463558197,\n",
      "ndcg_50_full=0.07039622962474823,\n",
      "hitrate_50_half=0.10085054486989975, \n",
      "ndcg_50_half=0.04510698467493057\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.07039623"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_target_phase(output_path + \"/baseline_ranking_v1_phase_5_offline.csv\", 5, \n",
    "         answer_fname=output_path +'/debias_track_answer.csv') # din + sliding + offline info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ranking data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### organize recall feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "t = (2020, 4, 10, 0, 0, 0, 0, 0, 0)\n",
    "time_end = time.mktime(t)\n",
    "max_day, max_hour, max_miniute = 7, 24, 60\n",
    "\n",
    "def time_info(time_delta):\n",
    "    timestamp = time_end * time_delta\n",
    "    struct_time = time.gmtime(timestamp)\n",
    "    day, hour, mini = struct_time.tm_wday+1, struct_time.tm_hour+1, struct_time.tm_min+1\n",
    "    return (day, hour, mini)\n",
    "\n",
    "def obtain_user_hist_feat(u, user_item_dict):\n",
    "    user_hist_seq = [i for i, t in user_item_dict[u]]\n",
    "    user_hist_day_seq, user_hist_hour_seq, user_hist_min_seq = zip(*[time_info(t) for i, t in user_item_dict[u]])\n",
    "    return [user_hist_seq, list(user_hist_day_seq), list(user_hist_hour_seq), list(user_hist_min_seq)]\n",
    "  \n",
    "def organize_recall_feat_each_user(u, recall_items, user_item_dict, strategy_item_sim_dict, phase):\n",
    "    user_hist_info = obtain_user_hist_feat(u, user_item_dict)\n",
    "    \n",
    "    # hist-item similarity with recall items\n",
    "    hist_num = 3\n",
    "    recall_items_sum_cf_sim2_hist = []\n",
    "    recall_items_max_cf_sim2_hist = []\n",
    "    recall_items_cnt_sim2_hist = []\n",
    "    user_hist_items = user_item_dict[u][::-1][-hist_num:]\n",
    "\n",
    "    for recall_i, rating in recall_items:\n",
    "        if rating > 0:\n",
    "            max_cf_sim2_hist = []\n",
    "            sum_cf_sim2_hist = []\n",
    "            cnt_sim2_hist = []\n",
    "            for hist_i, t in user_hist_items:\n",
    "                sum_sim_value = 0.0\n",
    "                max_sim_value = 0.0\n",
    "               \n",
    "                for strategy, item_sim_dict in strategy_item_sim_dict.items():\n",
    "                    strategy_sim_value = item_sim_dict.get(hist_i, {}).get(recall_i, 0.0) + item_sim_dict.get(recall_i, {}).get(hist_i, 0.0)\n",
    "                    sum_sim_value += strategy_sim_value\n",
    "                    max_sim_value = max(max_sim_value, strategy_sim_value)\n",
    "                    \n",
    "                cnt_sim_value = item_content_sim_dict.get(hist_i, {}).get(recall_i, 0.0) + item_content_sim_dict.get(recall_i, {}).get(hist_i, 0.0)\n",
    "      \n",
    "                sum_cf_sim2_hist.append(sum_sim_value)\n",
    "                max_cf_sim2_hist.append(max_sim_value)\n",
    "                cnt_sim2_hist.append(cnt_sim_value)\n",
    "\n",
    "            while len(sum_cf_sim2_hist) < hist_num:\n",
    "                sum_cf_sim2_hist.append(0.0)\n",
    "                max_cf_sim2_hist.append(0.0)\n",
    "                cnt_sim2_hist.append(0.0)\n",
    "                \n",
    "        else:\n",
    "            sum_cf_sim2_hist = [0.0] * hist_num\n",
    "            max_cf_sim2_hist = [0.0] * hist_num\n",
    "            cnt_sim2_hist = [0.0] * hist_num\n",
    "\n",
    "        recall_items_sum_cf_sim2_hist.append(sum_cf_sim2_hist)\n",
    "        recall_items_max_cf_sim2_hist.append(max_cf_sim2_hist)\n",
    "        recall_items_cnt_sim2_hist.append(cnt_sim2_hist)\n",
    "    \n",
    "    recom_item = []\n",
    "    for item_rating, sum_cf_sim2_hist, max_cf_sim2_hist, cnt_sim2_hist in zip(recall_items, recall_items_sum_cf_sim2_hist, recall_items_max_cf_sim2_hist, recall_items_cnt_sim2_hist):\n",
    "        recom_item.append([u, item_rating[0], item_rating[1], phase] + sum_cf_sim2_hist + max_cf_sim2_hist + \\\n",
    "                          cnt_sim2_hist + user_hist_info)\n",
    "        \n",
    "    return recom_item\n",
    "\n",
    "def organize_recall_feat(recall_item_dict, user_item_hist_dict, item_sim_dict, phase):\n",
    "    recom_columns = ['user_id', 'item_id', 'sim', 'phase'] + \\\n",
    "                      ['sum_sim2int_1', 'sum_sim2int_2', 'sum_sim2int_3'] + \\\n",
    "                             ['max_sim2int_1', 'max_sim2int_2', 'max_sim2int_3']  + \\\n",
    "                        ['cnt_sim2int_1', 'cnt_sim2int_2', 'cnt_sim2int_3'] + \\\n",
    "                          ['hist_item_id', 'hist_day_id', 'hist_hour_id', 'hist_minute_id']\n",
    "    recom_item = []\n",
    "    for u, recall_items in recall_item_dict.items():\n",
    "        recom_item.extend(organize_recall_feat_each_user(u, recall_items, user_item_hist_dict, item_sim_dict, phase))\n",
    "\n",
    "    recall_recom_df = pd.DataFrame(recom_item, columns=recom_columns)\n",
    "    recall_recom_df['sim_rank_score'] = recall_recom_df.groupby('user_id')['sim'].rank(method='first', ascending=True) / topk_num\n",
    "    \n",
    "    return recall_recom_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### organize label "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "basic_columns = ['user_id','item_id', 'phase', 'label', ]\n",
    "time_columns = ['time', 'day_id', 'hour_id', 'minute_id']\n",
    "hist_columns = ['hist_item_id', 'hist_day_id', 'hist_hour_id', 'hist_minute_id',]\n",
    "sim_columns = ['sim', 'sum_sim2int_1', 'sum_sim2int_2', 'sum_sim2int_3'] + \\\n",
    "                             ['max_sim2int_1', 'max_sim2int_2', 'max_sim2int_3', 'sim_rank_score']  + \\\n",
    "                              ['cnt_sim2int_1', 'cnt_sim2int_2', 'cnt_sim2int_3']\n",
    "\n",
    "use_columns =  basic_columns + hist_columns + sim_columns + time_columns\n",
    "\n",
    "def organize_label_interact_feat_df(click_last_df, click_last_recall_recom_df, phase, is_consider_cold_start=True):\n",
    "    dfm_df = pd.merge(click_last_recall_recom_df, click_last_df[['user_id', 'item_id', 'time']], on=['user_id', 'item_id'], how='left') \n",
    "    dfm_df['label'] = dfm_df['time'].apply(lambda x: 0.0 if np.isnan(x) else 1.0) # time非空代表该click-item被召回了\n",
    "    del dfm_df['time']\n",
    "\n",
    "    # merge_time\n",
    "    click_last_df['day_id'],  click_last_df['hour_id'], click_last_df['minute_id'] = zip(*click_last_df['time'].apply(time_info))\n",
    "    dfm_df = pd.merge(dfm_df, click_last_df[['user_id', 'time', 'day_id', 'hour_id', 'minute_id']], on='user_id', how='left')\n",
    "\n",
    "\n",
    "    # click_last_df里头有些用户的点击没有召回到，即：全部为负样本，导致下采样时，这些用户的负样本可能全被下采样掉了，导致这些用户id丢失；\n",
    "    # item同理。用户真实点击的item可能没有召回到。\n",
    "    dfm_df = downsample_by_user(dfm_df)\n",
    "    dfm_df = dfm_df[use_columns]\n",
    "\n",
    "    # cold_start_item直接泄露, 这些item可能在infer阶段被recall到，导致item_id缺失\n",
    "    cold_start_items = set(click_last_df['item_id'].unique()) - set(dfm_df['item_id'].unique())\n",
    "    if is_consider_cold_start and len(cold_start_items) > 0:\n",
    "        click_last_cold_start_df = click_last_df[click_last_df['item_id'].isin(cold_start_items)]\n",
    "        click_last_cold_start_df['label'] = 1.0\n",
    "        click_last_cold_start_df['phase'] = phase\n",
    "        for sim_col in sim_columns:\n",
    "            mean_value = dfm_df[dfm_df['label'] == 1.0][sim_col].mean()\n",
    "            print('sim_col={}, mean_value={}'.format(sim_col, mean_value))\n",
    "            click_last_cold_start_df[sim_col] = mean_value\n",
    "        click_last_cold_start_df = pd.merge(click_last_cold_start_df, dfm_df[['user_id',] + hist_columns], on='user_id', how='left')\n",
    "    \n",
    "        print('cold_start_item_num={}, hit_last_cold_start_df_num={}'.format(len(cold_start_items), len(click_last_cold_start_df)))\n",
    "        dfm_df = dfm_df.append(click_last_cold_start_df[use_columns])\n",
    "\n",
    "#     dfm_df = sim_process(dfm_df) # TODO, 移动到召回里头呢？\n",
    "    return dfm_df\n",
    "\n",
    "# def sim_process(dfm_df):\n",
    "#     def norm_sim_by_user(sim_df):\n",
    "#         min_sim = sim_df.min()\n",
    "#         max_sim = sim_df.max()\n",
    "#         if max_sim == min_sim:\n",
    "#             sim_df = sim_df.apply(lambda sim: 1.0)\n",
    "#         else:\n",
    "#             sim_df = sim_df.apply(lambda sim: 1.0 * (sim - min_sim) / (max_sim - min_sim))\n",
    "#         return sim_df\n",
    "    \n",
    "#     dfm_df['sim'] = dfm_df.groupby('user_id')['sim'].transform(norm_sim_by_user) \n",
    "#     dfm_df['exp_sim'] =  dfm_df['sim'].apply(lambda x: np.exp(x))\n",
    "#     return dfm_df\n",
    "\n",
    "\n",
    "def downsample_by_user(df, percent=10):\n",
    "    '''\n",
    "    percent:多数类别下采样的数量相对于少数类别样本数量的比例\n",
    "    '''\n",
    "    data_pos = df[df['label'] != 0]\n",
    "    data_neg = df[df['label'] == 0]\n",
    "\n",
    "    def group_neg_sample_func(group_df):\n",
    "        total_neg_num = len(group_df)\n",
    "        sample_num = max(int(total_neg_num * 0.002), 1) # 有些用户召回的数量不足, 取1个\n",
    "        sample_num = min(sample_num, 5)\n",
    "        return group_df.sample(n=sample_num, replace=True)\n",
    "\n",
    "    data_u_neg = data_neg.groupby('user_id', group_keys=False).apply(group_neg_sample_func) # # 保证user全覆盖\n",
    "    data_i_neg = data_neg.groupby('item_id', group_keys=False).apply(group_neg_sample_func) # 保证item全覆盖\n",
    "    data_neg = data_u_neg.append(data_i_neg)\n",
    "    data_neg = data_neg.sort_values(['user_id', 'sim']).drop_duplicates(['user_id', 'item_id'], keep='last')\n",
    "\n",
    "    data = pd.concat([data_neg, data_pos], ignore_index=True)\n",
    "    data = data.sample(frac=1.0)\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### organize interact train/val data\n",
    "\n",
    "1. 先获取steps的recall结果以及对应的 strategy_item_sim_dict\n",
    "\n",
    "处理训练集：\n",
    "2. 接着对每个step, \n",
    "      进行organize recall feat \n",
    "3. 对full_step_df进行organize label操作\n",
    " \n",
    "处理验证集\n",
    "1.  对验证集进行organize recall feat \n",
    "2. 对验证集也进行organize label操作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "def organize_train_data(c, is_silding_compute_sim=False, online_is_eval=False):\n",
    "    # 1. 获取recall的结果\n",
    "    compute_mode = 'once' if not is_silding_compute_sim else 'multi'\n",
    "    save_training_path = os.path.join('training', mode, compute_mode, str(c))\n",
    "    \n",
    "    print('train_path={}, test_path={}'.format(train_path, test_path))\n",
    "    click_train = pd.read_csv(train_path + '/underexpose_train_click-{}.csv'.format(c), header=None,\n",
    "                          names=['user_id', 'item_id', 'time'])\n",
    "    click_test = pd.read_csv(test_path + '/underexpose_test_click-{}.csv'.format(c), header=None,\n",
    "                          names=['user_id', 'item_id', 'time'])\n",
    "    all_click = click_train.append(click_test)\n",
    "    \n",
    "    click_history_df = all_click  # init\n",
    "    \n",
    "    full_sim_pair_dict = pickle.load(open(os.path.join(save_training_path, 'full_sim_pair_dict.pkl'), 'rb'))\n",
    "    step_user_recall_item_dict = pickle.load(open(os.path.join(save_training_path, 'step_user_recall_item_dict.pkl'), 'rb'))\n",
    "    \n",
    "    if  is_silding_compute_sim:\n",
    "        step_strategy_sim_pair_dict = pickle.load(open(os.path.join(save_training_path, 'step_strategy_sim_pair_dict.pkl'), 'rb'))\n",
    "    print('read recall data done...')\n",
    "    \n",
    "    step = 0\n",
    "    total_step = 10\n",
    "    train_full_df_list = []\n",
    "    while step < total_step:\n",
    "        print('step={} begin...'.format(step))\n",
    "        click_history_df, click_last_df = get_history_and_last_click_df(click_history_df)  # override click_history_df\n",
    "        user_item_time_dict = get_user_item_time_dict(click_history_df)\n",
    "        \n",
    "        user_recall_item_dict = step_user_recall_item_dict[step]\n",
    "        strategy_sim_pair_dict =  step_strategy_sim_pair_dict[step] if is_silding_compute_sim else full_sim_pair_dict\n",
    "        \n",
    "         # organize recall interact feat\n",
    "        click_last_recall_recom_df = organize_recall_feat(user_recall_item_dict, user_item_time_dict, strategy_sim_pair_dict, c)\n",
    "        \n",
    "        assert len(user_item_time_dict) == len(click_last_recall_recom_df['user_id'].unique()) == len(\n",
    "            click_last_df['user_id'].unique())\n",
    "\n",
    "        train_full_df = organize_label_interact_feat_df(click_last_df, click_last_recall_recom_df, c)\n",
    "        print(train_full_df['label'].value_counts())\n",
    "        train_full_df_list.append(train_full_df)\n",
    "        step += 1\n",
    "      \n",
    "    if mode == 'offline':\n",
    "        train_full_df = pd.concat(train_full_df_list, ignore_index=True)\n",
    "    \n",
    "        # valid data\n",
    "        val_user_item_dict = get_user_item_time_dict(click_test) # click_test as history\n",
    "        val_user_recall_item_dict = pickle.load(open(os.path.join(save_training_path, 'val_user_recall_item_dict.pkl'), 'rb'))\n",
    "\n",
    "        phase_val_last_click_answer_df = pd.read_csv(offline_answer_path + '/underexpose_test_qtime_with_answer-{}.csv'.format(c), header=None, \n",
    "                                       names=['user_id', 'item_id', 'time']) \n",
    "\n",
    "        # organize recall interact feat\n",
    "        phase_val_last_click_recall_recom_df = organize_recall_feat(val_user_recall_item_dict, val_user_item_dict, full_sim_pair_dict, c)\n",
    "       \n",
    "        val_full_df = organize_label_interact_feat_df(phase_val_last_click_answer_df, phase_val_last_click_recall_recom_df, phase, False)\n",
    "        val_target_uids = phase_val_last_click_answer_df['user_id'].unique()\n",
    "        \n",
    "        save_train_val_path = os.path.join(save_training_path, 'train_val_label_target_id_data.pkl')\n",
    "        pickle.dump([train_full_df, val_full_df, val_target_uids], open(save_train_val_path, 'wb'))\n",
    "        \n",
    "        return train_full_df, val_full_df, val_target_uids\n",
    "    elif mode == 'online' and online_is_eval:\n",
    "        print('online, use the last step as validation data')\n",
    "        val_full_df = train_full_df_list[0]\n",
    "        train_full_df = pd.concat(train_full_df_list[1:], ignore_index=True)\n",
    "        val_target_uids = val_full_df.user_id.unique()\n",
    "        \n",
    "        save_train_val_path = os.path.join(save_training_path, 'train_val_label_target_id_data.pkl')\n",
    "        pickle.dump([train_full_df, val_full_df, val_target_uids], open(save_train_val_path, 'wb'))\n",
    "        \n",
    "        return train_full_df, val_full_df, val_target_uids\n",
    "    \n",
    "    return train_full_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "def organize_train_data_multi_processing(c, is_silding_compute_sim=False, load_from_file=True):        \n",
    "    # 1. 获取recall的结果\n",
    "    compute_mode = 'once' if not is_silding_compute_sim else 'multi'\n",
    "    save_training_path = os.path.join('training', mode, compute_mode, str(c))\n",
    "    \n",
    "    save_result_train_val_path = os.path.join(save_training_path, 'train_val_label_target_id_data.pkl')\n",
    "    if load_from_file and os.path.exists(save_result_train_val_path):\n",
    "        return pickle.load(open(save_result_train_val_path, 'rb'))\n",
    "    \n",
    "    print('train_path={}, test_path={}'.format(train_path, test_path))\n",
    "    click_train = pd.read_csv(train_path + '/underexpose_train_click-{}.csv'.format(c), header=None,\n",
    "                          names=['user_id', 'item_id', 'time'])\n",
    "    click_test = pd.read_csv(test_path + '/underexpose_test_click-{}.csv'.format(c), header=None,\n",
    "                          names=['user_id', 'item_id', 'time'])\n",
    "    all_click = click_train.append(click_test)\n",
    "    \n",
    "    click_history_df = all_click  # init\n",
    "    \n",
    "    full_sim_pair_dict = pickle.load(open(os.path.join(save_training_path, 'full_sim_pair_dict.pkl'), 'rb'))\n",
    "    step_user_recall_item_dict = pickle.load(open(os.path.join(save_training_path, 'step_user_recall_item_dict.pkl'), 'rb'))\n",
    "    \n",
    "    if  is_silding_compute_sim:\n",
    "        step_strategy_sim_pair_dict = pickle.load(open(os.path.join(save_training_path, 'step_strategy_sim_pair_dict.pkl'), 'rb'))\n",
    "    print('read recall data done...')\n",
    "    \n",
    "    step = 0\n",
    "    total_step = 10\n",
    "    \n",
    "    from multiprocessing import Process, JoinableQueue, Queue   \n",
    "        \n",
    "    def convert(click_history_df, click_last_df, user_recall_item_dict, strategy_sim_pair_dict, input_q, result_q):\n",
    "        step = input_q.get()\n",
    "        print('step={} begin...'.format(step))\n",
    "        user_item_time_dict = get_user_item_time_dict(click_history_df)\n",
    "         # organize recall interact feat\n",
    "        click_last_recall_recom_df = organize_recall_feat(user_recall_item_dict, user_item_time_dict, strategy_sim_pair_dict, c)\n",
    "        \n",
    "        assert len(user_item_time_dict) == len(click_last_recall_recom_df['user_id'].unique()) == len(\n",
    "            click_last_df['user_id'].unique())\n",
    "\n",
    "        train_full_df = organize_label_interact_feat_df(click_last_df, click_last_recall_recom_df, c)\n",
    "        print(train_full_df['label'].value_counts())\n",
    "        result_q.put(train_full_df)\n",
    "        input_q.task_done()\n",
    "        assert 'sim' in train_full_df.columns\n",
    "        \n",
    "    input_q = JoinableQueue()\n",
    "    result_q = Queue()\n",
    "        \n",
    "    processes = []\n",
    "    for step in range(total_step):\n",
    "        input_q.put(step)\n",
    "        click_history_df, click_last_df = get_history_and_last_click_df(click_history_df)  # override click_history_df\n",
    "        user_recall_item_dict = step_user_recall_item_dict[step]\n",
    "        strategy_sim_pair_dict =  step_strategy_sim_pair_dict[step] if is_silding_compute_sim else full_sim_pair_dict\n",
    "        \n",
    "        processes.append(Process(target=convert, args=(click_history_df, click_last_df, \n",
    "                                                                             user_recall_item_dict, strategy_sim_pair_dict,\n",
    "                                                                             input_q, result_q)))\n",
    "        processes[-1].daemon = True\n",
    "        processes[-1].start()\n",
    "        \n",
    "    input_q.join()\n",
    "    \n",
    "    train_full_df_list = []\n",
    "    while len(train_full_df_list) != total_step:\n",
    "        train_full_df = result_q.get()\n",
    "        train_full_df_list.append(train_full_df)\n",
    "    \n",
    "    for p in processes:\n",
    "        p.terminate()\n",
    "        p.join()\n",
    "    \n",
    "    print('obtain train data done....')\n",
    "    \n",
    "    assert len(train_full_df_list) == total_step\n",
    "    \n",
    "    if mode == 'offline':\n",
    "        train_full_df = pd.concat(train_full_df_list, ignore_index=True)\n",
    "        # valid data\n",
    "        print('begin obtain validate data...')\n",
    "        val_user_item_dict = get_user_item_time_dict(click_test) # click_test as history\n",
    "        val_user_recall_item_dict = pickle.load(open(os.path.join(save_training_path, 'val_user_recall_item_dict.pkl'), 'rb'))\n",
    "\n",
    "        phase_val_last_click_answer_df = pd.read_csv(offline_answer_path + '/underexpose_test_qtime_with_answer-{}.csv'.format(c), header=None, \n",
    "                                       names=['user_id', 'item_id', 'time']) \n",
    "\n",
    "        # organize recall interact feat\n",
    "        phase_val_last_click_recall_recom_df = organize_recall_feat(val_user_recall_item_dict, val_user_item_dict, full_sim_pair_dict, c)\n",
    "       \n",
    "        val_full_df = organize_label_interact_feat_df(phase_val_last_click_answer_df, phase_val_last_click_recall_recom_df, phase, False)\n",
    "        val_target_uids = phase_val_last_click_answer_df['user_id'].unique()\n",
    "        \n",
    "        save_train_val_path = os.path.join(save_training_path, 'train_val_label_target_id_data.pkl')\n",
    "        pickle.dump([train_full_df, val_full_df, val_target_uids], open(save_train_val_path, 'wb'))\n",
    "        \n",
    "#         train_full_df = train_full_df.drop_duplicates(subset=['user_id', 'item_id'])\n",
    "#         val_full_df = val_full_df.drop_duplicates(subset=['user_id', 'item_id'])\n",
    "        \n",
    "        return train_full_df, val_full_df, val_target_uids\n",
    "    \n",
    "#     else:\n",
    "#         print('online, use the last step as validation data')\n",
    "#         val_full_df = train_full_df_list[0]\n",
    "#         train_full_df = pd.concat(train_full_df_list[1:], ignore_index=True)\n",
    "#         val_target_uids = val_full_df.user_id.unique()\n",
    "        \n",
    "#         save_train_val_path = os.path.join(save_training_path, 'train_val_label_target_id_data.pkl')\n",
    "#         pickle.dump([train_full_df, val_full_df, val_target_uids], open(save_train_val_path, 'wb'))\n",
    "        \n",
    "#         return train_full_df, val_full_df, val_target_uids\n",
    "\n",
    "    return train_full_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train_full_df_dict = {}\n",
    "val_full_df_dict = {}\n",
    "for i in [0]:\n",
    "    train_full_df, val_full_df, val_target_uids = organize_train_data_multi_processing(i, is_silding_compute_sim=True)\n",
    "    train_full_df_dict[i] = train_full_df\n",
    "    val_full_df_dict[i] = val_full_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_path=underexpose_train, test_path=underexpose_test\n",
      "read recall data done...\n",
      "step=0 begin...\n",
      "step=1 begin...\n",
      "step=2 begin...\n",
      "step=3 begin...\n",
      "step=4 begin...\n",
      "step=5 begin...\n",
      "step=6 begin...\n",
      "step=7 begin...\n",
      "step=8 begin...\n",
      "step=9 begin...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/researcher/anaconda3/envs/deepctr/lib/python3.6/site-packages/ipykernel_launcher.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/home/researcher/anaconda3/envs/deepctr/lib/python3.6/site-packages/ipykernel_launcher.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sim_col=sim, mean_value=0.9842633971087507\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/researcher/anaconda3/envs/deepctr/lib/python3.6/site-packages/ipykernel_launcher.py:34: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sim_col=sum_sim2int_1, mean_value=0.11756902021679881\n",
      "sim_col=sum_sim2int_2, mean_value=0.07886291107863397\n",
      "sim_col=sum_sim2int_3, mean_value=0.061854033959642125\n",
      "sim_col=max_sim2int_1, mean_value=0.08510828356831658\n",
      "sim_col=max_sim2int_2, mean_value=0.057917302171004055\n",
      "sim_col=max_sim2int_3, mean_value=0.04603264528715214\n",
      "sim_col=sim_rank_score, mean_value=1.6084663250366011\n",
      "sim_col=cnt_sim2int_1, mean_value=0.19339526005056557\n",
      "sim_col=cnt_sim2int_2, mean_value=0.15198994807175395\n",
      "sim_col=cnt_sim2int_3, mean_value=0.10730928265507364\n",
      "cold_start_item_num=11, hit_last_cold_start_df_num=100\n",
      "0.0    59857\n",
      "1.0     4198\n",
      "Name: label, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/researcher/anaconda3/envs/deepctr/lib/python3.6/site-packages/ipykernel_launcher.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/home/researcher/anaconda3/envs/deepctr/lib/python3.6/site-packages/ipykernel_launcher.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sim_col=sim, mean_value=0.9798864146849876\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/researcher/anaconda3/envs/deepctr/lib/python3.6/site-packages/ipykernel_launcher.py:34: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sim_col=sum_sim2int_1, mean_value=0.3280598166755363\n",
      "sim_col=sum_sim2int_2, mean_value=0.2158218852670238\n",
      "sim_col=sum_sim2int_3, mean_value=0.1569369623398415\n",
      "sim_col=max_sim2int_1, mean_value=0.21195165605660787\n",
      "sim_col=max_sim2int_2, mean_value=0.13989079952399044\n",
      "sim_col=max_sim2int_3, mean_value=0.09959397179679275\n",
      "sim_col=sim_rank_score, mean_value=1.4738662952646255\n",
      "sim_col=cnt_sim2int_1, mean_value=0.21206709817259425\n",
      "sim_col=cnt_sim2int_2, mean_value=0.16966531847844882\n",
      "sim_col=cnt_sim2int_3, mean_value=0.11864917424395888\n",
      "cold_start_item_num=1655, hit_last_cold_start_df_num=4862\n",
      "0.0    55805\n",
      "1.0     6657\n",
      "Name: label, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/researcher/anaconda3/envs/deepctr/lib/python3.6/site-packages/ipykernel_launcher.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/home/researcher/anaconda3/envs/deepctr/lib/python3.6/site-packages/ipykernel_launcher.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sim_col=sim, mean_value=0.9620434962403956\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/researcher/anaconda3/envs/deepctr/lib/python3.6/site-packages/ipykernel_launcher.py:34: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sim_col=sum_sim2int_1, mean_value=0.1508215590332938\n",
      "sim_col=sum_sim2int_2, mean_value=0.0817815728807734\n",
      "sim_col=sum_sim2int_3, mean_value=0.058332595178609094\n",
      "sim_col=max_sim2int_1, mean_value=0.10639124059260802\n",
      "sim_col=max_sim2int_2, mean_value=0.06016911605307904\n",
      "sim_col=max_sim2int_3, mean_value=0.042762130545629794\n",
      "sim_col=sim_rank_score, mean_value=1.5288151116199236\n",
      "sim_col=cnt_sim2int_1, mean_value=0.24651737467657175\n",
      "sim_col=cnt_sim2int_2, mean_value=0.16713845325526197\n",
      "sim_col=cnt_sim2int_3, mean_value=0.10116772705920438\n",
      "cold_start_item_num=124, hit_last_cold_start_df_num=512\n",
      "0.0    59539\n",
      "1.0     4006\n",
      "Name: label, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/researcher/anaconda3/envs/deepctr/lib/python3.6/site-packages/ipykernel_launcher.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/home/researcher/anaconda3/envs/deepctr/lib/python3.6/site-packages/ipykernel_launcher.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sim_col=sim, mean_value=0.9576394234075539\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/researcher/anaconda3/envs/deepctr/lib/python3.6/site-packages/ipykernel_launcher.py:34: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sim_col=sum_sim2int_1, mean_value=0.34812737942477745\n",
      "sim_col=sum_sim2int_2, mean_value=0.2663416782542099\n",
      "sim_col=sum_sim2int_3, mean_value=0.14921547281302872\n",
      "sim_col=max_sim2int_1, mean_value=0.22469328612580539\n",
      "sim_col=max_sim2int_2, mean_value=0.16810282919123362\n",
      "sim_col=max_sim2int_3, mean_value=0.09590130359176877\n",
      "sim_col=sim_rank_score, mean_value=1.4482605985037404\n",
      "sim_col=cnt_sim2int_1, mean_value=0.24547708989527459\n",
      "sim_col=cnt_sim2int_2, mean_value=0.16880897471583692\n",
      "sim_col=cnt_sim2int_3, mean_value=0.09230774518408978\n",
      "cold_start_item_num=1956, hit_last_cold_start_df_num=5250\n",
      "0.0    54786\n",
      "1.0     6854\n",
      "Name: label, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/researcher/anaconda3/envs/deepctr/lib/python3.6/site-packages/ipykernel_launcher.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/home/researcher/anaconda3/envs/deepctr/lib/python3.6/site-packages/ipykernel_launcher.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sim_col=sim, mean_value=0.9016412473476466\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/researcher/anaconda3/envs/deepctr/lib/python3.6/site-packages/ipykernel_launcher.py:34: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sim_col=sum_sim2int_1, mean_value=0.28794227310759785\n",
      "sim_col=sum_sim2int_2, mean_value=0.18026761296284613\n",
      "sim_col=sum_sim2int_3, mean_value=0.11237833527519102\n",
      "sim_col=max_sim2int_1, mean_value=0.18890395857528378\n",
      "sim_col=max_sim2int_2, mean_value=0.11640960529683501\n",
      "sim_col=max_sim2int_3, mean_value=0.07507989120515245\n",
      "sim_col=sim_rank_score, mean_value=1.4619517652908993\n",
      "sim_col=cnt_sim2int_1, mean_value=0.20675496608092975\n",
      "sim_col=cnt_sim2int_2, mean_value=0.14075356034246148\n",
      "sim_col=cnt_sim2int_3, mean_value=0.08997628992318751\n",
      "cold_start_item_num=1289, hit_last_cold_start_df_num=3815\n",
      "0.0    56731\n",
      "1.0     5826\n",
      "Name: label, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/researcher/anaconda3/envs/deepctr/lib/python3.6/site-packages/ipykernel_launcher.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/home/researcher/anaconda3/envs/deepctr/lib/python3.6/site-packages/ipykernel_launcher.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sim_col=sim, mean_value=0.8843633432698242\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/researcher/anaconda3/envs/deepctr/lib/python3.6/site-packages/ipykernel_launcher.py:34: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sim_col=sum_sim2int_1, mean_value=0.1829728597613542\n",
      "sim_col=sum_sim2int_2, mean_value=0.11804147486929313\n",
      "sim_col=sum_sim2int_3, mean_value=0.07270990157150287\n",
      "sim_col=max_sim2int_1, mean_value=0.1257197963411654\n",
      "sim_col=max_sim2int_2, mean_value=0.08072432823236983\n",
      "sim_col=max_sim2int_3, mean_value=0.05015786335122421\n",
      "sim_col=sim_rank_score, mean_value=1.4948671328671324\n",
      "sim_col=cnt_sim2int_1, mean_value=0.23284176940267737\n",
      "sim_col=cnt_sim2int_2, mean_value=0.16652942783349045\n",
      "sim_col=cnt_sim2int_3, mean_value=0.09558944267618073\n",
      "cold_start_item_num=454, hit_last_cold_start_df_num=1576\n",
      "0.0    58795\n",
      "1.0     4436\n",
      "Name: label, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/researcher/anaconda3/envs/deepctr/lib/python3.6/site-packages/ipykernel_launcher.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/home/researcher/anaconda3/envs/deepctr/lib/python3.6/site-packages/ipykernel_launcher.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sim_col=sim, mean_value=0.9003035550970173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/researcher/anaconda3/envs/deepctr/lib/python3.6/site-packages/ipykernel_launcher.py:34: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sim_col=sum_sim2int_1, mean_value=0.1618240720465993\n",
      "sim_col=sum_sim2int_2, mean_value=0.10134343301619238\n",
      "sim_col=sum_sim2int_3, mean_value=0.0626080176003374\n",
      "sim_col=max_sim2int_1, mean_value=0.11411880855361234\n",
      "sim_col=max_sim2int_2, mean_value=0.07159947503256822\n",
      "sim_col=max_sim2int_3, mean_value=0.046378103452958404\n",
      "sim_col=sim_rank_score, mean_value=1.5036726078799247\n",
      "sim_col=cnt_sim2int_1, mean_value=0.23214305960587817\n",
      "sim_col=cnt_sim2int_2, mean_value=0.1688222388053701\n",
      "sim_col=cnt_sim2int_3, mean_value=0.10608162299926166\n",
      "cold_start_item_num=246, hit_last_cold_start_df_num=928\n",
      "0.0    59239\n",
      "1.0     4126\n",
      "Name: label, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/researcher/anaconda3/envs/deepctr/lib/python3.6/site-packages/ipykernel_launcher.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/home/researcher/anaconda3/envs/deepctr/lib/python3.6/site-packages/ipykernel_launcher.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sim_col=sim, mean_value=0.9246739651418034\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/researcher/anaconda3/envs/deepctr/lib/python3.6/site-packages/ipykernel_launcher.py:34: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sim_col=sum_sim2int_1, mean_value=0.20134587452774635\n",
      "sim_col=sum_sim2int_2, mean_value=0.1327459737367494\n",
      "sim_col=sum_sim2int_3, mean_value=0.09354483089624144\n",
      "sim_col=max_sim2int_1, mean_value=0.13651329356306285\n",
      "sim_col=max_sim2int_2, mean_value=0.09004637557256803\n",
      "sim_col=max_sim2int_3, mean_value=0.06219571335131715\n",
      "sim_col=sim_rank_score, mean_value=1.4920222743259077\n",
      "sim_col=cnt_sim2int_1, mean_value=0.2235545262595367\n",
      "sim_col=cnt_sim2int_2, mean_value=0.15984058491929334\n",
      "sim_col=cnt_sim2int_3, mean_value=0.10238253692948944\n",
      "cold_start_item_num=661, hit_last_cold_start_df_num=2255\n",
      "0.0    58228\n",
      "1.0     4814\n",
      "Name: label, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/researcher/anaconda3/envs/deepctr/lib/python3.6/site-packages/ipykernel_launcher.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/home/researcher/anaconda3/envs/deepctr/lib/python3.6/site-packages/ipykernel_launcher.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sim_col=sim, mean_value=0.9264831342033911\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/researcher/anaconda3/envs/deepctr/lib/python3.6/site-packages/ipykernel_launcher.py:34: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sim_col=sum_sim2int_1, mean_value=0.23809394290370756\n",
      "sim_col=sum_sim2int_2, mean_value=0.15247126925640622\n",
      "sim_col=sum_sim2int_3, mean_value=0.08082415407101143\n",
      "sim_col=max_sim2int_1, mean_value=0.1588758521950985\n",
      "sim_col=max_sim2int_2, mean_value=0.1019726782251352\n",
      "sim_col=max_sim2int_3, mean_value=0.05716874652961455\n",
      "sim_col=sim_rank_score, mean_value=1.476242371403657\n",
      "sim_col=cnt_sim2int_1, mean_value=0.22943297151960076\n",
      "sim_col=cnt_sim2int_2, mean_value=0.12745334934232125\n",
      "sim_col=cnt_sim2int_3, mean_value=0.09113696285092321\n",
      "cold_start_item_num=975, hit_last_cold_start_df_num=2901\n",
      "0.0    57534\n",
      "1.0     5195\n",
      "Name: label, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/researcher/anaconda3/envs/deepctr/lib/python3.6/site-packages/ipykernel_launcher.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/home/researcher/anaconda3/envs/deepctr/lib/python3.6/site-packages/ipykernel_launcher.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sim_col=sim, mean_value=0.9590249266619287\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/researcher/anaconda3/envs/deepctr/lib/python3.6/site-packages/ipykernel_launcher.py:34: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sim_col=sum_sim2int_1, mean_value=0.12828821134235804\n",
      "sim_col=sum_sim2int_2, mean_value=0.083967362779633\n",
      "sim_col=sum_sim2int_3, mean_value=0.05030712181187723\n",
      "sim_col=max_sim2int_1, mean_value=0.09054924261411398\n",
      "sim_col=max_sim2int_2, mean_value=0.06117563943284279\n",
      "sim_col=max_sim2int_3, mean_value=0.03790784997617621\n",
      "sim_col=sim_rank_score, mean_value=1.5597291454730413\n",
      "sim_col=cnt_sim2int_1, mean_value=0.20580672097533548\n",
      "sim_col=cnt_sim2int_2, mean_value=0.1523468000236387\n",
      "sim_col=cnt_sim2int_3, mean_value=0.10454719952503759\n",
      "cold_start_item_num=47, hit_last_cold_start_df_num=276\n",
      "0.0    59693\n",
      "1.0     4208\n",
      "Name: label, dtype: int64\n",
      "obtain train data done....\n"
     ]
    }
   ],
   "source": [
    "online_train_full_df_dict = {}\n",
    "for i in [0]:\n",
    "    online_train_full_df = organize_train_data_multi_processing(i, is_silding_compute_sim=True, load_from_file=False)\n",
    "    online_train_full_df_dict[i] = online_train_full_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>phase</th>\n",
       "      <th>label</th>\n",
       "      <th>hist_item_id</th>\n",
       "      <th>hist_day_id</th>\n",
       "      <th>hist_hour_id</th>\n",
       "      <th>hist_minute_id</th>\n",
       "      <th>sim</th>\n",
       "      <th>sum_sim2int_1</th>\n",
       "      <th>...</th>\n",
       "      <th>max_sim2int_2</th>\n",
       "      <th>max_sim2int_3</th>\n",
       "      <th>sim_rank_score</th>\n",
       "      <th>cnt_sim2int_1</th>\n",
       "      <th>cnt_sim2int_2</th>\n",
       "      <th>cnt_sim2int_3</th>\n",
       "      <th>time</th>\n",
       "      <th>day_id</th>\n",
       "      <th>hour_id</th>\n",
       "      <th>minute_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>46452</th>\n",
       "      <td>26482</td>\n",
       "      <td>108191</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[52995, 30085, 98315, 88947, 86572, 79446, 112...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 3, 3, 3]</td>\n",
       "      <td>[24, 24, 24, 24, 24, 4, 4, 4]</td>\n",
       "      <td>[32, 33, 33, 34, 34, 9, 15, 16]</td>\n",
       "      <td>0.038626</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.390000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.983887</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45033</th>\n",
       "      <td>25576</td>\n",
       "      <td>52961</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[66644, 66479, 51239, 40013, 75798, 70567, 999...</td>\n",
       "      <td>[2, 2, 2, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4]</td>\n",
       "      <td>[22, 22, 22, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8]</td>\n",
       "      <td>[31, 32, 37, 46, 47, 47, 48, 51, 52, 53, 55, 5...</td>\n",
       "      <td>0.035789</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.020000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.983952</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18801</th>\n",
       "      <td>10226</td>\n",
       "      <td>12877</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[8191]</td>\n",
       "      <td>[3]</td>\n",
       "      <td>[23]</td>\n",
       "      <td>[40]</td>\n",
       "      <td>0.953142</td>\n",
       "      <td>0.236387</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.315000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.983931</td>\n",
       "      <td>3</td>\n",
       "      <td>23</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58788</th>\n",
       "      <td>34742</td>\n",
       "      <td>67077</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[22855, 54429, 63843, 105832, 38863, 66881, 55...</td>\n",
       "      <td>[1, 1, 1, 1, 2, 2, 2, 2, 2, 3]</td>\n",
       "      <td>[9, 21, 21, 21, 2, 2, 3, 3, 3, 20]</td>\n",
       "      <td>[9, 5, 6, 7, 57, 60, 5, 8, 13, 13]</td>\n",
       "      <td>0.081007</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.163952</td>\n",
       "      <td>0.870000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.983924</td>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50639</th>\n",
       "      <td>29136</td>\n",
       "      <td>50861</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[29445]</td>\n",
       "      <td>[2]</td>\n",
       "      <td>[10]</td>\n",
       "      <td>[34]</td>\n",
       "      <td>0.136786</td>\n",
       "      <td>0.242803</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.045000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.983847</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271</th>\n",
       "      <td>34625</td>\n",
       "      <td>18370</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[59093, 35118]</td>\n",
       "      <td>[3, 3]</td>\n",
       "      <td>[10, 10]</td>\n",
       "      <td>[22, 23]</td>\n",
       "      <td>0.959025</td>\n",
       "      <td>0.128288</td>\n",
       "      <td>...</td>\n",
       "      <td>0.061176</td>\n",
       "      <td>0.037908</td>\n",
       "      <td>1.559729</td>\n",
       "      <td>0.205807</td>\n",
       "      <td>0.152347</td>\n",
       "      <td>0.104547</td>\n",
       "      <td>0.983901</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272</th>\n",
       "      <td>34868</td>\n",
       "      <td>756</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[59260, 20549]</td>\n",
       "      <td>[1, 1]</td>\n",
       "      <td>[1, 1]</td>\n",
       "      <td>[5, 6]</td>\n",
       "      <td>0.959025</td>\n",
       "      <td>0.128288</td>\n",
       "      <td>...</td>\n",
       "      <td>0.061176</td>\n",
       "      <td>0.037908</td>\n",
       "      <td>1.559729</td>\n",
       "      <td>0.205807</td>\n",
       "      <td>0.152347</td>\n",
       "      <td>0.104547</td>\n",
       "      <td>0.983771</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>273</th>\n",
       "      <td>34868</td>\n",
       "      <td>756</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[59260, 20549]</td>\n",
       "      <td>[1, 1]</td>\n",
       "      <td>[1, 1]</td>\n",
       "      <td>[5, 6]</td>\n",
       "      <td>0.959025</td>\n",
       "      <td>0.128288</td>\n",
       "      <td>...</td>\n",
       "      <td>0.061176</td>\n",
       "      <td>0.037908</td>\n",
       "      <td>1.559729</td>\n",
       "      <td>0.205807</td>\n",
       "      <td>0.152347</td>\n",
       "      <td>0.104547</td>\n",
       "      <td>0.983771</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274</th>\n",
       "      <td>34868</td>\n",
       "      <td>756</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[59260, 20549]</td>\n",
       "      <td>[1, 1]</td>\n",
       "      <td>[1, 1]</td>\n",
       "      <td>[5, 6]</td>\n",
       "      <td>0.959025</td>\n",
       "      <td>0.128288</td>\n",
       "      <td>...</td>\n",
       "      <td>0.061176</td>\n",
       "      <td>0.037908</td>\n",
       "      <td>1.559729</td>\n",
       "      <td>0.205807</td>\n",
       "      <td>0.152347</td>\n",
       "      <td>0.104547</td>\n",
       "      <td>0.983771</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275</th>\n",
       "      <td>35027</td>\n",
       "      <td>43372</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[18800, 47266]</td>\n",
       "      <td>[3, 3]</td>\n",
       "      <td>[6, 6]</td>\n",
       "      <td>[34, 39]</td>\n",
       "      <td>0.959025</td>\n",
       "      <td>0.128288</td>\n",
       "      <td>...</td>\n",
       "      <td>0.061176</td>\n",
       "      <td>0.037908</td>\n",
       "      <td>1.559729</td>\n",
       "      <td>0.205807</td>\n",
       "      <td>0.152347</td>\n",
       "      <td>0.104547</td>\n",
       "      <td>0.983893</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>63901 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       user_id  item_id  phase  label  \\\n",
       "46452    26482   108191      0    0.0   \n",
       "45033    25576    52961      0    0.0   \n",
       "18801    10226    12877      0    0.0   \n",
       "58788    34742    67077      0    0.0   \n",
       "50639    29136    50861      0    0.0   \n",
       "...        ...      ...    ...    ...   \n",
       "271      34625    18370      0    1.0   \n",
       "272      34868      756      0    1.0   \n",
       "273      34868      756      0    1.0   \n",
       "274      34868      756      0    1.0   \n",
       "275      35027    43372      0    1.0   \n",
       "\n",
       "                                            hist_item_id  \\\n",
       "46452  [52995, 30085, 98315, 88947, 86572, 79446, 112...   \n",
       "45033  [66644, 66479, 51239, 40013, 75798, 70567, 999...   \n",
       "18801                                             [8191]   \n",
       "58788  [22855, 54429, 63843, 105832, 38863, 66881, 55...   \n",
       "50639                                            [29445]   \n",
       "...                                                  ...   \n",
       "271                                       [59093, 35118]   \n",
       "272                                       [59260, 20549]   \n",
       "273                                       [59260, 20549]   \n",
       "274                                       [59260, 20549]   \n",
       "275                                       [18800, 47266]   \n",
       "\n",
       "                                      hist_day_id  \\\n",
       "46452                    [1, 1, 1, 1, 1, 3, 3, 3]   \n",
       "45033  [2, 2, 2, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4]   \n",
       "18801                                         [3]   \n",
       "58788              [1, 1, 1, 1, 2, 2, 2, 2, 2, 3]   \n",
       "50639                                         [2]   \n",
       "...                                           ...   \n",
       "271                                        [3, 3]   \n",
       "272                                        [1, 1]   \n",
       "273                                        [1, 1]   \n",
       "274                                        [1, 1]   \n",
       "275                                        [3, 3]   \n",
       "\n",
       "                                        hist_hour_id  \\\n",
       "46452                  [24, 24, 24, 24, 24, 4, 4, 4]   \n",
       "45033  [22, 22, 22, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8]   \n",
       "18801                                           [23]   \n",
       "58788             [9, 21, 21, 21, 2, 2, 3, 3, 3, 20]   \n",
       "50639                                           [10]   \n",
       "...                                              ...   \n",
       "271                                         [10, 10]   \n",
       "272                                           [1, 1]   \n",
       "273                                           [1, 1]   \n",
       "274                                           [1, 1]   \n",
       "275                                           [6, 6]   \n",
       "\n",
       "                                          hist_minute_id       sim  \\\n",
       "46452                    [32, 33, 33, 34, 34, 9, 15, 16]  0.038626   \n",
       "45033  [31, 32, 37, 46, 47, 47, 48, 51, 52, 53, 55, 5...  0.035789   \n",
       "18801                                               [40]  0.953142   \n",
       "58788                 [9, 5, 6, 7, 57, 60, 5, 8, 13, 13]  0.081007   \n",
       "50639                                               [34]  0.136786   \n",
       "...                                                  ...       ...   \n",
       "271                                             [22, 23]  0.959025   \n",
       "272                                               [5, 6]  0.959025   \n",
       "273                                               [5, 6]  0.959025   \n",
       "274                                               [5, 6]  0.959025   \n",
       "275                                             [34, 39]  0.959025   \n",
       "\n",
       "       sum_sim2int_1  ...  max_sim2int_2  max_sim2int_3  sim_rank_score  \\\n",
       "46452       0.000000  ...       0.000000       0.000000        0.390000   \n",
       "45033       0.000000  ...       0.000000       0.000000        1.020000   \n",
       "18801       0.236387  ...       0.000000       0.000000        0.315000   \n",
       "58788       0.000000  ...       0.000000       0.163952        0.870000   \n",
       "50639       0.242803  ...       0.000000       0.000000        0.045000   \n",
       "...              ...  ...            ...            ...             ...   \n",
       "271         0.128288  ...       0.061176       0.037908        1.559729   \n",
       "272         0.128288  ...       0.061176       0.037908        1.559729   \n",
       "273         0.128288  ...       0.061176       0.037908        1.559729   \n",
       "274         0.128288  ...       0.061176       0.037908        1.559729   \n",
       "275         0.128288  ...       0.061176       0.037908        1.559729   \n",
       "\n",
       "       cnt_sim2int_1  cnt_sim2int_2  cnt_sim2int_3      time  day_id  hour_id  \\\n",
       "46452       0.000000       0.000000       0.000000  0.983887       3        4   \n",
       "45033       0.000000       0.000000       0.000000  0.983952       4        8   \n",
       "18801       0.000000       0.000000       0.000000  0.983931       3       23   \n",
       "58788       0.000000       0.000000       0.000000  0.983924       3       20   \n",
       "50639       0.000000       0.000000       0.000000  0.983847       2       10   \n",
       "...              ...            ...            ...       ...     ...      ...   \n",
       "271         0.205807       0.152347       0.104547  0.983901       3       10   \n",
       "272         0.205807       0.152347       0.104547  0.983771       1        1   \n",
       "273         0.205807       0.152347       0.104547  0.983771       1        1   \n",
       "274         0.205807       0.152347       0.104547  0.983771       1        1   \n",
       "275         0.205807       0.152347       0.104547  0.983893       3        6   \n",
       "\n",
       "       minute_id  \n",
       "46452         19  \n",
       "45033         58  \n",
       "18801         40  \n",
       "58788         30  \n",
       "50639         38  \n",
       "...          ...  \n",
       "271           28  \n",
       "272           11  \n",
       "273           11  \n",
       "274           11  \n",
       "275           56  \n",
       "\n",
       "[63901 rows x 23 columns]"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "online_train_full_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_target_phase_full_df = train_full_df_dict[5]\n",
    "val_target_phase_full_df = val_full_df_dict[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    55805\n",
       "1.0     6657\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "online_val_full_df_dict[0]['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    47014\n",
       "1.0      389\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.0    47014\n",
       "1.0      389\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.0    47014\n",
       "1.0      389\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_full_df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### organize raw user-item feat "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_item_feat(item_feat_df):\n",
    "    processed_item_feat_df = item_feat_df.copy()\n",
    "    txt_dense_feat = ['txt_embed_'+str(i) for i in range(128)] \n",
    "    img_dense_feat = ['img_embed_'+str(i) for i in range(128)]\n",
    "    dense_feat = txt_dense_feat + img_dense_feat\n",
    "    # norm\n",
    "    txt_item_feat_np = processed_item_feat_df[txt_dense_feat].values\n",
    "    img_item_feat_np = processed_item_feat_df[img_dense_feat].values\n",
    "    txt_item_feat_np = txt_item_feat_np / np.linalg.norm(txt_item_feat_np, axis=1, keepdims=True)\n",
    "    img_item_feat_np = img_item_feat_np / np.linalg.norm(img_item_feat_np, axis=1, keepdims=True)\n",
    "    processed_item_feat_df[txt_dense_feat] = pd.DataFrame(txt_item_feat_np, columns=txt_dense_feat)\n",
    "    processed_item_feat_df[img_dense_feat] = pd.DataFrame(img_item_feat_np, columns=img_dense_feat)\n",
    "\n",
    "    # item_feat_dict = dict(zip(processed_item_feat_df['item_id'], processed_item_feat_df[dense_feat].values))\n",
    "    return processed_item_feat_df, dense_feat\n",
    "\n",
    "def process_user_feat(user_feat_df):\n",
    "    # sparse encoder\n",
    "    user_sparse_feat = ['age_level','gender','city_level']\n",
    "    return user_feat_df, user_sparse_feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sparse_feat_fit(online_total_click):\n",
    "    global feat_lbe_dict, item_raw_id2_idx_dict\n",
    "    \n",
    "    from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "    # sparse features one-hot\n",
    "    feat_lbe_dict = {}\n",
    "    for feat in sparse_feat:\n",
    "        if feat in time_feat: continue\n",
    "        lbe = LabelEncoder()\n",
    "        lbe.fit(online_total_click[feat].astype(str))\n",
    "        feat_lbe_dict[feat] = lbe\n",
    "    \n",
    "    item_raw_id2_idx_dict = dict(zip(feat_lbe_dict['item_id'].classes_, \n",
    "                     feat_lbe_dict['item_id'].transform(feat_lbe_dict['item_id'].classes_)+1, )) # 得到字典\n",
    "    \n",
    "\n",
    "def sparse_feat_transform(df):\n",
    "    df['hist_item_id'] = df['hist_item_id'].apply(lambda seq: [item_raw_id2_idx_dict[str(x)] for x in seq])\n",
    "    \n",
    "    for hist_id in var_len_feat: \n",
    "        df[hist_id] = tf.keras.preprocessing.sequence.pad_sequences(df[hist_id], \n",
    "                                                  value=0, maxlen=max_seq_len, truncating='pre', padding='pre').tolist()\n",
    "    for feat in sparse_feat:\n",
    "        print(feat)\n",
    "        if feat in time_feat: continue\n",
    "        df[feat] = feat_lbe_dict[feat].transform(df[feat].astype(str))+1\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fillna(df, sparse_feat, dense_feat):\n",
    "  for sp in sparse_feat:\n",
    "    df[sp].fillna('-1', inplace=True)\n",
    "    \n",
    "  for ds in dense_feat:\n",
    "    df[ds].fillna(0.0, inplace=True) # all_click_user_item_df[ds].mean()\n",
    "  return df\n",
    "  \n",
    "def organize_user_item_feat(df, user_feat_df, item_feat_df, sparse_feat, dense_feat):\n",
    "    full_user_df = pd.merge(df, user_feat_df, how='left', on='user_id')\n",
    "    full_user_item_df = pd.merge(full_user_df, item_feat_df, how='left', on='item_id')\n",
    "    full_user_item_df = fillna(full_user_item_df, sparse_feat, dense_feat)\n",
    "    print('origin data done')\n",
    "  \n",
    "    # history interest\n",
    "    full_user_item_df = obtain_user_hist_interest_feat(full_user_item_df, item_content_vec_dict)\n",
    "\n",
    "    print('interest done')\n",
    "    \n",
    "    for key, file_name in zip(['item_id', 'user_id'], ['item_statistic.pkl', 'user_statistic.pkl']):\n",
    "        count_df, first_time_df, last_time_df, \\\n",
    "                day_count_df, hour_count_df = pickle.load(open(os.path.join(drive_path, file_name), 'rb'))\n",
    "        full_user_item_df = pd.merge(full_user_item_df, count_df, on=key, how='left')\n",
    "        full_user_item_df = pd.merge(full_user_item_df, first_time_df, on=key, how='left')\n",
    "        full_user_item_df = pd.merge(full_user_item_df, last_time_df, on=key, how='left')\n",
    "        full_user_item_df = pd.merge(full_user_item_df, day_count_df, on=[key, 'day_id'],  how='left')\n",
    "        full_user_item_df = pd.merge(full_user_item_df, hour_count_df, on=[key, 'hour_id'],  how='left')\n",
    "        full_user_item_df['{}_day_count'.format(key)].fillna(0.0, inplace=True)\n",
    "        full_user_item_df['{}_hour_count'.format(key)].fillna(0.0, inplace=True)\n",
    "        \n",
    "        full_user_item_df['diff_time'] = full_user_item_df['time'] -  full_user_item_df['item_id_first_time']\n",
    "\n",
    "    print('statistic done')\n",
    "    \n",
    "    full_user_item_df = sparse_feat_transform(full_user_item_df)\n",
    "    \n",
    "    return full_user_item_df\n",
    "\n",
    "\n",
    "def obtain_item_global_feat(total_click):\n",
    "    total_click_df = total_click.copy()\n",
    "\n",
    "    item_count_df = total_click_df.groupby('item_id', group_keys=False)['user_id'].count().reset_index().rename(columns={'user_id': 'item_degree'})\n",
    "    item_count_info_dict = item_count_df['item_degree'].describe().to_dict()\n",
    "    item_count_df['item_vs_degree_mean'] = item_count_df['item_degree'].apply(lambda x: 1.0 if x >= item_count_info_dict['mean'] else 0.0)\n",
    "    item_count_df['item_vs_25_degree']  = item_count_df['item_degree'].apply(lambda x: 1.0 if x >= item_count_info_dict['25%'] else 0.0)\n",
    "    item_count_df['item_vs_50_degree']  = item_count_df['item_degree'].apply(lambda x: 1.0 if x >= item_count_info_dict['50%'] else 0.0)\n",
    "    item_count_df['item_vs_75_degree']  = item_count_df['item_degree'].apply(lambda x: 1.0 if x >= item_count_info_dict['75%'] else 0.0)\n",
    "    \n",
    "    \n",
    "    item_last_time_df = total_click_df.groupby('item_id')['time'].max().reset_index().rename(columns={'time': 'item_id_last_time'})\n",
    "    item_first_time_df = total_click_df.groupby('item_id')['time'].min().reset_index().rename(columns={'time': 'item_id_first_time'})\n",
    "    \n",
    "    total_click_df['day_id'],  total_click_df['hour_id'], total_click_df['minute_id'] = zip(*total_click_df['time'].apply(time_info))\n",
    "    item_day_count_df =  total_click_df.groupby(['item_id', 'day_id']).size().reset_index().rename(columns={0: 'item_id_day_count'})\n",
    "    item_hour_count_df =  total_click_df.groupby(['item_id', 'hour_id']).size().reset_index().rename(columns={0: 'item_id_hour_count'})\n",
    "    \n",
    "    pickle.dump([item_count_df, item_first_time_df, item_last_time_df, item_day_count_df, item_hour_count_df], \n",
    "                    open(os.path.join(drive_path, 'item_statistic.pkl'), 'wb'))\n",
    "    \n",
    "def obtain_user_global_feat(total_click):\n",
    "    total_click_df = total_click.copy()   \n",
    "    user_count_df = total_click_df.groupby('user_id', group_keys=False)['item_id'].count().reset_index().rename(columns={'item_id': 'user_degree'})\n",
    "    user_count_info_dict = user_count_df['user_degree'].describe().to_dict()\n",
    "    user_count_df['user_vs_degree_mean'] = user_count_df['user_degree'].apply(lambda x: 1.0 if x >= user_count_info_dict['mean'] else 0.0)\n",
    "    user_count_df['user_vs_25_degree']  = user_count_df['user_degree'].apply(lambda x: 1.0 if x >= user_count_info_dict['25%'] else 0.0)\n",
    "    user_count_df['user_vs_50_degree']  = user_count_df['user_degree'].apply(lambda x: 1.0 if x >= user_count_info_dict['50%'] else 0.0)\n",
    "    user_count_df['user_vs_75_degree']  = user_count_df['user_degree'].apply(lambda x: 1.0 if x >= user_count_info_dict['75%'] else 0.0)\n",
    "    \n",
    "    user_last_time_df = total_click_df.groupby('user_id')['time'].max().reset_index().rename(columns={'time': 'user_id_last_time'})\n",
    "    user_first_time_df = total_click_df.groupby('user_id')['time'].min().reset_index().rename(columns={'time': 'user_id_first_time'})\n",
    "    \n",
    "    \n",
    "    total_click_df['day_id'],  total_click_df['hour_id'], total_click_df['minute_id'] = zip(*total_click_df['time'].apply(time_info))\n",
    "\n",
    "    user_day_count_df =  total_click_df.groupby(['user_id', 'day_id']).size().reset_index().rename(columns={0: 'user_id_day_count'})\n",
    "    user_hour_count_df =  total_click_df.groupby(['user_id', 'hour_id']).size().reset_index().rename(columns={0: 'user_id_hour_count'})\n",
    "    \n",
    "    pickle.dump([user_count_df, user_first_time_df, user_last_time_df, user_day_count_df, user_hour_count_df], \n",
    "                    open(os.path.join(drive_path, 'user_statistic.pkl'), 'wb'))\n",
    "    \n",
    "\n",
    "def obtain_user_hist_interest_feat(full_user_item_df, item_vec_dict):\n",
    "    def weighted_agg_content(hist_item_id_list):\n",
    "\n",
    "        weighted_content = np.zeros(128*2)\n",
    "        hist_num = len(hist_item_id_list)\n",
    "        for loc, i in enumerate(hist_item_id_list):\n",
    "            loc_weight = (0.9**(hist_num-loc)) \n",
    "            if i in item_vec_dict:\n",
    "                weighted_content += loc_weight*item_vec_dict[i]\n",
    "        return weighted_content\n",
    "\n",
    "    user_interest_vec = full_user_item_df['hist_item_id'].apply(weighted_agg_content).tolist()\n",
    "    user_interest_df = pd.DataFrame(user_interest_vec, columns=['interest_'+col for col in item_dense_feat])\n",
    "    \n",
    "    full_user_item_df[user_interest_df.columns] = user_interest_df\n",
    "\n",
    "    # begin compute degree\n",
    "    target_item_vec = full_user_item_df[item_dense_feat].values\n",
    "    user_interest_vec = np.array(user_interest_vec) \n",
    "    \n",
    "    txt_interest_degree_array = target_item_vec[:, 0:128] * user_interest_vec[:, 0:128]\n",
    "    txt_interest_degree_list = np.sum(txt_interest_degree_array, axis=1)\n",
    "    full_user_item_df['txt_interest_degree'] = txt_interest_degree_list.tolist()\n",
    "    \n",
    "    img_interest_degree_array = target_item_vec[:, 128:] * user_interest_vec[:, 128:]\n",
    "    img_interest_degree_list = np.sum(img_interest_degree_array, axis=1)\n",
    "    full_user_item_df['img_interest_degree'] = img_interest_degree_list.tolist()\n",
    "    \n",
    "    full_user_item_df['interest_degree'] =  full_user_item_df['img_interest_degree']  + full_user_item_df['img_interest_degree'] \n",
    "    \n",
    "    for f in ['interest_'+col for col in item_dense_feat]+['img_interest_degree', 'img_interest_degree', 'interest_degree']:\n",
    "        full_user_item_df[f].fillna(0.0, inplace=True)\n",
    "    print('obtain user dynamic feat done')\n",
    "    \n",
    "    def hist_2_target_cnt(hist_target_item_list, hist_no):\n",
    "        target_item = hist_target_item_list[-1]\n",
    "        if target_item not in item_content_vec_dict:\n",
    "            return [0.0, 0.0, 0.0]\n",
    "\n",
    "        hist_target_item_list = hist_target_item_list[: -1]\n",
    "\n",
    "        if len(hist_target_item_list) >= hist_no:\n",
    "            hist_item = hist_target_item_list[-hist_no]\n",
    "            if hist_item in item_content_vec_dict:\n",
    "                txt_cnt_sim = np.dot(item_content_vec_dict[target_item][0:128], item_content_vec_dict[hist_item][0:128])\n",
    "                img_cnt_sim = np.dot(item_content_vec_dict[target_item][128:], item_content_vec_dict[hist_item][128:])\n",
    "                return txt_cnt_sim, img_cnt_sim, txt_cnt_sim + img_cnt_sim\n",
    "\n",
    "        return [0.0, 0.0, 0.0]\n",
    "\n",
    "    hist_target_items_series = full_user_item_df['hist_item_id'] + full_user_item_df['item_id'].apply(lambda x:[x])\n",
    "    full_user_item_df['txt_cnt_sim_last_1'], full_user_item_df['img_cnt_sim_last_1'], full_user_item_df['cnt_sim_last_1']  = zip(*hist_target_items_series.apply(lambda x: hist_2_target_cnt(x, 1)))\n",
    "    full_user_item_df['txt_cnt_sim_last_2'], full_user_item_df['img_cnt_sim_last_2'], full_user_item_df['cnt_sim_last_2']  = zip(*hist_target_items_series.apply(lambda x: hist_2_target_cnt(x, 2)))\n",
    "    full_user_item_df['txt_cnt_sim_last_3'], full_user_item_df['img_cnt_sim_last_3'], full_user_item_df['cnt_sim_last_3'] = zip(*hist_target_items_series.apply(lambda x: hist_2_target_cnt(x, 3)))\n",
    "    return full_user_item_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### running"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_phase = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_item_feat_df, item_dense_feat = process_item_feat(item_feat_df)\n",
    "processed_user_feat_df, user_sparse_feat = process_user_feat(user_feat_df)\n",
    "item_content_vec_dict = dict(zip(processed_item_feat_df['item_id'], processed_item_feat_df[item_dense_feat].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_seq_len = 10\n",
    "time_feat = ['day_id', 'hour_id'] #, 'minute_id']  # no need to sparse encoder\n",
    "time_vocab_map = {'day_id': max_day, 'minute_id': max_miniute, 'hour_id': max_hour}\n",
    "\n",
    "sparse_feat = ['user_id', 'item_id',] + time_feat # + user_sparse_feat\n",
    "user_interest_dense_feat = ['interest_'+col for col in item_dense_feat] + ['interest_degree', 'txt_interest_degree', 'img_interest_degree',]\n",
    "# sim_dense_feat =  ['sim', 'exp_sim', 'sim2int_1', 'sim2int_2', 'sim2int_3'] + ['cnt_sim2int_1', 'cnt_sim2int_2', 'cnt_sim2int_3'] # , 'sim_rank_score']\n",
    "sim_dense_feat = ['sim', 'sum_sim2int_1', 'sum_sim2int_2', 'sum_sim2int_3'] + \\\n",
    "                             ['max_sim2int_1', 'max_sim2int_2', 'max_sim2int_3', 'sim_rank_score']  + \\\n",
    "                              ['cnt_sim2int_1', 'cnt_sim2int_2', 'cnt_sim2int_3']\n",
    "\n",
    "hist_cnt_sim_feat = ['txt_cnt_sim_last_1', 'img_cnt_sim_last_1', 'cnt_sim_last_1'] + \\\n",
    "                            ['txt_cnt_sim_last_2', 'img_cnt_sim_last_2', 'cnt_sim_last_2'] + \\\n",
    "                            ['txt_cnt_sim_last_3', 'img_cnt_sim_last_3', 'cnt_sim_last_3'] \n",
    "\n",
    "\n",
    "item_degree_feat = ['item_degree', 'item_vs_degree_mean', 'item_vs_25_degree', 'item_vs_50_degree', 'item_vs_75_degree'] \n",
    "item_time_feat =  ['item_id_first_time', 'item_id_last_time', 'item_id_day_count', 'item_id_hour_count']\n",
    "item_statistic_feat = item_degree_feat + item_time_feat\n",
    "\n",
    "user_degree_feat = ['user_degree', 'user_vs_degree_mean', 'user_vs_25_degree', 'user_vs_50_degree', 'user_vs_75_degree'] \n",
    "user_time_feat =  ['user_id_first_time', 'user_id_last_time', 'user_id_day_count', 'user_id_hour_count']\n",
    "user_statistic_feat = user_degree_feat + user_time_feat\n",
    "                               \n",
    "dense_feat = item_dense_feat  +  sim_dense_feat # + item_statistic_feat\n",
    "var_len_feat = ['hist_item_id'] +  ['hist_{}'.format(feat) for feat in time_feat]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_feat_fit(online_total_click)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# item statistic, global is useful ?\n",
    "obtain_item_global_feat(online_total_click[online_total_click['phase'] == target_phase])\n",
    "obtain_user_global_feat(online_total_click[online_total_click['phase'] == target_phase])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "origin data done\n",
      "obtain user dynamic feat done\n",
      "interest done\n",
      "statistic done\n",
      "user_id\n",
      "item_id\n",
      "day_id\n",
      "hour_id\n"
     ]
    }
   ],
   "source": [
    "train_final_df = organize_user_item_feat(online_train_full_df_dict[target_phase], processed_user_feat_df, processed_item_feat_df, sparse_feat, dense_feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "origin data done\n",
      "obtain user dynamic feat done\n",
      "interest done\n",
      "statistic done\n",
      "user_id\n",
      "item_id\n",
      "day_id\n",
      "hour_id\n"
     ]
    }
   ],
   "source": [
    "val_final_df = organize_user_item_feat(val_full_df_dict[target_phase], processed_user_feat_df, processed_item_feat_df, sparse_feat, dense_feat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ranking model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "lgb_cols = dense_feat  + user_interest_dense_feat + hist_cnt_sim_feat # ['user_degree'] # ['item_count',]  #, 'first_time', 'last_time'] # item_statistic_feat + time_feat "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.7,\n",
       "               importance_type='split', learning_rate=0.01, max_depth=-1,\n",
       "               min_child_samples=20, min_child_weight=50, min_split_gain=0.0,\n",
       "               n_estimators=300, n_jobs=-1, num_leaves=31, objective='binary',\n",
       "               random_state=2018, reg_alpha=0.0, reg_lambda=1, silent=True,\n",
       "               subsample=0.7, subsample_for_bin=200000, subsample_freq=1)"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 0.868919 -> 0.854(all_item_statistic_feat) -> 0.877 (item_count,first_time, last_time) -> 0.879 (item_count) -> item_degree_info (0.8826)\n",
    "clf = lgb.LGBMClassifier(\n",
    "        boosting_type='gbdt', num_leaves=31, reg_alpha=0.0, reg_lambda=1,\n",
    "        max_depth=-1, n_estimators=300, objective='binary',\n",
    "        subsample=0.7, colsample_bytree=0.7, subsample_freq=1,\n",
    "        learning_rate=0.01, min_child_weight=50, random_state=2018, n_jobs=-1) # 300epoch, best, 0.882898, dense_feat  + hist_cnt_sim_feat user_interest_dense_feat \n",
    "\n",
    "clf.fit(train_final_df[lgb_cols],  train_final_df['label'], )\n",
    "       # eval_set=[(val_final_df[lgb_cols], val_final_df['label'])],\n",
    "     #   eval_metric='auc',   early_stopping_rounds=50) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feat</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sim</td>\n",
       "      <td>787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sim_rank_score</td>\n",
       "      <td>736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cnt_sim_last_1</td>\n",
       "      <td>710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>txt_cnt_sim_last_1</td>\n",
       "      <td>569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>txt_embed_8</td>\n",
       "      <td>250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>530</th>\n",
       "      <td>interest_txt_embed_56</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>531</th>\n",
       "      <td>interest_txt_embed_57</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>532</th>\n",
       "      <td>txt_embed_116</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>533</th>\n",
       "      <td>interest_txt_embed_63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>534</th>\n",
       "      <td>interest_txt_embed_0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>535 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      feat  importance\n",
       "0                      sim         787\n",
       "1           sim_rank_score         736\n",
       "2           cnt_sim_last_1         710\n",
       "3       txt_cnt_sim_last_1         569\n",
       "4              txt_embed_8         250\n",
       "..                     ...         ...\n",
       "530  interest_txt_embed_56           0\n",
       "531  interest_txt_embed_57           0\n",
       "532          txt_embed_116           0\n",
       "533  interest_txt_embed_63           0\n",
       "534   interest_txt_embed_0           0\n",
       "\n",
       "[535 rows x 2 columns]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat_importance = pd.Series(clf.feature_importances_, index=lgb_cols).sort_values(ascending=False).reset_index().rename(columns={'index':'feat', 0:'importance'})\n",
    "feat_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feat</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sim</td>\n",
       "      <td>555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sim_rank_score</td>\n",
       "      <td>436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cnt_sim_last_1</td>\n",
       "      <td>401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>txt_cnt_sim_last_1</td>\n",
       "      <td>276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>interest_degree</td>\n",
       "      <td>143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>530</th>\n",
       "      <td>txt_embed_107</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>531</th>\n",
       "      <td>img_embed_124</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>532</th>\n",
       "      <td>interest_img_embed_21</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>533</th>\n",
       "      <td>txt_embed_35</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>534</th>\n",
       "      <td>interest_txt_embed_79</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>535 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      feat  importance\n",
       "0                      sim         555\n",
       "1           sim_rank_score         436\n",
       "2           cnt_sim_last_1         401\n",
       "3       txt_cnt_sim_last_1         276\n",
       "4          interest_degree         143\n",
       "..                     ...         ...\n",
       "530          txt_embed_107           1\n",
       "531          img_embed_124           1\n",
       "532  interest_img_embed_21           1\n",
       "533           txt_embed_35           0\n",
       "534  interest_txt_embed_79           0\n",
       "\n",
       "[535 rows x 2 columns]"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat_importance = pd.Series(clf.feature_importances_, index=lgb_cols).sort_values(ascending=False).reset_index().rename(columns={'index':'feat', 0:'importance'})\n",
    "feat_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_cols = feat_importance[feat_importance['importance'] > 0]['feat'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [],
   "source": [
    "HIDDEN_SIZE = (128, 128)\n",
    "BATCH_SIZE = 256\n",
    "EPOCH = 6\n",
    "EMBED_DIM = 16\n",
    "def generate_din_feature_columns(data, sparse_features, dense_features,):\n",
    "    sparse_feature_columns = [SparseFeat(feat, vocabulary_size=len(feat_lbe_dict[feat].classes_)+1, embedding_dim=EMBED_DIM)\n",
    "                              for i, feat in enumerate(sparse_features) if feat not in time_feat]\n",
    "\n",
    "    sparse_feature_columns += [SparseFeat(feat, vocabulary_size=time_vocab_map[feat]+1, embedding_dim=EMBED_DIM)\n",
    "                              for i, feat in enumerate(time_feat)]\n",
    "    \n",
    "\n",
    "    dense_feature_columns = [DenseFeat(feat, 1, ) for feat in dense_features]\n",
    "\n",
    "    var_feature_columns = [VarLenSparseFeat(SparseFeat('hist_item_id', vocabulary_size=len(feat_lbe_dict['item_id'].classes_)+1,\n",
    "                                                       embedding_dim=EMBED_DIM,embedding_name='item_id'), \n",
    "                                            maxlen=max_seq_len)]\n",
    "\n",
    "    var_feature_columns += [VarLenSparseFeat(SparseFeat('hist_{}'.format(feat), vocabulary_size=time_vocab_map[feat]+1,\n",
    "                                              embedding_dim=EMBED_DIM,embedding_name=feat), maxlen=max_seq_len) \n",
    "                                                    for i, feat in enumerate(time_feat)]\n",
    "    # DNN side\n",
    "    dnn_feature_columns = sparse_feature_columns + dense_feature_columns + var_feature_columns\n",
    "    # FM side\n",
    "    linear_feature_columns = sparse_feature_columns + dense_feature_columns + var_feature_columns\n",
    "    # all feature names\n",
    "    feature_names = get_feature_names(linear_feature_columns + dnn_feature_columns + var_feature_columns)\n",
    "\n",
    "    return feature_names, linear_feature_columns, dnn_feature_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names, linear_feature_columns, dnn_feature_columns = generate_din_feature_columns(train_final_df, ['user_id', 'item_id'], dense_feat+user_interest_dense_feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input = {name: np.array(train_final_df[name].values.tolist()) for name in feature_names}\n",
    "train_label = train_final_df['label'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_input = {name: np.array(val_final_df[name].values.tolist()) for name in feature_names}\n",
    "val_label = val_final_df['label'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (lambda_2), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'attention_sequence_pooling_layer_2/local_activation_unit_2/kernel:0' shape=(40, 1) dtype=float32>\n",
      "  <tf.Variable 'attention_sequence_pooling_layer_2/local_activation_unit_2/bias:0' shape=(1,) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n"
     ]
    }
   ],
   "source": [
    "behavior_feature_list = ['item_id'] #, 'day_id', 'hour_id',] #  'minute_id']\n",
    "model = DIN(dnn_feature_columns, behavior_feature_list, dnn_hidden_units=HIDDEN_SIZE,\n",
    "                dnn_dropout=0.5)\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(lr=0.001), loss=\"binary_crossentropy\",\n",
    "                  metrics=['binary_crossentropy', tf.keras.metrics.AUC()], )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 675364 samples, validate on 47403 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/researcher/anaconda3/envs/deepctr/lib/python3.6/site-packages/tensorflow_core/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/home/researcher/anaconda3/envs/deepctr/lib/python3.6/site-packages/tensorflow_core/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "675364/675364 [==============================] - 77s 114us/sample - loss: 0.2209 - binary_crossentropy: 0.2182 - auc_2: 0.8385 - val_loss: 0.1334 - val_binary_crossentropy: 0.1286 - val_auc_2: 0.8656\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7eff9f258d68>"
      ]
     },
     "execution_count": 360,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EPOCH = 1\n",
    "model.fit(train_input, train_label, batch_size=BATCH_SIZE, epochs=EPOCH,\n",
    "          verbose=1, validation_data=(val_input, val_label), ) # 1:20目前最优结果, epoch. 0.8728"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## generate recommend result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_recall_predict(infer_recall_df, phase):\n",
    "    topk_fill_items  = online_top50_click if mode == 'online' else offline_top50_click\n",
    "    result = get_predict(infer_recall_df, 'sim', topk_fill_items)\n",
    "    result.to_csv(output_path + '/baseline_recall_v1_phase_{}.csv'.format(phase), index=False, header=None)\n",
    "    return result\n",
    "\n",
    "def get_rank_predict(dfm_infer_call_df, phase, infer_target_uids=None, rating_col='prob'):\n",
    "    dfm_infer_call_df = dfm_infer_call_df.copy()\n",
    "    fake_item = dfm_infer_call_df['item_id'].iloc[0]\n",
    "    infer_users = set(dfm_infer_call_df['user_id'].unique())\n",
    "  \n",
    "    if infer_target_uids is None:\n",
    "        infer_target_uids = infer_users\n",
    "\n",
    "    for uid in infer_target_uids:\n",
    "        if uid not in infer_users:\n",
    "            print('uid={} not in infer_users'.format(uid))\n",
    "            dfm_infer_call_df = dfm_infer_call_df.append({'user_id': uid, 'item_id': fake_item, 'prob': -10000}, ignore_index=True)\n",
    "\n",
    "    dfm_infer_call_df['user_id'] = dfm_infer_call_df['user_id'].astype(int)\n",
    "    dfm_infer_call_df['item_id'] = dfm_infer_call_df['item_id'].astype(int)\n",
    "    \n",
    "    topk_fill_items  = online_top50_click if mode == 'online' else offline_top50_click\n",
    "    \n",
    "    result = get_predict(dfm_infer_call_df, rating_col, topk_fill_items)\n",
    "    result.to_csv(output_path + '/baseline_ranking_v1_phase_{}_{}.csv'.format(phase, mode), index=False, header=None)\n",
    "    return dfm_infer_call_df, result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def infer_process(phase, load_from_file=True, is_sliding_compute_sim=True):\n",
    "    print('train_path={}, test_path={}'.format(train_path, test_path))\n",
    "    click_train = pd.read_csv(train_path + '/underexpose_train_click-{}.csv'.format(phase), header=None,\n",
    "                          names=['user_id', 'item_id', 'time'])\n",
    "    click_test = pd.read_csv(test_path + '/underexpose_test_click-{}.csv'.format(phase), header=None,\n",
    "                          names=['user_id', 'item_id', 'time'])\n",
    "    all_click = click_train.append(click_test)\n",
    "    \n",
    "    target_infer_user_df = pd.read_csv(test_path + '/underexpose_test_qtime-{}.csv'.format(phase), header=None, \n",
    "                                   names=['user_id', 'time'])  \n",
    "    infer_user_item_time_dict = get_user_item_time_dict(all_click)\n",
    "    \n",
    "    if load_from_file:\n",
    "        compute_mode = 'multi' if is_sliding_compute_sim else 'once'\n",
    "        save_training_path = os.path.join('training', mode, compute_mode, str(phase)) \n",
    "        full_sim_pair_dict = pickle.load(open(os.path.join(save_training_path, 'full_sim_pair_dict.pkl'), 'rb'))\n",
    "        infer_user_recall_item_dict = pickle.load(open(os.path.join(save_training_path, 'val_user_recall_item_dict.pkl'), 'rb'))\n",
    "        print('load recall info from file done')\n",
    "    else:\n",
    "        full_sim_pair_dict = get_multi_source_sim_dict_results_multi_processing(all_click, recall_methods={'item-cf', 'bi-graph', 'user-cf', 'swing'}) \n",
    "        infer_user_recall_item_dict = do_multi_recall_results_multi_processing(full_sim_pair_dict, infer_user_item_time_dict, \n",
    "                                                                     target_user_ids=target_infer_user_df['user_id'].unique(), ret_type='tuple')\n",
    "    \n",
    "    infer_recall_recom_df = organize_recall_feat(infer_user_recall_item_dict, infer_user_item_time_dict, \n",
    "                                                                  full_sim_pair_dict, phase)\n",
    "#     infer_recall_recom_df = sim_process(infer_recall_recom_df) # TODO\n",
    "\n",
    "       \n",
    "    target_infer_user_df['day_id'],  target_infer_user_df['hour_id'], target_infer_user_df['minute_id'] = zip(*target_infer_user_df['time'].apply(time_info))\n",
    "    infer_recall_recom_df = pd.merge(infer_recall_recom_df, target_infer_user_df[['user_id', 'time', 'day_id', 'hour_id', 'minute_id']], on='user_id', how='left')\n",
    "\n",
    "\n",
    "    infer_final_df = organize_user_item_feat(infer_recall_recom_df, processed_user_feat_df, processed_item_feat_df,\n",
    "                                          sparse_feat, dense_feat)\n",
    "  \n",
    "    return infer_recall_recom_df, infer_final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_path=underexpose_train, test_path=underexpose_test\n",
      "load recall info from file done\n",
      "origin data done\n",
      "obtain user dynamic feat done\n",
      "interest done\n",
      "statistic done\n",
      "user_id\n",
      "item_id\n",
      "day_id\n",
      "hour_id\n"
     ]
    }
   ],
   "source": [
    "infer_recall_recom_df, infer_df = infer_process(target_phase, load_from_file=True, is_sliding_compute_sim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lgb\n",
    "lgb_infer_ans = clf.predict_proba(infer_df[lgb_cols],  axis=1)[:,1]\n",
    "infer_recall_recom_df['prob'] = lgb_infer_ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [],
   "source": [
    "infer_input = {name: np.array(infer_df[name].values.tolist()) for name in feature_names}\n",
    "din_infer_ans = model.predict(infer_input, batch_size=BATCH_SIZE)\n",
    "infer_recall_recom_df['prob'] = din_infer_ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "infer_recall_recom_df['prob_sim'] = infer_recall_recom_df['prob'] + infer_recall_recom_df['sim']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>36058</td>\n",
       "      <td>91413</td>\n",
       "      <td>67567</td>\n",
       "      <td>14234</td>\n",
       "      <td>19318</td>\n",
       "      <td>14233</td>\n",
       "      <td>91002</td>\n",
       "      <td>68704</td>\n",
       "      <td>68439</td>\n",
       "      <td>...</td>\n",
       "      <td>87564</td>\n",
       "      <td>49718</td>\n",
       "      <td>48669</td>\n",
       "      <td>93716</td>\n",
       "      <td>28376</td>\n",
       "      <td>15557</td>\n",
       "      <td>48653</td>\n",
       "      <td>25402</td>\n",
       "      <td>90445</td>\n",
       "      <td>91458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>18307</td>\n",
       "      <td>1906</td>\n",
       "      <td>3760</td>\n",
       "      <td>39469</td>\n",
       "      <td>15029</td>\n",
       "      <td>26786</td>\n",
       "      <td>40318</td>\n",
       "      <td>5507</td>\n",
       "      <td>13948</td>\n",
       "      <td>...</td>\n",
       "      <td>82473</td>\n",
       "      <td>101412</td>\n",
       "      <td>33881</td>\n",
       "      <td>82650</td>\n",
       "      <td>21333</td>\n",
       "      <td>7012</td>\n",
       "      <td>112044</td>\n",
       "      <td>25945</td>\n",
       "      <td>237</td>\n",
       "      <td>6834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "      <td>24232</td>\n",
       "      <td>8552</td>\n",
       "      <td>109651</td>\n",
       "      <td>40854</td>\n",
       "      <td>57849</td>\n",
       "      <td>36566</td>\n",
       "      <td>88062</td>\n",
       "      <td>114330</td>\n",
       "      <td>2611</td>\n",
       "      <td>...</td>\n",
       "      <td>62081</td>\n",
       "      <td>7939</td>\n",
       "      <td>83671</td>\n",
       "      <td>79533</td>\n",
       "      <td>10656</td>\n",
       "      <td>104625</td>\n",
       "      <td>78724</td>\n",
       "      <td>72498</td>\n",
       "      <td>100308</td>\n",
       "      <td>107297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17</td>\n",
       "      <td>25684</td>\n",
       "      <td>79967</td>\n",
       "      <td>80606</td>\n",
       "      <td>13285</td>\n",
       "      <td>37775</td>\n",
       "      <td>67210</td>\n",
       "      <td>51966</td>\n",
       "      <td>29918</td>\n",
       "      <td>31085</td>\n",
       "      <td>...</td>\n",
       "      <td>59323</td>\n",
       "      <td>55449</td>\n",
       "      <td>18984</td>\n",
       "      <td>53044</td>\n",
       "      <td>76342</td>\n",
       "      <td>86154</td>\n",
       "      <td>46596</td>\n",
       "      <td>22041</td>\n",
       "      <td>25540</td>\n",
       "      <td>46785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>42</td>\n",
       "      <td>17491</td>\n",
       "      <td>40670</td>\n",
       "      <td>87254</td>\n",
       "      <td>103775</td>\n",
       "      <td>59783</td>\n",
       "      <td>35441</td>\n",
       "      <td>102082</td>\n",
       "      <td>13306</td>\n",
       "      <td>44534</td>\n",
       "      <td>...</td>\n",
       "      <td>73131</td>\n",
       "      <td>12061</td>\n",
       "      <td>86936</td>\n",
       "      <td>25313</td>\n",
       "      <td>41755</td>\n",
       "      <td>32361</td>\n",
       "      <td>41603</td>\n",
       "      <td>10566</td>\n",
       "      <td>42948</td>\n",
       "      <td>34742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1595</th>\n",
       "      <td>35338</td>\n",
       "      <td>8207</td>\n",
       "      <td>80101</td>\n",
       "      <td>12530</td>\n",
       "      <td>76806</td>\n",
       "      <td>60349</td>\n",
       "      <td>85661</td>\n",
       "      <td>68871</td>\n",
       "      <td>63511</td>\n",
       "      <td>45278</td>\n",
       "      <td>...</td>\n",
       "      <td>25367</td>\n",
       "      <td>89959</td>\n",
       "      <td>50277</td>\n",
       "      <td>63510</td>\n",
       "      <td>112860</td>\n",
       "      <td>111077</td>\n",
       "      <td>72079</td>\n",
       "      <td>58165</td>\n",
       "      <td>53276</td>\n",
       "      <td>67647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1596</th>\n",
       "      <td>35360</td>\n",
       "      <td>28966</td>\n",
       "      <td>81227</td>\n",
       "      <td>60010</td>\n",
       "      <td>13438</td>\n",
       "      <td>88172</td>\n",
       "      <td>80437</td>\n",
       "      <td>87571</td>\n",
       "      <td>49402</td>\n",
       "      <td>65560</td>\n",
       "      <td>...</td>\n",
       "      <td>70914</td>\n",
       "      <td>9613</td>\n",
       "      <td>52261</td>\n",
       "      <td>86029</td>\n",
       "      <td>94370</td>\n",
       "      <td>83599</td>\n",
       "      <td>92318</td>\n",
       "      <td>38114</td>\n",
       "      <td>71295</td>\n",
       "      <td>77767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1597</th>\n",
       "      <td>35372</td>\n",
       "      <td>70643</td>\n",
       "      <td>76806</td>\n",
       "      <td>93437</td>\n",
       "      <td>86473</td>\n",
       "      <td>90006</td>\n",
       "      <td>94634</td>\n",
       "      <td>36071</td>\n",
       "      <td>50844</td>\n",
       "      <td>88701</td>\n",
       "      <td>...</td>\n",
       "      <td>51321</td>\n",
       "      <td>69398</td>\n",
       "      <td>50958</td>\n",
       "      <td>94804</td>\n",
       "      <td>23097</td>\n",
       "      <td>113623</td>\n",
       "      <td>48186</td>\n",
       "      <td>89864</td>\n",
       "      <td>112860</td>\n",
       "      <td>77723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1598</th>\n",
       "      <td>35374</td>\n",
       "      <td>27267</td>\n",
       "      <td>107900</td>\n",
       "      <td>90052</td>\n",
       "      <td>36259</td>\n",
       "      <td>42248</td>\n",
       "      <td>95843</td>\n",
       "      <td>84091</td>\n",
       "      <td>36631</td>\n",
       "      <td>76623</td>\n",
       "      <td>...</td>\n",
       "      <td>45390</td>\n",
       "      <td>56555</td>\n",
       "      <td>65099</td>\n",
       "      <td>42976</td>\n",
       "      <td>56101</td>\n",
       "      <td>65437</td>\n",
       "      <td>45281</td>\n",
       "      <td>21175</td>\n",
       "      <td>94898</td>\n",
       "      <td>87111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599</th>\n",
       "      <td>35386</td>\n",
       "      <td>103005</td>\n",
       "      <td>34027</td>\n",
       "      <td>106607</td>\n",
       "      <td>92712</td>\n",
       "      <td>89440</td>\n",
       "      <td>100870</td>\n",
       "      <td>20347</td>\n",
       "      <td>103668</td>\n",
       "      <td>107187</td>\n",
       "      <td>...</td>\n",
       "      <td>58500</td>\n",
       "      <td>86615</td>\n",
       "      <td>46006</td>\n",
       "      <td>107995</td>\n",
       "      <td>24233</td>\n",
       "      <td>98615</td>\n",
       "      <td>44807</td>\n",
       "      <td>65958</td>\n",
       "      <td>71637</td>\n",
       "      <td>45099</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1600 rows × 51 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      user_id       0       1       2       3      4       5       6       7  \\\n",
       "0           2   36058   91413   67567   14234  19318   14233   91002   68704   \n",
       "1           8   18307    1906    3760   39469  15029   26786   40318    5507   \n",
       "2           9   24232    8552  109651   40854  57849   36566   88062  114330   \n",
       "3          17   25684   79967   80606   13285  37775   67210   51966   29918   \n",
       "4          42   17491   40670   87254  103775  59783   35441  102082   13306   \n",
       "...       ...     ...     ...     ...     ...    ...     ...     ...     ...   \n",
       "1595    35338    8207   80101   12530   76806  60349   85661   68871   63511   \n",
       "1596    35360   28966   81227   60010   13438  88172   80437   87571   49402   \n",
       "1597    35372   70643   76806   93437   86473  90006   94634   36071   50844   \n",
       "1598    35374   27267  107900   90052   36259  42248   95843   84091   36631   \n",
       "1599    35386  103005   34027  106607   92712  89440  100870   20347  103668   \n",
       "\n",
       "           8  ...     40      41     42      43      44      45      46  \\\n",
       "0      68439  ...  87564   49718  48669   93716   28376   15557   48653   \n",
       "1      13948  ...  82473  101412  33881   82650   21333    7012  112044   \n",
       "2       2611  ...  62081    7939  83671   79533   10656  104625   78724   \n",
       "3      31085  ...  59323   55449  18984   53044   76342   86154   46596   \n",
       "4      44534  ...  73131   12061  86936   25313   41755   32361   41603   \n",
       "...      ...  ...    ...     ...    ...     ...     ...     ...     ...   \n",
       "1595   45278  ...  25367   89959  50277   63510  112860  111077   72079   \n",
       "1596   65560  ...  70914    9613  52261   86029   94370   83599   92318   \n",
       "1597   88701  ...  51321   69398  50958   94804   23097  113623   48186   \n",
       "1598   76623  ...  45390   56555  65099   42976   56101   65437   45281   \n",
       "1599  107187  ...  58500   86615  46006  107995   24233   98615   44807   \n",
       "\n",
       "         47      48      49  \n",
       "0     25402   90445   91458  \n",
       "1     25945     237    6834  \n",
       "2     72498  100308  107297  \n",
       "3     22041   25540   46785  \n",
       "4     10566   42948   34742  \n",
       "...     ...     ...     ...  \n",
       "1595  58165   53276   67647  \n",
       "1596  38114   71295   77767  \n",
       "1597  89864  112860   77723  \n",
       "1598  21175   94898   87111  \n",
       "1599  65958   71637   45099  \n",
       "\n",
       "[1600 rows x 51 columns]"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_recall_predict(infer_recall_recom_df, target_phase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>36058</td>\n",
       "      <td>67567</td>\n",
       "      <td>14234</td>\n",
       "      <td>91413</td>\n",
       "      <td>19318</td>\n",
       "      <td>14233</td>\n",
       "      <td>91002</td>\n",
       "      <td>112197</td>\n",
       "      <td>68439</td>\n",
       "      <td>...</td>\n",
       "      <td>90988</td>\n",
       "      <td>16722</td>\n",
       "      <td>50151</td>\n",
       "      <td>68493</td>\n",
       "      <td>15557</td>\n",
       "      <td>93845</td>\n",
       "      <td>15556</td>\n",
       "      <td>103448</td>\n",
       "      <td>16875</td>\n",
       "      <td>90445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>18307</td>\n",
       "      <td>39469</td>\n",
       "      <td>26786</td>\n",
       "      <td>15029</td>\n",
       "      <td>13948</td>\n",
       "      <td>228</td>\n",
       "      <td>40318</td>\n",
       "      <td>39921</td>\n",
       "      <td>34006</td>\n",
       "      <td>...</td>\n",
       "      <td>4492</td>\n",
       "      <td>106175</td>\n",
       "      <td>22123</td>\n",
       "      <td>276</td>\n",
       "      <td>33689</td>\n",
       "      <td>640</td>\n",
       "      <td>23773</td>\n",
       "      <td>34258</td>\n",
       "      <td>35140</td>\n",
       "      <td>33881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "      <td>24232</td>\n",
       "      <td>109651</td>\n",
       "      <td>8552</td>\n",
       "      <td>40854</td>\n",
       "      <td>88062</td>\n",
       "      <td>21504</td>\n",
       "      <td>11170</td>\n",
       "      <td>57849</td>\n",
       "      <td>4340</td>\n",
       "      <td>...</td>\n",
       "      <td>7156</td>\n",
       "      <td>17696</td>\n",
       "      <td>35264</td>\n",
       "      <td>7939</td>\n",
       "      <td>9604</td>\n",
       "      <td>71671</td>\n",
       "      <td>10656</td>\n",
       "      <td>37580</td>\n",
       "      <td>54429</td>\n",
       "      <td>52766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17</td>\n",
       "      <td>13285</td>\n",
       "      <td>51966</td>\n",
       "      <td>80606</td>\n",
       "      <td>20848</td>\n",
       "      <td>29918</td>\n",
       "      <td>37775</td>\n",
       "      <td>25684</td>\n",
       "      <td>115990</td>\n",
       "      <td>32683</td>\n",
       "      <td>...</td>\n",
       "      <td>85426</td>\n",
       "      <td>80324</td>\n",
       "      <td>5141</td>\n",
       "      <td>106783</td>\n",
       "      <td>55449</td>\n",
       "      <td>11101</td>\n",
       "      <td>95508</td>\n",
       "      <td>4340</td>\n",
       "      <td>27657</td>\n",
       "      <td>714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>42</td>\n",
       "      <td>87254</td>\n",
       "      <td>40670</td>\n",
       "      <td>13302</td>\n",
       "      <td>17491</td>\n",
       "      <td>13306</td>\n",
       "      <td>59783</td>\n",
       "      <td>103775</td>\n",
       "      <td>102082</td>\n",
       "      <td>23825</td>\n",
       "      <td>...</td>\n",
       "      <td>26149</td>\n",
       "      <td>75244</td>\n",
       "      <td>24411</td>\n",
       "      <td>64622</td>\n",
       "      <td>110891</td>\n",
       "      <td>111225</td>\n",
       "      <td>21580</td>\n",
       "      <td>41603</td>\n",
       "      <td>34934</td>\n",
       "      <td>23924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1595</th>\n",
       "      <td>35338</td>\n",
       "      <td>80101</td>\n",
       "      <td>8207</td>\n",
       "      <td>12530</td>\n",
       "      <td>60349</td>\n",
       "      <td>76806</td>\n",
       "      <td>85661</td>\n",
       "      <td>68871</td>\n",
       "      <td>87016</td>\n",
       "      <td>45278</td>\n",
       "      <td>...</td>\n",
       "      <td>25367</td>\n",
       "      <td>85900</td>\n",
       "      <td>63510</td>\n",
       "      <td>72079</td>\n",
       "      <td>67647</td>\n",
       "      <td>112860</td>\n",
       "      <td>50277</td>\n",
       "      <td>70391</td>\n",
       "      <td>58165</td>\n",
       "      <td>45578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1596</th>\n",
       "      <td>35360</td>\n",
       "      <td>28966</td>\n",
       "      <td>78438</td>\n",
       "      <td>7820</td>\n",
       "      <td>74204</td>\n",
       "      <td>80437</td>\n",
       "      <td>81227</td>\n",
       "      <td>94674</td>\n",
       "      <td>21426</td>\n",
       "      <td>99626</td>\n",
       "      <td>...</td>\n",
       "      <td>100444</td>\n",
       "      <td>94055</td>\n",
       "      <td>84094</td>\n",
       "      <td>47027</td>\n",
       "      <td>52261</td>\n",
       "      <td>75950</td>\n",
       "      <td>73369</td>\n",
       "      <td>795</td>\n",
       "      <td>115686</td>\n",
       "      <td>1363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1597</th>\n",
       "      <td>35372</td>\n",
       "      <td>76806</td>\n",
       "      <td>70643</td>\n",
       "      <td>90006</td>\n",
       "      <td>93437</td>\n",
       "      <td>94634</td>\n",
       "      <td>36071</td>\n",
       "      <td>50844</td>\n",
       "      <td>46491</td>\n",
       "      <td>63321</td>\n",
       "      <td>...</td>\n",
       "      <td>110845</td>\n",
       "      <td>23097</td>\n",
       "      <td>40989</td>\n",
       "      <td>53845</td>\n",
       "      <td>89864</td>\n",
       "      <td>116102</td>\n",
       "      <td>96020</td>\n",
       "      <td>98643</td>\n",
       "      <td>108205</td>\n",
       "      <td>74774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1598</th>\n",
       "      <td>35374</td>\n",
       "      <td>27267</td>\n",
       "      <td>36259</td>\n",
       "      <td>107900</td>\n",
       "      <td>90052</td>\n",
       "      <td>9499</td>\n",
       "      <td>95843</td>\n",
       "      <td>68931</td>\n",
       "      <td>52182</td>\n",
       "      <td>42248</td>\n",
       "      <td>...</td>\n",
       "      <td>80434</td>\n",
       "      <td>65099</td>\n",
       "      <td>41858</td>\n",
       "      <td>10914</td>\n",
       "      <td>97254</td>\n",
       "      <td>68886</td>\n",
       "      <td>81042</td>\n",
       "      <td>85613</td>\n",
       "      <td>41219</td>\n",
       "      <td>53367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599</th>\n",
       "      <td>35386</td>\n",
       "      <td>103005</td>\n",
       "      <td>103668</td>\n",
       "      <td>34027</td>\n",
       "      <td>89440</td>\n",
       "      <td>20347</td>\n",
       "      <td>100870</td>\n",
       "      <td>92712</td>\n",
       "      <td>106607</td>\n",
       "      <td>107187</td>\n",
       "      <td>...</td>\n",
       "      <td>47940</td>\n",
       "      <td>79679</td>\n",
       "      <td>58500</td>\n",
       "      <td>102121</td>\n",
       "      <td>39499</td>\n",
       "      <td>18877</td>\n",
       "      <td>99443</td>\n",
       "      <td>64920</td>\n",
       "      <td>98500</td>\n",
       "      <td>98828</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1600 rows × 51 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      user_id       0       1       2      3      4       5       6       7  \\\n",
       "0           2   36058   67567   14234  91413  19318   14233   91002  112197   \n",
       "1           8   18307   39469   26786  15029  13948     228   40318   39921   \n",
       "2           9   24232  109651    8552  40854  88062   21504   11170   57849   \n",
       "3          17   13285   51966   80606  20848  29918   37775   25684  115990   \n",
       "4          42   87254   40670   13302  17491  13306   59783  103775  102082   \n",
       "...       ...     ...     ...     ...    ...    ...     ...     ...     ...   \n",
       "1595    35338   80101    8207   12530  60349  76806   85661   68871   87016   \n",
       "1596    35360   28966   78438    7820  74204  80437   81227   94674   21426   \n",
       "1597    35372   76806   70643   90006  93437  94634   36071   50844   46491   \n",
       "1598    35374   27267   36259  107900  90052   9499   95843   68931   52182   \n",
       "1599    35386  103005  103668   34027  89440  20347  100870   92712  106607   \n",
       "\n",
       "           8  ...      40      41     42      43      44      45     46  \\\n",
       "0      68439  ...   90988   16722  50151   68493   15557   93845  15556   \n",
       "1      34006  ...    4492  106175  22123     276   33689     640  23773   \n",
       "2       4340  ...    7156   17696  35264    7939    9604   71671  10656   \n",
       "3      32683  ...   85426   80324   5141  106783   55449   11101  95508   \n",
       "4      23825  ...   26149   75244  24411   64622  110891  111225  21580   \n",
       "...      ...  ...     ...     ...    ...     ...     ...     ...    ...   \n",
       "1595   45278  ...   25367   85900  63510   72079   67647  112860  50277   \n",
       "1596   99626  ...  100444   94055  84094   47027   52261   75950  73369   \n",
       "1597   63321  ...  110845   23097  40989   53845   89864  116102  96020   \n",
       "1598   42248  ...   80434   65099  41858   10914   97254   68886  81042   \n",
       "1599  107187  ...   47940   79679  58500  102121   39499   18877  99443   \n",
       "\n",
       "          47      48     49  \n",
       "0     103448   16875  90445  \n",
       "1      34258   35140  33881  \n",
       "2      37580   54429  52766  \n",
       "3       4340   27657    714  \n",
       "4      41603   34934  23924  \n",
       "...      ...     ...    ...  \n",
       "1595   70391   58165  45578  \n",
       "1596     795  115686   1363  \n",
       "1597   98643  108205  74774  \n",
       "1598   85613   41219  53367  \n",
       "1599   64920   98500  98828  \n",
       "\n",
       "[1600 rows x 51 columns]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "infer_recall_df, result = get_rank_predict(infer_recall_recom_df, target_phase, rating_col='prob')\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83150\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11</td>\n",
       "      <td>20389</td>\n",
       "      <td>10528</td>\n",
       "      <td>84026</td>\n",
       "      <td>79868</td>\n",
       "      <td>66955</td>\n",
       "      <td>83429</td>\n",
       "      <td>59862</td>\n",
       "      <td>21941</td>\n",
       "      <td>26711</td>\n",
       "      <td>...</td>\n",
       "      <td>25539</td>\n",
       "      <td>59382</td>\n",
       "      <td>79345</td>\n",
       "      <td>18552</td>\n",
       "      <td>65676</td>\n",
       "      <td>76676</td>\n",
       "      <td>11896</td>\n",
       "      <td>2538</td>\n",
       "      <td>103775</td>\n",
       "      <td>6264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22</td>\n",
       "      <td>108852</td>\n",
       "      <td>100827</td>\n",
       "      <td>85728</td>\n",
       "      <td>101900</td>\n",
       "      <td>80765</td>\n",
       "      <td>109803</td>\n",
       "      <td>86011</td>\n",
       "      <td>43263</td>\n",
       "      <td>10513</td>\n",
       "      <td>...</td>\n",
       "      <td>86836</td>\n",
       "      <td>30941</td>\n",
       "      <td>42910</td>\n",
       "      <td>25433</td>\n",
       "      <td>66475</td>\n",
       "      <td>58916</td>\n",
       "      <td>79511</td>\n",
       "      <td>6702</td>\n",
       "      <td>45772</td>\n",
       "      <td>7807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>44</td>\n",
       "      <td>25356</td>\n",
       "      <td>88371</td>\n",
       "      <td>77047</td>\n",
       "      <td>25454</td>\n",
       "      <td>25306</td>\n",
       "      <td>95536</td>\n",
       "      <td>25197</td>\n",
       "      <td>11328</td>\n",
       "      <td>78709</td>\n",
       "      <td>...</td>\n",
       "      <td>109170</td>\n",
       "      <td>27179</td>\n",
       "      <td>108857</td>\n",
       "      <td>74261</td>\n",
       "      <td>60544</td>\n",
       "      <td>89554</td>\n",
       "      <td>93424</td>\n",
       "      <td>80464</td>\n",
       "      <td>70618</td>\n",
       "      <td>71152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>55</td>\n",
       "      <td>95867</td>\n",
       "      <td>87011</td>\n",
       "      <td>60374</td>\n",
       "      <td>69312</td>\n",
       "      <td>100510</td>\n",
       "      <td>100940</td>\n",
       "      <td>40981</td>\n",
       "      <td>37819</td>\n",
       "      <td>77831</td>\n",
       "      <td>...</td>\n",
       "      <td>3506</td>\n",
       "      <td>6669</td>\n",
       "      <td>58966</td>\n",
       "      <td>54564</td>\n",
       "      <td>53785</td>\n",
       "      <td>82552</td>\n",
       "      <td>9555</td>\n",
       "      <td>4154</td>\n",
       "      <td>53403</td>\n",
       "      <td>59795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>66</td>\n",
       "      <td>76806</td>\n",
       "      <td>85661</td>\n",
       "      <td>36071</td>\n",
       "      <td>42985</td>\n",
       "      <td>51182</td>\n",
       "      <td>50958</td>\n",
       "      <td>80679</td>\n",
       "      <td>78868</td>\n",
       "      <td>53845</td>\n",
       "      <td>...</td>\n",
       "      <td>67890</td>\n",
       "      <td>65476</td>\n",
       "      <td>25339</td>\n",
       "      <td>89524</td>\n",
       "      <td>27944</td>\n",
       "      <td>69398</td>\n",
       "      <td>93539</td>\n",
       "      <td>38289</td>\n",
       "      <td>63321</td>\n",
       "      <td>41604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1658</th>\n",
       "      <td>35321</td>\n",
       "      <td>109556</td>\n",
       "      <td>32148</td>\n",
       "      <td>91689</td>\n",
       "      <td>11902</td>\n",
       "      <td>96077</td>\n",
       "      <td>5307</td>\n",
       "      <td>3147</td>\n",
       "      <td>38330</td>\n",
       "      <td>40764</td>\n",
       "      <td>...</td>\n",
       "      <td>3428</td>\n",
       "      <td>4089</td>\n",
       "      <td>70245</td>\n",
       "      <td>81076</td>\n",
       "      <td>24212</td>\n",
       "      <td>104455</td>\n",
       "      <td>18513</td>\n",
       "      <td>3247</td>\n",
       "      <td>7394</td>\n",
       "      <td>76469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1659</th>\n",
       "      <td>35343</td>\n",
       "      <td>95312</td>\n",
       "      <td>11645</td>\n",
       "      <td>28880</td>\n",
       "      <td>33200</td>\n",
       "      <td>47905</td>\n",
       "      <td>64147</td>\n",
       "      <td>46639</td>\n",
       "      <td>63958</td>\n",
       "      <td>87020</td>\n",
       "      <td>...</td>\n",
       "      <td>11031</td>\n",
       "      <td>39717</td>\n",
       "      <td>69435</td>\n",
       "      <td>14148</td>\n",
       "      <td>83784</td>\n",
       "      <td>58096</td>\n",
       "      <td>30766</td>\n",
       "      <td>56746</td>\n",
       "      <td>29889</td>\n",
       "      <td>86127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1660</th>\n",
       "      <td>35354</td>\n",
       "      <td>100517</td>\n",
       "      <td>29975</td>\n",
       "      <td>98928</td>\n",
       "      <td>13623</td>\n",
       "      <td>22785</td>\n",
       "      <td>46670</td>\n",
       "      <td>26758</td>\n",
       "      <td>53056</td>\n",
       "      <td>16296</td>\n",
       "      <td>...</td>\n",
       "      <td>51289</td>\n",
       "      <td>71771</td>\n",
       "      <td>33697</td>\n",
       "      <td>37015</td>\n",
       "      <td>89124</td>\n",
       "      <td>82194</td>\n",
       "      <td>8410</td>\n",
       "      <td>17561</td>\n",
       "      <td>20131</td>\n",
       "      <td>102886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1661</th>\n",
       "      <td>35365</td>\n",
       "      <td>27816</td>\n",
       "      <td>67570</td>\n",
       "      <td>3970</td>\n",
       "      <td>82080</td>\n",
       "      <td>91392</td>\n",
       "      <td>68947</td>\n",
       "      <td>77740</td>\n",
       "      <td>92536</td>\n",
       "      <td>23318</td>\n",
       "      <td>...</td>\n",
       "      <td>16850</td>\n",
       "      <td>49491</td>\n",
       "      <td>65836</td>\n",
       "      <td>7347</td>\n",
       "      <td>72266</td>\n",
       "      <td>48266</td>\n",
       "      <td>59012</td>\n",
       "      <td>6171</td>\n",
       "      <td>48963</td>\n",
       "      <td>60538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1662</th>\n",
       "      <td>35398</td>\n",
       "      <td>111140</td>\n",
       "      <td>88431</td>\n",
       "      <td>30149</td>\n",
       "      <td>91581</td>\n",
       "      <td>64971</td>\n",
       "      <td>88781</td>\n",
       "      <td>102821</td>\n",
       "      <td>97063</td>\n",
       "      <td>95453</td>\n",
       "      <td>...</td>\n",
       "      <td>109592</td>\n",
       "      <td>69969</td>\n",
       "      <td>42651</td>\n",
       "      <td>97103</td>\n",
       "      <td>56765</td>\n",
       "      <td>100492</td>\n",
       "      <td>29749</td>\n",
       "      <td>54702</td>\n",
       "      <td>27885</td>\n",
       "      <td>104465</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1663 rows × 51 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      user_id       0       1      2       3       4       5       6      7  \\\n",
       "0          11   20389   10528  84026   79868   66955   83429   59862  21941   \n",
       "1          22  108852  100827  85728  101900   80765  109803   86011  43263   \n",
       "2          44   25356   88371  77047   25454   25306   95536   25197  11328   \n",
       "3          55   95867   87011  60374   69312  100510  100940   40981  37819   \n",
       "4          66   76806   85661  36071   42985   51182   50958   80679  78868   \n",
       "...       ...     ...     ...    ...     ...     ...     ...     ...    ...   \n",
       "1658    35321  109556   32148  91689   11902   96077    5307    3147  38330   \n",
       "1659    35343   95312   11645  28880   33200   47905   64147   46639  63958   \n",
       "1660    35354  100517   29975  98928   13623   22785   46670   26758  53056   \n",
       "1661    35365   27816   67570   3970   82080   91392   68947   77740  92536   \n",
       "1662    35398  111140   88431  30149   91581   64971   88781  102821  97063   \n",
       "\n",
       "          8  ...      40     41      42     43     44      45     46     47  \\\n",
       "0     26711  ...   25539  59382   79345  18552  65676   76676  11896   2538   \n",
       "1     10513  ...   86836  30941   42910  25433  66475   58916  79511   6702   \n",
       "2     78709  ...  109170  27179  108857  74261  60544   89554  93424  80464   \n",
       "3     77831  ...    3506   6669   58966  54564  53785   82552   9555   4154   \n",
       "4     53845  ...   67890  65476   25339  89524  27944   69398  93539  38289   \n",
       "...     ...  ...     ...    ...     ...    ...    ...     ...    ...    ...   \n",
       "1658  40764  ...    3428   4089   70245  81076  24212  104455  18513   3247   \n",
       "1659  87020  ...   11031  39717   69435  14148  83784   58096  30766  56746   \n",
       "1660  16296  ...   51289  71771   33697  37015  89124   82194   8410  17561   \n",
       "1661  23318  ...   16850  49491   65836   7347  72266   48266  59012   6171   \n",
       "1662  95453  ...  109592  69969   42651  97103  56765  100492  29749  54702   \n",
       "\n",
       "          48      49  \n",
       "0     103775    6264  \n",
       "1      45772    7807  \n",
       "2      70618   71152  \n",
       "3      53403   59795  \n",
       "4      63321   41604  \n",
       "...      ...     ...  \n",
       "1658    7394   76469  \n",
       "1659   29889   86127  \n",
       "1660   20131  102886  \n",
       "1661   48963   60538  \n",
       "1662   27885  104465  \n",
       "\n",
       "[1663 rows x 51 columns]"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_recall_predict(infer_recall_recom_df, target_phase) # phase 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83150\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11</td>\n",
       "      <td>79868</td>\n",
       "      <td>59255</td>\n",
       "      <td>21517</td>\n",
       "      <td>26711</td>\n",
       "      <td>84026</td>\n",
       "      <td>20389</td>\n",
       "      <td>66955</td>\n",
       "      <td>10528</td>\n",
       "      <td>3654</td>\n",
       "      <td>...</td>\n",
       "      <td>4453</td>\n",
       "      <td>40484</td>\n",
       "      <td>4971</td>\n",
       "      <td>52751</td>\n",
       "      <td>11595</td>\n",
       "      <td>68105</td>\n",
       "      <td>15844</td>\n",
       "      <td>11896</td>\n",
       "      <td>34630</td>\n",
       "      <td>6264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22</td>\n",
       "      <td>100827</td>\n",
       "      <td>108852</td>\n",
       "      <td>85728</td>\n",
       "      <td>109803</td>\n",
       "      <td>101900</td>\n",
       "      <td>98489</td>\n",
       "      <td>113764</td>\n",
       "      <td>80765</td>\n",
       "      <td>100703</td>\n",
       "      <td>...</td>\n",
       "      <td>113527</td>\n",
       "      <td>103417</td>\n",
       "      <td>105407</td>\n",
       "      <td>79511</td>\n",
       "      <td>570</td>\n",
       "      <td>40648</td>\n",
       "      <td>57042</td>\n",
       "      <td>43245</td>\n",
       "      <td>42910</td>\n",
       "      <td>81106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>44</td>\n",
       "      <td>77047</td>\n",
       "      <td>88371</td>\n",
       "      <td>25356</td>\n",
       "      <td>25306</td>\n",
       "      <td>25454</td>\n",
       "      <td>95536</td>\n",
       "      <td>25197</td>\n",
       "      <td>25339</td>\n",
       "      <td>25178</td>\n",
       "      <td>...</td>\n",
       "      <td>109170</td>\n",
       "      <td>76806</td>\n",
       "      <td>27179</td>\n",
       "      <td>50844</td>\n",
       "      <td>113733</td>\n",
       "      <td>80464</td>\n",
       "      <td>70618</td>\n",
       "      <td>62532</td>\n",
       "      <td>71152</td>\n",
       "      <td>81717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>55</td>\n",
       "      <td>95867</td>\n",
       "      <td>100510</td>\n",
       "      <td>40981</td>\n",
       "      <td>87011</td>\n",
       "      <td>100940</td>\n",
       "      <td>14626</td>\n",
       "      <td>35884</td>\n",
       "      <td>16725</td>\n",
       "      <td>91879</td>\n",
       "      <td>...</td>\n",
       "      <td>56638</td>\n",
       "      <td>4154</td>\n",
       "      <td>93328</td>\n",
       "      <td>9555</td>\n",
       "      <td>80865</td>\n",
       "      <td>33366</td>\n",
       "      <td>35878</td>\n",
       "      <td>18472</td>\n",
       "      <td>86054</td>\n",
       "      <td>20437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>66</td>\n",
       "      <td>42985</td>\n",
       "      <td>51182</td>\n",
       "      <td>53845</td>\n",
       "      <td>22404</td>\n",
       "      <td>37665</td>\n",
       "      <td>76806</td>\n",
       "      <td>85661</td>\n",
       "      <td>36071</td>\n",
       "      <td>20115</td>\n",
       "      <td>...</td>\n",
       "      <td>73287</td>\n",
       "      <td>22383</td>\n",
       "      <td>32157</td>\n",
       "      <td>25178</td>\n",
       "      <td>85158</td>\n",
       "      <td>103204</td>\n",
       "      <td>79060</td>\n",
       "      <td>65476</td>\n",
       "      <td>66752</td>\n",
       "      <td>70691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1658</th>\n",
       "      <td>35321</td>\n",
       "      <td>32148</td>\n",
       "      <td>109556</td>\n",
       "      <td>5307</td>\n",
       "      <td>96077</td>\n",
       "      <td>11902</td>\n",
       "      <td>25334</td>\n",
       "      <td>3147</td>\n",
       "      <td>91689</td>\n",
       "      <td>63131</td>\n",
       "      <td>...</td>\n",
       "      <td>71220</td>\n",
       "      <td>6326</td>\n",
       "      <td>110141</td>\n",
       "      <td>12749</td>\n",
       "      <td>28741</td>\n",
       "      <td>12554</td>\n",
       "      <td>106031</td>\n",
       "      <td>4980</td>\n",
       "      <td>70245</td>\n",
       "      <td>9881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1659</th>\n",
       "      <td>35343</td>\n",
       "      <td>11645</td>\n",
       "      <td>28880</td>\n",
       "      <td>95312</td>\n",
       "      <td>46639</td>\n",
       "      <td>33200</td>\n",
       "      <td>97400</td>\n",
       "      <td>75564</td>\n",
       "      <td>25613</td>\n",
       "      <td>47905</td>\n",
       "      <td>...</td>\n",
       "      <td>29889</td>\n",
       "      <td>85458</td>\n",
       "      <td>111225</td>\n",
       "      <td>77322</td>\n",
       "      <td>1236</td>\n",
       "      <td>52119</td>\n",
       "      <td>71994</td>\n",
       "      <td>53566</td>\n",
       "      <td>32102</td>\n",
       "      <td>44195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1660</th>\n",
       "      <td>35354</td>\n",
       "      <td>100517</td>\n",
       "      <td>29975</td>\n",
       "      <td>46670</td>\n",
       "      <td>13623</td>\n",
       "      <td>22785</td>\n",
       "      <td>53056</td>\n",
       "      <td>26758</td>\n",
       "      <td>16296</td>\n",
       "      <td>5895</td>\n",
       "      <td>...</td>\n",
       "      <td>24025</td>\n",
       "      <td>62489</td>\n",
       "      <td>4844</td>\n",
       "      <td>32544</td>\n",
       "      <td>103202</td>\n",
       "      <td>6216</td>\n",
       "      <td>75986</td>\n",
       "      <td>20235</td>\n",
       "      <td>93516</td>\n",
       "      <td>23265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1661</th>\n",
       "      <td>35365</td>\n",
       "      <td>27816</td>\n",
       "      <td>91392</td>\n",
       "      <td>92538</td>\n",
       "      <td>92536</td>\n",
       "      <td>67570</td>\n",
       "      <td>92659</td>\n",
       "      <td>995</td>\n",
       "      <td>3970</td>\n",
       "      <td>93845</td>\n",
       "      <td>...</td>\n",
       "      <td>59012</td>\n",
       "      <td>27227</td>\n",
       "      <td>60538</td>\n",
       "      <td>82080</td>\n",
       "      <td>24978</td>\n",
       "      <td>96185</td>\n",
       "      <td>54019</td>\n",
       "      <td>93856</td>\n",
       "      <td>48266</td>\n",
       "      <td>75830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1662</th>\n",
       "      <td>35398</td>\n",
       "      <td>111140</td>\n",
       "      <td>88431</td>\n",
       "      <td>91581</td>\n",
       "      <td>30149</td>\n",
       "      <td>97063</td>\n",
       "      <td>88781</td>\n",
       "      <td>64971</td>\n",
       "      <td>102821</td>\n",
       "      <td>108845</td>\n",
       "      <td>...</td>\n",
       "      <td>35439</td>\n",
       "      <td>95445</td>\n",
       "      <td>39389</td>\n",
       "      <td>45866</td>\n",
       "      <td>73416</td>\n",
       "      <td>98535</td>\n",
       "      <td>13018</td>\n",
       "      <td>29749</td>\n",
       "      <td>94054</td>\n",
       "      <td>97103</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1663 rows × 51 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      user_id       0       1      2       3       4      5       6       7  \\\n",
       "0          11   79868   59255  21517   26711   84026  20389   66955   10528   \n",
       "1          22  100827  108852  85728  109803  101900  98489  113764   80765   \n",
       "2          44   77047   88371  25356   25306   25454  95536   25197   25339   \n",
       "3          55   95867  100510  40981   87011  100940  14626   35884   16725   \n",
       "4          66   42985   51182  53845   22404   37665  76806   85661   36071   \n",
       "...       ...     ...     ...    ...     ...     ...    ...     ...     ...   \n",
       "1658    35321   32148  109556   5307   96077   11902  25334    3147   91689   \n",
       "1659    35343   11645   28880  95312   46639   33200  97400   75564   25613   \n",
       "1660    35354  100517   29975  46670   13623   22785  53056   26758   16296   \n",
       "1661    35365   27816   91392  92538   92536   67570  92659     995    3970   \n",
       "1662    35398  111140   88431  91581   30149   97063  88781   64971  102821   \n",
       "\n",
       "           8  ...      40      41      42     43      44      45      46  \\\n",
       "0       3654  ...    4453   40484    4971  52751   11595   68105   15844   \n",
       "1     100703  ...  113527  103417  105407  79511     570   40648   57042   \n",
       "2      25178  ...  109170   76806   27179  50844  113733   80464   70618   \n",
       "3      91879  ...   56638    4154   93328   9555   80865   33366   35878   \n",
       "4      20115  ...   73287   22383   32157  25178   85158  103204   79060   \n",
       "...      ...  ...     ...     ...     ...    ...     ...     ...     ...   \n",
       "1658   63131  ...   71220    6326  110141  12749   28741   12554  106031   \n",
       "1659   47905  ...   29889   85458  111225  77322    1236   52119   71994   \n",
       "1660    5895  ...   24025   62489    4844  32544  103202    6216   75986   \n",
       "1661   93845  ...   59012   27227   60538  82080   24978   96185   54019   \n",
       "1662  108845  ...   35439   95445   39389  45866   73416   98535   13018   \n",
       "\n",
       "         47     48     49  \n",
       "0     11896  34630   6264  \n",
       "1     43245  42910  81106  \n",
       "2     62532  71152  81717  \n",
       "3     18472  86054  20437  \n",
       "4     65476  66752  70691  \n",
       "...     ...    ...    ...  \n",
       "1658   4980  70245   9881  \n",
       "1659  53566  32102  44195  \n",
       "1660  20235  93516  23265  \n",
       "1661  93856  48266  75830  \n",
       "1662  29749  94054  97103  \n",
       "\n",
       "[1663 rows x 51 columns]"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# phase 0\n",
    "infer_recall_df, result = get_rank_predict(infer_recall_recom_df, target_phase, rating_col='prob')\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### submit one-phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_recom_df = pickle.load(open('sub_0513_cf_df_online.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_recom_lgb_df = total_recom_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_recom_lgb_df = total_recom_lgb_df[total_recom_lgb_df['phase'] != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set()"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(infer_recall_recom_df['user_id'].unique())-set(total_recom_df[total_recom_df['phase'] == 0].user_id.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "online_infer_recall_recom_df = infer_recall_recom_df[['user_id', 'item_id', 'prob']].rename(columns={'prob': 'sim'})\n",
    "online_infer_recall_recom_df['phase'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>sim</th>\n",
       "      <th>phase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1133</td>\n",
       "      <td>87420</td>\n",
       "      <td>0.503302</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1133</td>\n",
       "      <td>47839</td>\n",
       "      <td>0.417899</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1133</td>\n",
       "      <td>108699</td>\n",
       "      <td>0.278788</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1133</td>\n",
       "      <td>4844</td>\n",
       "      <td>0.248607</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1133</td>\n",
       "      <td>53692</td>\n",
       "      <td>0.246954</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>626986</th>\n",
       "      <td>20922</td>\n",
       "      <td>17522</td>\n",
       "      <td>0.028076</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>626987</th>\n",
       "      <td>20922</td>\n",
       "      <td>77119</td>\n",
       "      <td>0.011286</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>626988</th>\n",
       "      <td>20922</td>\n",
       "      <td>93858</td>\n",
       "      <td>0.013175</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>626989</th>\n",
       "      <td>20922</td>\n",
       "      <td>48807</td>\n",
       "      <td>0.012677</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>626990</th>\n",
       "      <td>20922</td>\n",
       "      <td>28810</td>\n",
       "      <td>0.012417</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>626991 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        user_id  item_id       sim  phase\n",
       "0          1133    87420  0.503302      0\n",
       "1          1133    47839  0.417899      0\n",
       "2          1133   108699  0.278788      0\n",
       "3          1133     4844  0.248607      0\n",
       "4          1133    53692  0.246954      0\n",
       "...         ...      ...       ...    ...\n",
       "626986    20922    17522  0.028076      0\n",
       "626987    20922    77119  0.011286      0\n",
       "626988    20922    93858  0.013175      0\n",
       "626989    20922    48807  0.012677      0\n",
       "626990    20922    28810  0.012417      0\n",
       "\n",
       "[626991 rows x 4 columns]"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "online_infer_recall_recom_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_recom_lgb_df = total_recom_lgb_df.append(online_infer_recall_recom_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>sim</th>\n",
       "      <th>phase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>32360</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>100116</td>\n",
       "      <td>0.663404</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>46297</td>\n",
       "      <td>1.337734</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>35247</td>\n",
       "      <td>0.956139</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>92349</td>\n",
       "      <td>0.886396</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>626986</th>\n",
       "      <td>20922</td>\n",
       "      <td>17522</td>\n",
       "      <td>0.028076</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>626987</th>\n",
       "      <td>20922</td>\n",
       "      <td>77119</td>\n",
       "      <td>0.011286</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>626988</th>\n",
       "      <td>20922</td>\n",
       "      <td>93858</td>\n",
       "      <td>0.013175</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>626989</th>\n",
       "      <td>20922</td>\n",
       "      <td>48807</td>\n",
       "      <td>0.012677</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>626990</th>\n",
       "      <td>20922</td>\n",
       "      <td>28810</td>\n",
       "      <td>0.012417</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3978268 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        user_id  item_id       sim  phase\n",
       "0             1    32360  4.000000      1\n",
       "1             1   100116  0.663404      1\n",
       "2             1    46297  1.337734      1\n",
       "3             1    35247  0.956139      1\n",
       "4             1    92349  0.886396      1\n",
       "...         ...      ...       ...    ...\n",
       "626986    20922    17522  0.028076      0\n",
       "626987    20922    77119  0.011286      0\n",
       "626988    20922    93858  0.013175      0\n",
       "626989    20922    48807  0.012677      0\n",
       "626990    20922    28810  0.012417      0\n",
       "\n",
       "[3978268 rows x 4 columns]"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_recom_lgb_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "513000\n"
     ]
    }
   ],
   "source": [
    "# find most popular items  \n",
    "result = get_predict(total_recom_lgb_df, 'sim', online_top50_click)\n",
    "result.to_csv(output_path + '/baseline_cf_ranking_0_v4.csv', index=False, header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sub_online/baseline_cf_ranking_0_v4.csv'"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_path + '/baseline_cf_ranking_0_v4.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "upload: sub_online/baseline_cf_ranking_0_v4.csv to s3://mx-machine-learning/xuetaofeng/kdd/phase/5/baseline_cf_ranking_0.csv\n"
     ]
    }
   ],
   "source": [
    "!aws s3 cp 'sub_online/baseline_cf_ranking_0_v4.csv' s3://mx-machine-learning/xuetaofeng/kdd/phase/5/baseline_cf_ranking_0.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>sim</th>\n",
       "      <th>phase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>32360</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>100116</td>\n",
       "      <td>0.663404</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>46297</td>\n",
       "      <td>1.337734</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>35247</td>\n",
       "      <td>0.956139</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>92349</td>\n",
       "      <td>0.886396</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>626986</th>\n",
       "      <td>20922</td>\n",
       "      <td>17522</td>\n",
       "      <td>0.028076</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>626987</th>\n",
       "      <td>20922</td>\n",
       "      <td>77119</td>\n",
       "      <td>0.011286</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>626988</th>\n",
       "      <td>20922</td>\n",
       "      <td>93858</td>\n",
       "      <td>0.013175</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>626989</th>\n",
       "      <td>20922</td>\n",
       "      <td>48807</td>\n",
       "      <td>0.012677</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>626990</th>\n",
       "      <td>20922</td>\n",
       "      <td>28810</td>\n",
       "      <td>0.012417</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3978268 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        user_id  item_id       sim  phase\n",
       "0             1    32360  4.000000      1\n",
       "1             1   100116  0.663404      1\n",
       "2             1    46297  1.337734      1\n",
       "3             1    35247  0.956139      1\n",
       "4             1    92349  0.886396      1\n",
       "...         ...      ...       ...    ...\n",
       "626986    20922    17522  0.028076      0\n",
       "626987    20922    77119  0.011286      0\n",
       "626988    20922    93858  0.013175      0\n",
       "626989    20922    48807  0.012677      0\n",
       "626990    20922    28810  0.012417      0\n",
       "\n",
       "[3978268 rows x 4 columns]"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_recom_lgb_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DeepCTR(py3)",
   "language": "python",
   "name": "deepctr"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "287.9891357421875px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
